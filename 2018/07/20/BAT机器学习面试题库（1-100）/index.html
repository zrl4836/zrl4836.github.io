<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://yoursite.com">
  <title>BAT机器学习面试题库(1-100) | fahai的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="为了求职笔试面试，需恶补基础、算法原理，于是仔细研读了七月在线发布的BAT机器学习面试1000题系列，也添加了一些自己的理解或来自其他博客的答案，以下内容均来自BAT机器学习面试1000题系列。该文为本人的阅读笔记，主要是为了记忆和自查。 　　 前言July我又回来了。  之前本博客整理过数千道微软等公司的面试题，侧重数据结构、算法、海量数据处理，详见：微软面试100题系列，今17年，近期和团">
<meta name="keywords" content="面试,笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="BAT机器学习面试题库(1-100)">
<meta property="og:url" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/index.html">
<meta property="og:site_name" content="fahai的博客">
<meta property="og:description" content="为了求职笔试面试，需恶补基础、算法原理，于是仔细研读了七月在线发布的BAT机器学习面试1000题系列，也添加了一些自己的理解或来自其他博客的答案，以下内容均来自BAT机器学习面试1000题系列。该文为本人的阅读笔记，主要是为了记忆和自查。 　　 前言July我又回来了。  之前本博客整理过数千道微软等公司的面试题，侧重数据结构、算法、海量数据处理，详见：微软面试100题系列，今17年，近期和团">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/graph.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/flow.gif">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/AlexNet.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/lrloss.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/gaussian.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/gaussianfb.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/laplacefb.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/cnn1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/cnn2.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/plsa.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/lda.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/em1.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/gmm.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/gmm_e.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/gmm_m.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/conentry.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/IX.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/sigmoid.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/logistic.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/sigmoid.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/conv1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/cov.gif">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/pooling.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/GAN.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/pipleline.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_9.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_10.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_11.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_12.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_14.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/image_thumb_15.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/BGD.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/1042406-20161017221342935-1872962415.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/NewtonIteration_Ani.gif">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/222309373784741.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/222253268161863.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008190826961.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008190944146.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008190952260.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008191123640.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/220px-Conjugate_gradient_illustration.svg.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008200137803.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171214111608352.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20131119171556593.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20131119171613656.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/sigmoid.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171214113420858.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171604539.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171612298.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171620055.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171627148.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171638975.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171649563.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171727619.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171738997.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171751331.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171820270.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171832891.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171908694.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006171917236.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006172007882.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171006172029181.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20170929002252306.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20150921225357857.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20150921225622105.jpg">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/1.png">
<meta property="og:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/20171008195457989.jpg">
<meta property="og:updated_time" content="2018-09-11T08:48:02.597Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BAT机器学习面试题库(1-100)">
<meta name="twitter:description" content="为了求职笔试面试，需恶补基础、算法原理，于是仔细研读了七月在线发布的BAT机器学习面试1000题系列，也添加了一些自己的理解或来自其他博客的答案，以下内容均来自BAT机器学习面试1000题系列。该文为本人的阅读笔记，主要是为了记忆和自查。 　　 前言July我又回来了。  之前本博客整理过数千道微软等公司的面试题，侧重数据结构、算法、海量数据处理，详见：微软面试100题系列，今17年，近期和团">
<meta name="twitter:image" content="http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/graph.jpg">
  
    <link rel="alternative" href="/atom.xml" title="fahai的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/assets/img/favicon.ico">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<!-- <div class="overlay" style="background: #CDC9A5"></div> -->
<div class="overlay" style="background: url('/assets/blogImg/cyy.jpg') no-repeat center bottom;background-size: cover;"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/assets/blogImg/fahai.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">申发海</a></h1>
		</hgroup>
		
		<p class="header-subtitle">重庆邮电大学19届研究僧一枚，找工作中......</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/photos/">相册</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav" style="display:block;">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/fahaihappy" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="http://weibo.com/fahaihappy" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:861768935@qq.com" title="mail"><i class="icon-mail"></i></a>
		        
					<a class="weixin" target="_blank" href="/assets/img/weixin.png" title="weixin"><i class="icon-weixin"></i></a>
		        
			</div>
		</nav>
		
		
	
	</header>	
	<div style="position:absolute; bottom: 60px; left:36px; width:76%;">
		<iframe width=100% height=86 frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1306496848&auto=0&height=66"></iframe>
	</div>	
</div>

    </div>
   
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #CDC9A5"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/blogImg/fahai.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">申发海</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>重庆邮电大学19届研究僧一枚，找工作中......<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/fahaihappy" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/fahaihappy" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:861768935@qq.com" title="mail"><i class="icon-mail"></i></a>
			        
						<a class="weixin" target="_blank" href="/assets/img/weixin.png" title="weixin"><i class="icon-weixin"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/photos/">相册</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-BAT机器学习面试题库（1-100）" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      BAT机器学习面试题库(1-100)
    </h1>
  

        
        <a href="/2018/07/20/BAT机器学习面试题库（1-100）/" class="archive-article-date">
  	<time datetime="2018-07-19T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-07-20</time>
</a>
        
		
		
			<div style="margin-top:10px;">
    <span class="post-time">
      <span class="post-meta-item-icon">
        <i class="fa fa-keyboard-o"></i>
        <span class="post-meta-item-text">  字数统计: </span>
        <span class="post-count">37.7k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
        <i class="fa fa-hourglass-half"></i>
        <span class="post-meta-item-text">  阅读时长: </span>
        <span class="post-count">136分</span>
      </span>
    </span>
</div>
		
		
		<!-- 目录内容 -->
		
			<p class="show-toc-btn" id="show-toc-btn" onclick="showToc();" style="display:none">
			<span class="btn-bg"></span>
			<span class="btn-text">文章导航</span>
			</p>
			<div id="toc-article" class="toc-article">
				<span id="toc-close" class="toc-close" title="隐藏导航" onclick="showBtn();">×</span>
				<strong class="toc-title">文章目录</strong>
				<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BAT机器学习面试1000题系列"><span class="toc-number"></span> <span class="toc-text">BAT机器学习面试1000题系列</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-请简要介绍下SVM。-机器学习-ML模型-易"><span class="toc-number">0.0.1.</span> <span class="toc-text">1. 请简要介绍下SVM。 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-请简要介绍下Tensorflow的计算图。-深度学习-DL框架-中"><span class="toc-number">0.0.2.</span> <span class="toc-text">2. 请简要介绍下Tensorflow的计算图。 深度学习 DL框架 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？-机器学习-ML模型-中"><span class="toc-number">0.0.3.</span> <span class="toc-text">3. 在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？ 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-CNN的卷积核是单层的还是多层的？-深度学习-DL模型-中"><span class="toc-number">0.0.4.</span> <span class="toc-text">4. CNN的卷积核是单层的还是多层的？ 深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-关于LR。-机器学习-ML模型-难"><span class="toc-number">0.0.5.</span> <span class="toc-text">5. 关于LR。 机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-（过拟合）overfitting怎么解决？机器学习-ML基础-中"><span class="toc-number">0.0.6.</span> <span class="toc-text">6. （过拟合）overfitting怎么解决？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-LR和SVM的联系与区别。机器学习-ML模型-中"><span class="toc-number">0.0.7.</span> <span class="toc-text">7. LR和SVM的联系与区别。机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-说说你知道的核函数。机器学习-ML基础-易"><span class="toc-number">0.0.8.</span> <span class="toc-text">8. 说说你知道的核函数。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-LR与线性回归的区别与联系。机器学习-ML模型-中等"><span class="toc-number">0.0.9.</span> <span class="toc-text">9. LR与线性回归的区别与联系。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-请问（决策树、Random-Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习-ML模型-难"><span class="toc-number">0.0.10.</span> <span class="toc-text">10. 请问（决策树、Random Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难"><span class="toc-number">0.0.11.</span> <span class="toc-text">11. 为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#12-xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习-ML模型-难"><span class="toc-number">0.0.12.</span> <span class="toc-text">12. xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-谈谈判别式模型和生成式模型？机器学习-ML基础-易"><span class="toc-number">0.0.13.</span> <span class="toc-text">13. 谈谈判别式模型和生成式模型？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#14-L1和L2的区别。机器学习-ML基础-易"><span class="toc-number">0.0.14.</span> <span class="toc-text">14. L1和L2的区别。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#15-L1和L2正则先验分别服从什么分布。机器学习-ML基础-易"><span class="toc-number">0.0.15.</span> <span class="toc-text">15. L1和L2正则先验分别服从什么分布。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#16-CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习-DL应用-难"><span class="toc-number">0.0.16.</span> <span class="toc-text">16. CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#17-说一下Adaboost，权值更新公式。当弱分类器是-G-m-时，每个样本的的权重是-w-1，w-2…-，请写出最终的决策公式。机器学习-ML模型-难"><span class="toc-number">0.0.17.</span> <span class="toc-text">17. 说一下Adaboost，权值更新公式。当弱分类器是$G_m$时，每个样本的的权重是$w_1，w_2…$，请写出最终的决策公式。机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#18-LSTM结构推导，为什么比RNN好？-深度学习DL模型-难"><span class="toc-number">0.0.18.</span> <span class="toc-text">18. LSTM结构推导，为什么比RNN好？ 深度学习DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#19-根据谷歌一员工写的How-to-Write-a-Spelling-Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习-ML应用-难"><span class="toc-number">0.0.19.</span> <span class="toc-text">19. 根据谷歌一员工写的How to Write a Spelling Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习 ML应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#20-为什么朴素贝叶斯如此“朴素”？机器学习-ML模型-易"><span class="toc-number">0.0.20.</span> <span class="toc-text">20. 为什么朴素贝叶斯如此“朴素”？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#21-请大致对比下plsa和LDA的区别。机器学习-ML模型-中等"><span class="toc-number">0.0.21.</span> <span class="toc-text">21. 请大致对比下plsa和LDA的区别。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#22-请简要说说EM算法。机器学习-ML模型-中等"><span class="toc-number">0.0.22.</span> <span class="toc-text">22. 请简要说说EM算法。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#23-KNN中的K如何选取的？机器学习-ML模型-易"><span class="toc-number">0.0.23.</span> <span class="toc-text">23. KNN中的K如何选取的？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#24-机器学习中，为何要经常对数据做归一化。机器学习-ML基础-中等"><span class="toc-number">0.0.24.</span> <span class="toc-text">24. 机器学习中，为何要经常对数据做归一化。机器学习 ML基础 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#25-谈谈深度学习中的归一化问题。深度学习-DL基础-易"><span class="toc-number">0.0.25.</span> <span class="toc-text">25. 谈谈深度学习中的归一化问题。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#26-哪些机器学习算法不需要做归一化处理？机器学习-ML基础-易"><span class="toc-number">0.0.26.</span> <span class="toc-text">26. 哪些机器学习算法不需要做归一化处理？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#27-请简要说说一个完整机器学习项目的流程。机器学习-ML应用-中"><span class="toc-number">0.0.27.</span> <span class="toc-text">27. 请简要说说一个完整机器学习项目的流程。机器学习 ML应用 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#28-逻辑斯特回归为什么要对特征进行离散化。机器学习-ML模型-中等"><span class="toc-number">0.0.28.</span> <span class="toc-text">28. 逻辑斯特回归为什么要对特征进行离散化。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#29-下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B）-机器学习-ML模型-中等"><span class="toc-number">0.0.29.</span> <span class="toc-text">29. 下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B） 机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#30-什么是熵。机器学习-ML基础-易"><span class="toc-number">0.0.30.</span> <span class="toc-text">30. 什么是熵。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#31-熵、联合熵、条件熵、相对熵、互信息的定义。机器学习-ML基础-中等"><span class="toc-number">0.0.31.</span> <span class="toc-text">31. 熵、联合熵、条件熵、相对熵、互信息的定义。机器学习 ML基础 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#32-什么是最大熵。机器学习-ML基础-易"><span class="toc-number">0.0.32.</span> <span class="toc-text">32. 什么是最大熵。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#33-了解正则化么。机器学习-ML基础-易"><span class="toc-number">0.0.33.</span> <span class="toc-text">33. 了解正则化么。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#34-协方差和相关性有什么区别？机器学习-ML基础-易"><span class="toc-number">0.0.34.</span> <span class="toc-text">34. 协方差和相关性有什么区别？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#35-线性分类器与非线性分类器的区别以及优劣。机器学习-ML基础-易"><span class="toc-number">0.0.35.</span> <span class="toc-text">35. 线性分类器与非线性分类器的区别以及优劣。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#36-简单说说贝叶斯定理。机器学习-ML模型-易"><span class="toc-number">0.0.36.</span> <span class="toc-text">36. 简单说说贝叶斯定理。机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#37-某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？-A-数据挖掘-DM模型-易"><span class="toc-number">0.0.37.</span> <span class="toc-text">37. 某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？(A)   数据挖掘 DM模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#38-将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？-C-数据挖掘-DM基础-易"><span class="toc-number">0.0.38.</span> <span class="toc-text">38. 将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？(C)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#39-下面哪种不属于数据预处理的方法？-D-数据挖掘-DM基础-易"><span class="toc-number">0.0.39.</span> <span class="toc-text">39. 下面哪种不属于数据预处理的方法？ (D)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#40-什么是KDD？-A-数据挖掘-DM基础-易"><span class="toc-number">0.0.40.</span> <span class="toc-text">40. 什么是KDD？ (A)   数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#41-当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？-B-数据挖掘-DM模型-易"><span class="toc-number">0.0.41.</span> <span class="toc-text">41. 当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？(B)  数据挖掘 DM模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#42-建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？-C-数据挖掘-DM基础-易"><span class="toc-number">0.0.42.</span> <span class="toc-text">42. 建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？(C)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#43-以下哪种方法不属于特征选择的标准方法：-D-数据挖掘-DM基础-易"><span class="toc-number">0.0.43.</span> <span class="toc-text">43. 以下哪种方法不属于特征选择的标准方法： (D)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#44-请用python编写函数find-string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python-Python语言-易"><span class="toc-number">0.0.44.</span> <span class="toc-text">44. 请用python编写函数find_string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python Python语言 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#45-简单说下sigmoid激活函数。深度学习-DL基础-易"><span class="toc-number">0.0.45.</span> <span class="toc-text">45. 简单说下sigmoid激活函数。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#46-什么是卷积。深度学习-DL基础-易"><span class="toc-number">0.0.46.</span> <span class="toc-text">46. 什么是卷积。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#47-什么是CNN的池化pool层。深度学习-DL模型-易"><span class="toc-number">0.0.47.</span> <span class="toc-text">47. 什么是CNN的池化pool层。深度学习 DL模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#48-简述下什么是生成对抗网络（GAN）。深度学习-DL扩展-中"><span class="toc-number">0.0.48.</span> <span class="toc-text">48. 简述下什么是生成对抗网络（GAN）。深度学习 DL扩展 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#48-学梵高作画的原理是啥？深度学习-DL应用-难"><span class="toc-number">0.0.49.</span> <span class="toc-text">48. 学梵高作画的原理是啥？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#49-现在有-a-到-z-26-个元素，-编写程序打印-a-到-z-中任取-3-个元素的组合（比如-打印-a-b-c-，d-y-z等）-数理逻辑-排列组合-中"><span class="toc-number">0.0.50.</span> <span class="toc-text">49. 现在有 a 到 z 26 个元素， 编写程序打印 a 到 z 中任取 3 个元素的组合（比如 打印 a b c ，d y z等） 数理逻辑 排列组合 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#50-说说梯度下降法。机器学习-ML基础-中"><span class="toc-number">0.0.51.</span> <span class="toc-text">50. 说说梯度下降法。机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#51-梯度下降法找到的一定是下降最快的方向么？机器学习-ML基础-中"><span class="toc-number">0.0.52.</span> <span class="toc-text">51. 梯度下降法找到的一定是下降最快的方向么？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#52-随机梯度下降"><span class="toc-number">0.0.53.</span> <span class="toc-text">52. 随机梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#53-牛顿法和梯度下降法有什么不同。机器学习-ML基础-中"><span class="toc-number">0.0.54.</span> <span class="toc-text">53. 牛顿法和梯度下降法有什么不同。机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#54-什么是拟牛顿法（Quasi-Newton-Methods）？机器学习-ML基础-中"><span class="toc-number">0.0.55.</span> <span class="toc-text">54. 什么是拟牛顿法（Quasi-Newton Methods）？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#55-请说说随机梯度下降法的问题和挑战？机器学习-ML基础-中"><span class="toc-number">0.0.56.</span> <span class="toc-text">55. 请说说随机梯度下降法的问题和挑战？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#56-说说共轭梯度法？机器学习-ML基础-中"><span class="toc-number">0.0.57.</span> <span class="toc-text">56. 说说共轭梯度法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#57-对所有优化问题来说-有没有可能找到比現在已知算法更好的算法？机器学习-ML基础-中"><span class="toc-number">0.0.58.</span> <span class="toc-text">57. 对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#58-什么最小二乘法？机器学习-ML基础-中"><span class="toc-number">0.0.59.</span> <span class="toc-text">58. 什么最小二乘法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#59-看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python-Python语言-易"><span class="toc-number">0.0.60.</span> <span class="toc-text">59. 看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python Python语言 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#60-Python是如何进行内存管理的？-Python-Python基础-中"><span class="toc-number">0.0.61.</span> <span class="toc-text">60. Python是如何进行内存管理的？ Python Python基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#61-请写出一段Python代码实现删除一个list里面的重复元素。Python-Python开发-中"><span class="toc-number">0.0.62.</span> <span class="toc-text">61. 请写出一段Python代码实现删除一个list里面的重复元素。Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#62-编程用sort进行排序，然后从最后一个元素开始判断？Python-Python开发-中"><span class="toc-number">0.0.63.</span> <span class="toc-text">62. 编程用sort进行排序，然后从最后一个元素开始判断？Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#63-Python里面如何生成随机数？-？Python-Python开发-中"><span class="toc-number">0.0.64.</span> <span class="toc-text">63. Python里面如何生成随机数？ ？Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#64-说说常见的损失函数？机器学习-ML基础-易"><span class="toc-number">0.0.65.</span> <span class="toc-text">64. 说说常见的损失函数？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#65-简单介绍下logistics回归？机器学习-ML模型-易"><span class="toc-number">0.0.66.</span> <span class="toc-text">65. 简单介绍下logistics回归？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#66-看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习-DL应用-难"><span class="toc-number">0.0.67.</span> <span class="toc-text">66. 看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#67-深度学习在视觉领域有何前沿进展？深度学习-DL应用-难"><span class="toc-number">0.0.68.</span> <span class="toc-text">67. 深度学习在视觉领域有何前沿进展？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#68-在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是-？-机器学习-ML基础-中"><span class="toc-number">0.0.69.</span> <span class="toc-text">68. 在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是(  )？ 机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#69-深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A-B-C的乘积ABC-假设三个矩阵的尺寸分别为m-n，n-p，p-q，且m-lt-n-lt-p-lt-q，以下计算顺序效率最高的是（）？深度学习-DL基础-中"><span class="toc-number">0.0.70.</span> <span class="toc-text">69. 深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A,B,C的乘积ABC,假设三个矩阵的尺寸分别为m*n，n*p，p*q，且m&lt;n&lt;p&lt;q，以下计算顺序效率最高的是（）？深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#70-Nave-Bayes是一种特殊的Bayes分类器-特征变量是X-类别标签是C-它的一个假定是（）机器学习-ML模型-中"><span class="toc-number">0.0.71.</span> <span class="toc-text">70. Nave Bayes是一种特殊的Bayes分类器,特征变量是X,类别标签是C,它的一个假定是（）机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#70-关于支持向量机SVM-下列说法错误的是（）-机器学习-ML模型-中"><span class="toc-number">0.0.72.</span> <span class="toc-text">70. 关于支持向量机SVM,下列说法错误的是（） 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#71-在HMM中-如果已知观察序列和产生观察序列的状态序列-那么可用以下哪种方法直接进行参数估计（）机器学习-ML模型-中"><span class="toc-number">0.0.73.</span> <span class="toc-text">71. 在HMM中,如果已知观察序列和产生观察序列的状态序列,那么可用以下哪种方法直接进行参数估计（）机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#72-假定某同学使用Naive-Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习-ML模型-中"><span class="toc-number">0.0.74.</span> <span class="toc-text">72. 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#73-以下哪些方法不可以直接来对文本分类？机器学习-ML模型-易"><span class="toc-number">0.0.75.</span> <span class="toc-text">73. 以下哪些方法不可以直接来对文本分类？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#74-已知一组数据的协方差矩阵P-下面关于主分量说法错误的是（）机器学习-ML基础-易"><span class="toc-number">0.0.76.</span> <span class="toc-text">74. 已知一组数据的协方差矩阵P,下面关于主分量说法错误的是（）机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#75-kmeans的复杂度？机器学习-ML模型-易"><span class="toc-number">0.0.77.</span> <span class="toc-text">75. kmeans的复杂度？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#76-关于logit回归和SVM不正确的是（A）-机器学习-ML模型-中"><span class="toc-number">0.0.78.</span> <span class="toc-text">76. 关于logit回归和SVM不正确的是（A） 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#77-输入图片大小为200×200，依次经过一层卷积（kernel-size-5×5，padding-1，stride-2），pooling（kernel-size-3×3，padding-0，stride-1），又一层卷积（kernel-size-3×3，padding-1，stride-1）之后，输出特征图大小为（）-深度学习-DL基础-中"><span class="toc-number">0.0.79.</span> <span class="toc-text">77. 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为（） 深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#78-影响聚类算法结果的主要因素有？-机器学习-ML模型-易"><span class="toc-number">0.0.80.</span> <span class="toc-text">78. 影响聚类算法结果的主要因素有？ 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#79-模式识别中，马式距离较之于欧式距离的优点是（C、D）-机器学习-ML模型-易"><span class="toc-number">0.0.81.</span> <span class="toc-text">79. 模式识别中，马式距离较之于欧式距离的优点是（C、D） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#79-影响基本K-均值算法的主要因素有-BD）-机器学习-ML模型-易"><span class="toc-number">0.0.82.</span> <span class="toc-text">79. 影响基本K-均值算法的主要因素有(BD） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#80-在统计模式分类问题中，当先验概率未知时，可以使用（BD）-机器学习-ML模型-易"><span class="toc-number">0.0.83.</span> <span class="toc-text">80. 在统计模式分类问题中，当先验概率未知时，可以使用（BD） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#81-如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC）-机器学习-ML模型-易"><span class="toc-number">0.0.84.</span> <span class="toc-text">81. 如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#82-欧式距离具有（AB-）；马式距离具有（ABCD-）。机器学习-ML基础-易"><span class="toc-number">0.0.85.</span> <span class="toc-text">82. 欧式距离具有（AB ）；马式距离具有（ABCD ）。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#83-你有哪些deep-learning（rnn、cnn）调参的经验？-深度学习-DL基础-中"><span class="toc-number">0.0.86.</span> <span class="toc-text">83. 你有哪些deep learning（rnn、cnn）调参的经验？ 深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#84-简单说说RNN的原理？深度学习-DL模型-中"><span class="toc-number">0.0.87.</span> <span class="toc-text">84. 简单说说RNN的原理？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#85-什么是RNN？深度学习-DL模型-中"><span class="toc-number">0.0.88.</span> <span class="toc-text">85. 什么是RNN？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#86-RNN是怎么从单层网络一步一步构造的？深度学习-DL模型-难"><span class="toc-number">0.0.89.</span> <span class="toc-text">86. RNN是怎么从单层网络一步一步构造的？深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#87-RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习-DL模型-中"><span class="toc-number">0.0.90.</span> <span class="toc-text">87. RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#88-深度学习（CNN-RNN-Attention）解决大规模文本分类问题。深度学习-DL应用-难"><span class="toc-number">0.0.91.</span> <span class="toc-text">88. 深度学习（CNN RNN Attention）解决大规模文本分类问题。深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#89-如何解决RNN梯度爆炸和弥散的问题？深度学习-DL模型-难"><span class="toc-number">0.0.92.</span> <span class="toc-text">89. 如何解决RNN梯度爆炸和弥散的问题？深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#90-如何理解LSTM网络。深度学习-DL模型-难"><span class="toc-number">0.0.93.</span> <span class="toc-text">90. 如何理解LSTM网络。深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#91-当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习-ML应用-难"><span class="toc-number">0.0.94.</span> <span class="toc-text">91. 当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习 ML应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#92-如何提高深度学习的性能？深度学习-DL应用-难"><span class="toc-number">0.0.95.</span> <span class="toc-text">92. 如何提高深度学习的性能？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#93-什麽样的资料集不适合用深度学习？深度学习-DL应用-难"><span class="toc-number">0.0.96.</span> <span class="toc-text">93. 什麽样的资料集不适合用深度学习？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#94-广义线性模型是怎被应用在深度学习中？深度学习-DL模型-中"><span class="toc-number">0.0.97.</span> <span class="toc-text">94. 广义线性模型是怎被应用在深度学习中？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#95-准备机器学习面试应该了解哪些理论知识？机器学习-ML模型-中"><span class="toc-number">0.0.98.</span> <span class="toc-text">95. 准备机器学习面试应该了解哪些理论知识？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#96-标准化与归一化的区别？机器学习-ML基础-易"><span class="toc-number">0.0.99.</span> <span class="toc-text">96. 标准化与归一化的区别？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#97-随机森林如何处理缺失值？机器学习-ML模型-中"><span class="toc-number">0.0.100.</span> <span class="toc-text">97. 随机森林如何处理缺失值？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#98-随机森林如何评估特征重要性？机器学习-ML模型-中"><span class="toc-number">0.0.101.</span> <span class="toc-text">98. 随机森林如何评估特征重要性？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#99-优化Kmeans？机器学习-ML模型-中"><span class="toc-number">0.0.102.</span> <span class="toc-text">99. 优化Kmeans？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#100-KMeans初始类簇中心点的选取。机器学习-ML模型-中"><span class="toc-number">0.0.103.</span> <span class="toc-text">100. KMeans初始类簇中心点的选取。机器学习 ML模型 中</span></a></li></ol></li></ol></li></ol>
		   </div>
		   <script type="text/javascript">
			function showToc(){
				var toc_article = document.getElementById("toc-article");
				var show_toc_btn = document.getElementById("show-toc-btn");
				toc_article.setAttribute("style","display:block");
				show_toc_btn.setAttribute("style","display:none");
				};
			function showBtn(){
				var toc_article = document.getElementById("toc-article");
				var show_toc_btn = document.getElementById("show-toc-btn");
				toc_article.setAttribute("style","display:none");
				show_toc_btn.setAttribute("style","display:block");
				};
		   </script>
		     
		<!-- 目录内容结束 -->
	
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>　　为了求职笔试面试，需恶补基础、算法原理，于是仔细研读了七月在线发布的BAT机器学习面试1000题系列，也添加了一些自己的理解或来自其他博客的答案，以下内容均来自<a href="https://blog.csdn.net/v_JULY_v/article/details/78121924" target="_blank" rel="noopener">BAT机器学习面试1000题系列</a>。该文为本人的阅读笔记，主要是为了记忆和自查。
　　</p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><pre><code>July我又回来了。

之前本博客整理过数千道微软等公司的面试题，侧重数据结构、算法、海量数据处理，详见：微软面试100题系列，今17年，近期和团队整理BAT机器学习面试1000题系列，侧重机器学习、深度学习。我们将通过这个系列索引绝大部分机器学习和深度学习的笔试面试题、知识点，它将更是一个足够庞大的机器学习和深度学习面试库/知识库，通俗成体系且循序渐进。

此外，有四点得强调下：
</code></pre><p>　　虽然本系列主要是机器学习、深度学习相关的考题，其他类型的题不多，但不代表应聘机器学习或深度学习的岗位时，公司或面试官就只问这两项，虽说是做数据或AI相关，但基本的语言（比如Python）、编码coding能力（对于开发，编码coding能力怎么强调都不过分，比如最简单的手写快速排序、手写二分查找）、数据结构、算法、计算机体系结构、操作系统、概率统计等等也必须掌握。对于数据结构和算法，一者 重点推荐前面说的微软面试100题系列（后来这个系列整理成了新书《编程之法：面试和算法心得》），二者 多刷leetcode，看1000道题不如实际动手刷100道。<br>　　本系列会尽量让考察同一个部分（比如同是模型/算法相关的）、同一个方向（比如同是属于最优化的算法）的题整理到一块，为的是让大家做到举一反三、构建完整知识体系，在准备笔试面试的过程中，通过懂一题懂一片。<br>　　本系列每一道题的答案都会确保逻辑清晰、通俗易懂（当你学习某个知识点感觉学不懂时，十有八九不是你不够聪明，十有八九是你所看的资料不够通俗、不够易懂），如有更好意见，欢迎在评论下共同探讨。<br>　　关于如何学习机器学习，最推荐机器学习集训营系列。从Python基础、数据分析、爬虫，到数据可视化、spark大数据，最后实战机器学习、深度学习等一应俱全。<br>    另，本系列会长久更新，直到上千道、甚至数千道题，欢迎各位于评论下留言分享你在自己笔试面试中遇到的题，或你在网上看到或收藏的题，共同分享帮助全球更多人，thanks。</p>
<h2 id="BAT机器学习面试1000题系列"><a href="#BAT机器学习面试1000题系列" class="headerlink" title="BAT机器学习面试1000题系列"></a><strong>BAT机器学习面试1000题系列</strong></h2><a id="more"></a>
<h5 id="1-请简要介绍下SVM。-机器学习-ML模型-易"><a href="#1-请简要介绍下SVM。-机器学习-ML模型-易" class="headerlink" title="1. 请简要介绍下SVM。 机器学习 ML模型 易"></a>1. 请简要介绍下SVM。 机器学习 ML模型 易</h5><p>　　SVM，全称是support vector machine，中文名叫支持向量机。SVM是一个面向数据（特征空间）的分类算法，它的目标是为确定一个分类超平面（间隔最大化），从而将不同的数据分隔开。<br>　　<strong>线性可分支持向量机</strong>：训练数据线性可分，通过硬间隔最大化，训练得到线性分类器。<br>　　<strong>线性支持向量机</strong>：训练数据近似线性可分，通过软间隔最大化，也可以学习得到线性分类器。<br>　　<strong>线性不可分支持向量机</strong>：训练数据线性不可分，通过核技巧 + 软间隔最大化，学习非线性支持向量机。<br>　　《统计学习方法》$P_{96}$-$p_{135}$<br>　　<a href="https://blog.csdn.net/v_JULY_v/article/details/7624837" target="_blank" rel="noopener">支持向量机通俗导论（理解SVM的三层境界）</a><br>　　<a href="https://blog.csdn.net/sinat_35512245/article/details/54984251" target="_blank" rel="noopener">机器学习之深入理解SVM</a><br>　　<a href="http://www.julyedu.com/video/play/18/429" target="_blank" rel="noopener">纯白板手推SVM</a></p>
<h5 id="2-请简要介绍下Tensorflow的计算图。-深度学习-DL框架-中"><a href="#2-请简要介绍下Tensorflow的计算图。-深度学习-DL框架-中" class="headerlink" title="2. 请简要介绍下Tensorflow的计算图。 深度学习 DL框架 中"></a>2. 请简要介绍下Tensorflow的计算图。 深度学习 DL框架 中</h5><p>　　@寒小阳：Tensorflow是一个通过<strong>计算图</strong>的形式来表述计算的编程系统，计算图也叫<strong>数据流图</strong>，可以把计算图看做是一种有向图，Tensorflow中的每一个<strong>计算</strong>（op）都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系。<br>　　Tensorflow一般分为两部分：构造计算流图部分 + 通过session输入数据执行构造图中的计算。<br>　　TF python库中默认有一个计算图（default graph, tf.get_default_graph() 调用），也可以自定义计算图（tf.Graph()）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=x*y;b=a+z;c=tf.reduce_sum(b)</span><br></pre></td></tr></table></figure></p>
<p>　　<img src="graph.jpg" alt="&quot;graph.jpg&quot;"> <img src="flow.gif" alt="&quot;flow.gif&quot;"><br>　　<a href="https://www.bilibili.com/video/av9156347?from=search&amp;seid=1176851659192037373" target="_blank" rel="noopener">CS 20SI: Tensorflow for Deep Learning Research</a><br>　　<a href="https://blog.csdn.net/piaoxuezhong/article/details/78897186" target="_blank" rel="noopener">tensorflow学习笔记（1）如何高效地学习TensorFlow（附链接）</a></p>
<h5 id="3-在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？-机器学习-ML模型-中"><a href="#3-在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？-机器学习-ML模型-中" class="headerlink" title="3. 在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？ 机器学习 ML模型 中"></a>3. 在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？ 机器学习 ML模型 中</h5><p>　　<strong>欧氏距离</strong>，最常见的两点之间或多点之间的距离表示法，又称之为欧几里得度量、L2距离，它定义于欧几里得空间中，如点 x = (x1,…,xn) 和 y = (y1,…,yn) 之间的距离为：<br>　　<script type="math/tex">d(x,y) =\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + ...+(x_n - y_n)^2} = \sqrt{\sum_{i=1}^n(x_i-y_i)^2}</script><br>　　欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各<strong>指标</strong>或各<strong>变量量纲</strong>）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，欧氏距离适用于向量各分量的度量标准统一的情况。<em>欧氏距离可用于<strong>任何空间的距离计算</strong>问题(无坐标空间限制)。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。</em><br>　　<strong>曼哈顿距离</strong>，我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。例如在平面上，坐标（x1, y1）的点P1与坐标（x2, y2）的点P2的曼哈顿距离为：$|x_1 - x_2| + |y_1 - y_2|$，要注意的是，曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。当坐标轴变动时，点间的距离就会不同。通俗来讲，想象你在曼哈顿要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。而实际驾驶距离就是这个“<strong>曼哈顿距离</strong>”，这也是曼哈顿距离名称的来源， 同时，曼哈顿距离也称为城市<strong>街区距离</strong>(City Block distance)。<br>　　曼哈顿距离和欧式距离一般用途不同，无相互替代性。<em>k-means或kNN中，距离的选择也是一个可选超参数</em>。另，关于各种距离的比较参看《<a href="https://blog.csdn.net/v_july_v/article/details/8203674" target="_blank" rel="noopener">从K近邻算法、距离度量谈到KD树、SIFT+BBF算法</a>》。</p>
<h5 id="4-CNN的卷积核是单层的还是多层的？-深度学习-DL模型-中"><a href="#4-CNN的卷积核是单层的还是多层的？-深度学习-DL模型-中" class="headerlink" title="4. CNN的卷积核是单层的还是多层的？ 深度学习 DL模型 中"></a>4. CNN的卷积核是单层的还是多层的？ 深度学习 DL模型 中</h5><p>　　@AntZ：卷积运算的定义和理解可以看下这篇文章《<a href="http://blog.csdn.net/v_july_v/article/details/51812459" target="_blank" rel="noopener">CNN笔记：通俗理解卷积神经网络</a>》，在CNN中,卷积计算属于离散卷积, 本来需要卷积核的权重矩阵旋转180度(<em>相关与卷积</em>), 但我们并不需要旋转前的权重矩阵形式, 故直接用旋转后权重矩阵作为卷积核表达, 这样的好处就离散卷积运算变成了矩阵点积运算。<br>　　一般而言，深度卷积网络是一层又一层的。层的本质是特征图, 存贮输入数据或其中间表示值。一组卷积核则是联系前后两层的网络参数表达体, 训练的目标就是每个<strong>卷积核的权重参数组</strong>。<br>　　描述网络模型中某层的厚度，通常用名词通道channel数或者特征图feature map数。不过人们更习惯把作为数据输入的前层的厚度称之为<strong>通道数</strong>（比如RGB三色图层称为输入通道数为3），把作为卷积输出的后层的厚度称之为<strong>特征图数</strong>。<br>　　卷积核(filter)一般是3D多层的，除了面积参数, 比如3x3之外, 还有厚度参数H（2D的视为厚度1). 还有一个属性是卷积核的个数N。<br>　　<strong>卷积核的厚度H</strong>, 一般等于前层厚度M(输入通道数或feature map数). 特殊情况M &gt; H。<br>　　<strong>卷积核的个数N</strong>, 一般等于后层厚度(后层feature maps数，因为相等所以也用N表示)。<br>　　<strong>卷积核的大小K</strong>, 一般为奇数大小（３, ５, ７）的正方形模板。<br>　　卷积核通常从属于后层，为后层提供了各种查看前层特征的视角，这个视角是自动形成的。<em>一层的参数为：H x K x K x N个，输出N个feature map</em><br>　　卷积核厚度等于1时为2D卷积，也就是平面对应点分别相乘然后把结果加起来，相当于点积运算. 各种2D卷积动图可以看<a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="noopener">这里</a><br>　　卷积核厚度大于1时为3D卷积(depth-wise)，每片平面分别求2D卷积，然后把每片卷积结果加起来，作为3D卷积结果；1x1卷积属于3D卷积的一个特例(point-wise)，有厚度无面积, 直接把每层单个点相乘再相加。<br>　　归纳之，卷积的意思就是把一个区域，不管是一维线段，二维方阵，还是三维长方块，全部按照卷积核的维度形状，从输入挖出同样维度形状, 对应逐点相乘后求和，浓缩成一个标量值也就是降到零维度，作为输出到一个特征图的一个点的值. 这个很像渔夫收网。</p>
<blockquote>
<p>　　<br>　　可以比喻一群渔夫坐一个渔船撒网打鱼，鱼塘是多层水域，每层鱼儿不同。<br>　　船每次移位一个stride到一个地方，每个渔夫撒一网，得到收获，然后换一个距离stride再撒，如此重复直到遍历鱼塘。<br>　　A渔夫盯着鱼的品种，遍历鱼塘后该渔夫描绘了鱼塘的鱼品种分布；<br>　　B渔夫盯着鱼的重量，遍历鱼塘后该渔夫描绘了鱼塘的鱼重量分布；<br>　　还有N-2个渔夫，各自兴趣各干各的；<br>　　最后得到N个特征图，描述了鱼塘的一切！<br>　　2D卷积表示渔夫的网就是带一圈浮标的渔网，只打上面一层水体的鱼；<br>　　3D卷积表示渔夫的网是多层嵌套的渔网，上中下层水体的鱼儿都跑不掉；<br>　　1x1卷积可以视为每次移位stride，甩钩钓鱼代替了撒网；</p>
</blockquote>
<p>　　下面解释一下特殊情况的 M &gt; H：<br>　　实际上，除了输入数据的通道数比较少之外，中间层的feature map数很多，这样中间层算卷积会累死计算机（鱼塘太深，每层鱼都打，需要的鱼网太重了）。所以很多深度卷积网络把全部通道/特征图划分一下，每个卷积核只看其中一部分（渔夫A的渔网只打捞深水段，渔夫B的渔网只打捞浅水段）。这样整个深度网络架构是横向开始分道扬镳了，到最后才又融合。这样看来，很多网络模型的架构不完全是突发奇想，而是是被参数计算量逼得。特别是现在需要在移动设备上进行AI应用计算(也叫推断), 模型参数规模必须更小, 所以出现很多减少握手规模的卷积形式, 现在主流网络架构大都如此。比如AlexNet：</p>
<p><img src="AlexNet.jpg" alt="&quot;AlexNet.jpg&quot;"><br>　　另，附<a href="http://www.itmian4.com/thread-7042-1-1.html" target="_blank" rel="noopener">百度2015校招机器学习笔试题</a></p>
<h5 id="5-关于LR。-机器学习-ML模型-难"><a href="#5-关于LR。-机器学习-ML模型-难" class="headerlink" title="5. 关于LR。 机器学习 ML模型 难"></a>5. 关于LR。 机器学习 ML模型 难</h5><p>　　@rickjin：把LR从头到脚都给讲一遍。建模，现场数学推导，每种解法的原理，正则化，LR和maxent模型啥关系，lr为啥比线性回归好。有不少会背答案的人，问逻辑细节就糊涂了。原理都会? 那就问工程，并行化怎么做，有几种并行化方式，读过哪些开源的实现。还会，那就准备收了吧，顺便逼问LR模型发展历史。<br><img src="lrloss.jpg" alt="lrloss.jpg"><br>　　另外，下面资料可作学习参考：《统计学习方法$P_{77}-P_{94}$》、<a href="http://blog.csdn.net/cyh_24/article/details/50359055" target="_blank" rel="noopener">Logistic Regression 的前世今生（理论篇）</a>、<a href="http://blog.csdn.net/zouxy09/article/details/20319673" target="_blank" rel="noopener">机器学习算法与Python实践之（七）逻辑回归（Logistic Regression）</a>。</p>
<h5 id="6-（过拟合）overfitting怎么解决？机器学习-ML基础-中"><a href="#6-（过拟合）overfitting怎么解决？机器学习-ML基础-中" class="headerlink" title="6. （过拟合）overfitting怎么解决？机器学习 ML基础 中"></a>6. （过拟合）overfitting怎么解决？机器学习 ML基础 中</h5><p>　　@AntZ: overfitting就是<strong>过拟合</strong>, 也就是随着训练过程的进行，模型复杂度增加，在training data上的error渐渐减小，但是在验证集上的error却反而渐渐增大——因为训练出来的网络过拟合了训练集, 对训练集外的数据却不work, 这称之为<strong>泛化</strong>(generalization)性能不好。泛化性能是训练的效果评价中的首要目标，没有良好的泛化，就等于南辕北辙, 一切都是无用功。<br>　　<strong>产生原因</strong>：算法的学习能力过强；一些假设条件（如样本独立同分布）可能是不成立的；训练样本过少不能对整个空间进行分布估计。 　　<br>　　<strong>解决方法</strong>：<strong>dropout、regularization、batch normalizatin、Early stopping、数据扩增（Data augmentatio）、模型融合、交叉验证、特征选择/特征降维</strong></p>
<h5 id="7-LR和SVM的联系与区别。机器学习-ML模型-中"><a href="#7-LR和SVM的联系与区别。机器学习-ML模型-中" class="headerlink" title="7. LR和SVM的联系与区别。机器学习 ML模型 中"></a>7. LR和SVM的联系与区别。机器学习 ML模型 中</h5><p>　　@朝阳在望，<strong>联系</strong>：<br>　　1、LR和SVM都可以处理分类问题，且一般都用于处理线性二分类问题（在改进的情况下可以处理多分类问题）<br>　　2、两个方法都可以增加不同的正则化项，如l1、l2等等。所以在很多实验中，两种算法的结果是很接近的。<br>　　<em>3、均属于有监督判别模型。</em><br>　　<strong>区别</strong>：<br>　　1、LR是参数模型，SVM是非参数模型。<br>　　2、从目标函数来看，区别在于逻辑回归采用的是<strong>logistical loss</strong>，SVM采用的是<strong>hinge loss + L2</strong>，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。<br>　　3、SVM的处理方法是只考虑<strong>support vectors</strong>（边界线局部的点），也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。<br>　　4、逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。<br>　　5、logic 能做的 svm能做，但可能在准确率上有问题，svm能做（核方法）的logic有的做不了。来源：<a href="http://blog.csdn.net/timcompp/article/details/62237986" target="_blank" rel="noopener">机器学习常见面试问题（一）</a><br>　　6、LR输出为概率，SVM输出为类别。</p>
<h5 id="8-说说你知道的核函数。机器学习-ML基础-易"><a href="#8-说说你知道的核函数。机器学习-ML基础-易" class="headerlink" title="8. 说说你知道的核函数。机器学习 ML基础 易"></a>8. 说说你知道的核函数。机器学习 ML基础 易</h5><p>　　通常人们会从一些常用的核函数中选择（根据问题和数据的不同，选择不同的参数，实际上就是得到了不同的核函数），例如：<br>　　- <strong>多项式核</strong>：$K(x, z) = (x\cdot z + 1)^p$，对应的SVM是一个p次多项式分类器。分类决策函数为：$f(x) = sign(\sum_{i=1}^{N_S}a_{i}^{\ast}y_i(x_i \cdot  x+1)^p + b^\ast)$<br>　　- <strong>高斯核</strong>:$K(x, z) = exp(-\frac{||x-z||^2}{2\sigma^2})$，对应的SVM是高斯径向基函数分类器，分类决策函数为：$f(x) = sign(\sum_{i=1}^{N_S}a_{i}^{\ast}y_iexp(-\frac{||x-z||^2}{2\sigma^2}) + b^\ast)$，这个核就是最可以将原始空间映射为无穷维空间的那个家伙。不过，如果$\sigma$选得很大的话，高次特征上的权重实际上衰减得非常快，所以实际上（数值上近似一下）相当于一个低维的子空间；反过来，如果$\sigma$选得很小，则可以将任意的数据映射为线性可分——当然，这并不一定是好事，因为随之而来的可能是非常严重的过拟合问题。不过，总的来说，通过调控参数$\sigma$，高斯核实际上具有相当高的灵活性，也是使用最广泛的核函数之一。下图所示的例子便是把低维线性不可分的数据通过高斯核函数映射到了高维空间：<br>　　<img src="gaussian.jpg" alt="gaussian.jpg"><br>　　- <strong>线性核</strong>:$K(x_1,x_2) = (x_1, x_2)$，这实际上就是原始空间中的内积。这个核存在的主要目的是使得“映射后空间中的问题”和“映射前空间中的问题”两者在形式上统一起来了(意思是说，咱们有的时候，写代码，或写公式的时候，只要写个模板或通用表达式，然后再代入不同的核，便可以了，于此，便在形式上统一了起来，不用再分别写一个线性的，和一个非线性的)。</p>
<h5 id="9-LR与线性回归的区别与联系。机器学习-ML模型-中等"><a href="#9-LR与线性回归的区别与联系。机器学习-ML模型-中等" class="headerlink" title="9. LR与线性回归的区别与联系。机器学习 ML模型 中等"></a>9. LR与线性回归的区别与联系。机器学习 ML模型 中等</h5><p>　　@AntZ: LR工业上一般指<strong>Logistic Regression</strong>(逻辑回归)而不是Linear Regression(线性回归). LR在线性回归的实数范围输出值上施加sigmoid函数将值收敛到0~1范围, 其目标函数也因此从<strong>差平方和函数</strong>变为<strong>对数损失函数</strong>, 以提供最优化所需导数（sigmoid函数是softmax函数的二元特例, 其导数均为函数值的$f(x)\cdot (1-f(x))$形式）。请注意, LR往往是解决二元0/1分类问题的, 只是它和线性回归耦合太紧, 不自觉也冠了个回归的名字(马甲无处不在). 若要求多元分类,就要把sigmoid换成大名鼎鼎的softmax了。<br>　　@nishizhen：个人感觉逻辑回归和线性回归首先都是广义的线性回归，其次经典线性模型的优化目标函数是<strong>最小二乘</strong>，而逻辑回归则是<strong>似然函数</strong>，另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围，需要在[0,1]。逻辑回归就是一种减小预测范围，将预测值限定为[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。<br>　　@乖乖癞皮狗：逻辑回归的模型本质上是一个线性回归模型，逻辑回归都是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。</p>
<h5 id="10-请问（决策树、Random-Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习-ML模型-难"><a href="#10-请问（决策树、Random-Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习-ML模型-难" class="headerlink" title="10. 请问（决策树、Random Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习 ML模型 难"></a>10. 请问（决策树、Random Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习 ML模型 难</h5><p>　　@AntZ:集成学习的集成对象是学习器. <strong>Bagging</strong>和<strong>Boosting</strong>属于集成学习的两类方法. Bagging方法有放回地采样同数量样本训练每个学习器, 然后再一起集成(简单投票); Boosting方法使用全部样本(可调权重)依次训练每个学习器, 迭代集成(平滑加权)。<br>　　<strong>决策树</strong>属于最常用的学习器, 其学习过程是从根建立树, 也就是如何决策叶子节点分裂. ID3/C4.5决策树用<strong>信息熵</strong>计算最优分裂, CART决策树用<strong>基尼指数</strong>计算最优分裂, xgboost每颗决策树模型使用<strong>二阶泰勒展开系数</strong>计算最优分裂。<br>　　下面所提到的学习器都是决策树:<br>　　<strong>Bagging方法</strong>: <em>降低方差（variance）</em><br>　　学习器间不存在强依赖关系, 学习器可并行训练生成, 集成方式一般为投票;<br>　　Random Forest属于Bagging的代表, 放回抽样, 每个学习器随机选择部分特征去优化;<br>　　<strong>Boosting方法</strong>: <em>降低偏差（bias）</em><br>　　学习器之间存在强依赖关系、必须串行生成, 集成方式为加权和;<br>　　Adaboost属于Boosting, 采用<strong>指数损失函数</strong>替代原本分类任务的0/1损失函数;<br>　　<em>区别：样本量、样本权重、决策方法、可并行性</em><br>　　xgboost属于Boosting的集大成者, 对函数<strong>残差</strong>近似值进行梯度下降, 迭代时利用了<strong>二阶梯度</strong>信息, 集成模型可分类也可回归. 由于它可在特征粒度上并行计算, 结构风险和工程实现都做了很多优化, 泛化, 性能和扩展性都比GBDT要好。<br>　　关于决策树，这里有篇《<a href="http://blog.csdn.net/v_july_v/article/details/7577684" target="_blank" rel="noopener">决策树算法</a>》。而随机森林Random Forest是一个包含多个决策树的分类器。至于AdaBoost，则是英文”Adaptive Boosting”（自适应增强）的缩写，关于AdaBoost可以看下这篇文章《Adaboost 算法的原理与推导》。GBDT（Gradient Boosting Decision Tree），即梯度上升决策树算法，相当于融合决策树和梯度上升boosting算法。<br>　　@Xijun LI：xgboost类似于gbdt的优化版，不论是精度还是效率上都有了提升。与gbdt相比，具体的优点有：<br>　　1.损失函数是用泰勒展式二项逼近，而不是像gbdt里的就是一阶导数<br>　　2.对树的结构进行了正则化约束，防止模型过度复杂，降低了过拟合的可能性<br>　　3.节点分裂的方式不同，gbdt是用的gini系数，xgboost是经过优化推导后的<br>　　更多详见：<a href="https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener">集成学习总结</a></p>
<h5 id="11-为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难"><a href="#11-为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难" class="headerlink" title="11. 为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难"></a>11. 为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难</h5><p>　　@AntZ：xgboost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准. 使用泰勒展开取得函数做自变量的二阶导数形式, 可以在不选定损失函数具体形式的情况下, 仅仅依靠输入数据的值就可以进行叶子分裂优化计算, 本质上也就把<strong>损失函数的选取</strong>和<strong>模型算法优化/参数选择</strong>分开了. 这种去耦合增加了xgboost的适用性, 使得它按需选取损失函数, 可以用于分类, 也可以用于回归。</p>
<h5 id="12-xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习-ML模型-难"><a href="#12-xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习-ML模型-难" class="headerlink" title="12. xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习 ML模型 难"></a>12. xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习 ML模型 难</h5><p>　　@AntZ：xgboost在训练的过程中给出各个特征的增益评分，最大增益的特征会被选出来作为分裂依据, 从而记忆了每个特征对在模型训练时的重要性 — 从根到叶子中间节点涉及某特征的次数作为该特征重要性排序.<br>　　xgboost属于boosting集成学习方法, 样本是<strong>不放回</strong>的, 因而每轮计算样本不重复. 另一方面, xgboost支持<strong>子采样</strong>, 也就是每轮计算可以不使用全部样本, 以减少过拟合. 进一步地, xgboost还有<strong>列采样</strong>, 每轮计算按百分比随机采样一部分特征, 既提高计算速度又减少过拟合。</p>
<h5 id="13-谈谈判别式模型和生成式模型？机器学习-ML基础-易"><a href="#13-谈谈判别式模型和生成式模型？机器学习-ML基础-易" class="headerlink" title="13. 谈谈判别式模型和生成式模型？机器学习 ML基础 易"></a>13. 谈谈判别式模型和生成式模型？机器学习 ML基础 易</h5><p>　　<strong>判别方法</strong>：由数据直接学习决策函数 Y = f（X），或者由条件分布概率 P（Y|X）作为预测模型，即判别模型。<br>　　<strong>生成方法</strong>：由数据学习联合概率密度分布函数 P（X,Y）,然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型。<br>　　由生成模型可以得到判别模型，但由判别模型得不到生成模型。<br>　　常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场（CRF）<br>　　常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机</p>
<h5 id="14-L1和L2的区别。机器学习-ML基础-易"><a href="#14-L1和L2的区别。机器学习-ML基础-易" class="headerlink" title="14. L1和L2的区别。机器学习 ML基础 易"></a>14. L1和L2的区别。机器学习 ML基础 易</h5><p>　　L1范数（L1 norm）是指向量中各个元素绝对值之和，也有个美称叫“<strong>稀疏规则算子</strong>”（Lasso regularization）。 比如 向量A=[1，-1，3]， 那么A的L1范数为 |1|+|-1|+|3|.<br>　　简单总结一下就是：<br>　　L1范数: 为x向量各个元素绝对值之和。<br>　　L2范数: 为x向量各个元素平方和的1/2次方，L2范数又称Euclidean范数或者Frobenius范数<br>　　Lp范数: 为x向量各个元素绝对值p次方和的1/p次方.<br>　　在支持向量机学习过程中，L1范数实际是一种对于成本函数求解最优的过程，因此，L1范数正则化通过向成本函数中添加L1范数，使得学习得到的结果满足<strong>稀疏化</strong>，从而方便人类提取特征。<br>　　L1范数可以使<strong>权值稀疏</strong>，方便特征提取。<br>　　L2范数可以<strong>防止过拟合</strong>，提升模型的泛化能力。<br>　　@AntZ: L1和L2的差别，为什么一个让绝对值最小，一个让平方最小，会有那么大的差别呢？看导数一个是1一个是w便知, 在靠进零附近, L1以匀速下降到零, 而L2则完全停下来了. 这说明L1是将不重要的特征(或者说, 重要性不在一个数量级上)尽快剔除, L2则是把特征贡献尽量压缩最小但不至于为零。 两者一起作用（Elastic Net）, 就是把重要性在一个数量级(重要性最高的)的那些特征一起平等共事(简言之, 不养闲人也不要超人)。</p>
<h5 id="15-L1和L2正则先验分别服从什么分布。机器学习-ML基础-易"><a href="#15-L1和L2正则先验分别服从什么分布。机器学习-ML基础-易" class="headerlink" title="15. L1和L2正则先验分别服从什么分布。机器学习 ML基础 易"></a>15. L1和L2正则先验分别服从什么分布。机器学习 ML基础 易</h5><p>　　@齐同学：面试中遇到的，L1和L2正则先验分别服从什么分布，L1是<strong>拉普拉斯分布</strong>，L2是<strong>高斯分布</strong>。<br>　　@AntZ: 先验就是优化的起跑线, 有先验的好处就是可以在较小的数据集中有良好的泛化性能，当然这是在先验分布是接近真实分布的情况下得到的了，从信息论的角度看，向系统加入了正确先验这个信息，肯定会提高系统的性能。<br>　　对参数引入高斯正态先验分布相当于L2正则化, 这个大家都熟悉，如下图(左)：$f(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$,对参数引入拉普拉斯先验等价于 L1正则化, 如下图(右)：$f(x| \mu, b) = \frac{1}{2b}e^{-\frac{|x-\mu|}{b}}$</p>
<p><center><img src="gaussianfb.jpg" width="30%" height="30%"> <img src="laplacefb.jpg" width="30%" height="30%"></center><br>　　从上面两图可以看出, L2先验趋向零周围, L1先验趋向零本身。</p>
<h5 id="16-CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习-DL应用-难"><a href="#16-CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习-DL应用-难" class="headerlink" title="16. CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习 DL应用 难"></a>16. CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习 DL应用 难</h5><p>　　@许韩，来源：<a href="https://zhuanlan.zhihu.com/p/25005808" target="_blank" rel="noopener">深度学习岗位面试问题整理笔记</a><br>　　- 以上几个不相关问题的相关性在于，都存在<strong>局部与整体</strong>的关系，由低<strong>层次的特征经过组合</strong>，组成高层次的特征，并且得到不同特征之间的空间相关性。如下图：低层次的直线／曲线等特征，组合成为不同的形状，最后得到汽车的。<br><img src="cnn1.jpg" alt="cnn1.jpg"><br>　　- CNN抓住此共性的手段主要有四个：<strong>局部连接</strong>／<strong>权值共享</strong>／<strong>池化操作</strong>／<strong>多层次结构</strong>。<br>　　- CNN抓住此共性的手段主要有四个：局部连接／权值共享／池化操作／多层次结构。<br>　　局部连接使网络可以提取数据的局部特征；权值共享大大降低了网络的训练难度，一个Filter只提取一个特征，在整个图片（或者语音／文本） 中进行卷积；池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。如下图：<br><img src="cnn2.jpg" alt="cnn2.jpg"></p>
<h5 id="17-说一下Adaboost，权值更新公式。当弱分类器是-G-m-时，每个样本的的权重是-w-1，w-2…-，请写出最终的决策公式。机器学习-ML模型-难"><a href="#17-说一下Adaboost，权值更新公式。当弱分类器是-G-m-时，每个样本的的权重是-w-1，w-2…-，请写出最终的决策公式。机器学习-ML模型-难" class="headerlink" title="17. 说一下Adaboost，权值更新公式。当弱分类器是$G_m$时，每个样本的的权重是$w_1，w_2…$，请写出最终的决策公式。机器学习 ML模型 难"></a>17. 说一下Adaboost，权值更新公式。当弱分类器是$G_m$时，每个样本的的权重是$w_1，w_2…$，请写出最终的决策公式。机器学习 ML模型 难</h5><p>　　给定一个训练数据集$T={(x_1,y_1), (x_2,y_2)…(x_N,y_N)}$，其中实例$x \in \mathcal{X}$，而实例空间$\mathcal{X} \subset \mathbb{R}^n$，$y_i$属于标记集合{-1,+1}，Adaboost的目的就是从训练数据中学习一系列<strong>弱分类器</strong>或<strong>基本分类器</strong>，然后将这些弱分类器组合成(权值求和)一个强分类器 <em>主要做法是增加难分类样本权重，减小易分类样本权值；加大错误率小的弱分类权值，使其在表决中其较大的作用，减小分类错误率大的弱分类器权值，使其在表决中其较小作用</em>。<br>　　Adaboost的<strong>算法流程如下</strong>：<br>　　<strong>步骤1</strong>. <strong>初始化样本权重</strong>。首先，初始化训练数据的权值分布。每一个训练样本最开始时都被赋予相同的权值：1/N。</p>
<script type="math/tex; mode=display">D_1 = (w_{11},..., w_{1i}, ..., w_{1N}), w_{1i} = \frac{1}{N}, i=1,2,...,N</script><p>　　<strong>步骤2</strong>. <strong>进行多轮迭代</strong>，用$m = 1,2, …, m$表示迭代的第多少轮<br>　　a).使用具有权值分布$D_m$的训练数据集学习，得到基本分类器（选取让误差率最低的阈值来设计基本分类器）：</p>
<script type="math/tex; mode=display">G_m(x):\mathcal{X} \to \{-1,1\}</script><p>　　b).计算$G_m(x)$在训练集上的分类误差。</p>
<script type="math/tex; mode=display">e_m = P(G_m(x_i) \neq y_i) = \sum_{i=1}^{N}w_{mi}I(G_m(x_i) \neq y_i)</script><blockquote>
<p>由上述式子可知，$G_m(x)$在训练数据集上的误差率em就是被Gm(x)误分类样本的权值之和。</p>
</blockquote>
<p>　　c).计算$G_m(x)$的系数，$a_m$表示$G_m(x)$在最终分类器中的重要程度（目的：得到基本分类器在最终分类器中所占的权重）：</p>
<script type="math/tex; mode=display">a_m = \frac{1}{2}\log{\frac{1-e_m}{e_m}}</script><blockquote>
<p>由上述式子可知，$e_m &lt;= 1/2$时，$a_m &gt;= 0$，且$a_m$随着$e_m$的减小而增大，意味着分类误差率越小的基本分类器在最终分类器中的作用越大。</p>
</blockquote>
<p>　　d).更新训练数据集的权值分布（目的：得到样本的新的权值分布），用于下一轮迭代</p>
<script type="math/tex; mode=display">D_{m+1} = (w_{m+1,1},...,w_{m+1,i},...,w_{m+1, N}),
 w_{m+1,i} = \frac{w_{mi}}{Z_m} \exp (-a_my_iG_m(x_i)), i=1,2,...,N</script><blockquote>
<p>使得被基本分类器$G_m(x)$误分类样本的权值增大，而被正确分类样本的权值减小。就这样，通过这样的方式，AdaBoost方法能“重点关注”或“聚焦于”那些<strong>较难分的样本上</strong></p>
</blockquote>
<p>　　其中，$Z＿m$是规范化因子，使得$D_{m+1}$成为一个概率分布：</p>
<script type="math/tex; mode=display">Z_m = \sum_{i=1}^{N}w_{mi} \exp (-a_my_iG_m(x_i))</script><p>　　<strong>步骤3</strong>. <strong>组合各个弱分类器</strong>。</p>
<script type="math/tex; mode=display">f(x) = \sum_{i=1}^{M}a_mG_m(x)</script><p>　　从而得到最终分类器，如下：</p>
<script type="math/tex; mode=display">G(x) = sign(f(x)) = sign(\sum_{i=1}^{M}a_mG_m(x))</script><p>　　更多请查看此文：《<a href="http://blog.csdn.net/v_july_v/article/details/40718799" target="_blank" rel="noopener">Adaboost算法的原理与推导</a>》</p>
<h5 id="18-LSTM结构推导，为什么比RNN好？-深度学习DL模型-难"><a href="#18-LSTM结构推导，为什么比RNN好？-深度学习DL模型-难" class="headerlink" title="18. LSTM结构推导，为什么比RNN好？ 深度学习DL模型 难"></a>18. LSTM结构推导，为什么比RNN好？ 深度学习DL模型 难</h5><p>　　推导<strong>forget gate，input gate，cell state， hidden information</strong>等的变化；因为LSTM有进有出且当前的cell informaton是通过input gate控制之后叠加的，RNN是叠乘，因此LSTM可以防止<strong>梯度消失或者爆炸</strong>。<br>　　《<a href="">深度理解LSTM</a>》</p>
<h5 id="19-根据谷歌一员工写的How-to-Write-a-Spelling-Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习-ML应用-难"><a href="#19-根据谷歌一员工写的How-to-Write-a-Spelling-Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习-ML应用-难" class="headerlink" title="19. 根据谷歌一员工写的How to Write a Spelling Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习 ML应用 难"></a>19. 根据谷歌一员工写的<a href="http://norvig.com/spell-correct.html" target="_blank" rel="noopener">How to Write a Spelling Corrector</a>显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习 ML应用 难</h5><p>　　用户输入一个单词时，可能拼写正确，也可能拼写错误。如果把拼写正确的情况记做c（代表correct），拼写错误的情况记做w（代表wrong），那么”拼写检查”要做的事情就是：在发生w的情况下，试图推断出c。换言之：已知w，然后在若干个备选方案中，找出可能性最大的那个c，也就是求$P(c|w)$的最大值。而根据贝叶斯定理，有： </p>
<script type="math/tex; mode=display">P(c|w)=\frac{P(w|c)P(c)}{P(w)}</script><p>　　由于对于所有备选的c来说，对应的都是同一个w，所以它们的P(w)是相同的，因此我们只要最大化$P(w|c)P(c)$即可。其中:<br>　　P(c)表示某个正确的词的出现”概率”，它可以用”频率”代替。如果我们有一个足够大的文本库，那么这个<strong>文本库中每个单词的出现频率</strong>，就相当于它的发生概率。某个词的出现频率越高，P(c)就越大。比如在你输入一个错误的词“Julw”时，系统更倾向于去猜测你可能想输入的词是“July”，而不是“Jult”，因为“July”更常见。<br>　　P(w|c)表示在试图拼写c的情况下，出现拼写错误w的概率。为了简化问题，假定两个单词在字形上越接近，就有越可能拼错，P(w|c)就越大。举例来说，相差一个字母的拼法，就比相差两个字母的拼法，发生概率更高。你想拼写单词July，那么错误拼成Julw（相差一个字母）的可能性，就比拼成Jullw高（相差两个字母）。值得一提的是，一般把这种问题称为“<strong>编辑距离</strong>”，参见:<a href="http://blog.csdn.net/v_july_v/article/details/8701148#t4" target="_blank" rel="noopener">]程序员编程艺术第二十八~二十九章：最大连续乘积子串、字符串编辑距离</a>。<br>　　所以，我们比较所有拼写相近的词在文本库中的出现频率，再从中挑出出现频率最高的一个，即是用户最想输入的那个词。具体的计算过程及此方法的缺陷请参见<a href="http://norvig.com/spell-correct.html" target="_blank" rel="noopener">How to Write a Spelling Corrector</a></p>
<h5 id="20-为什么朴素贝叶斯如此“朴素”？机器学习-ML模型-易"><a href="#20-为什么朴素贝叶斯如此“朴素”？机器学习-ML模型-易" class="headerlink" title="20. 为什么朴素贝叶斯如此“朴素”？机器学习 ML模型 易"></a>20. 为什么朴素贝叶斯如此“朴素”？机器学习 ML模型 易</h5><p>　　因为它假定所有的特征在数据集中的作用是<strong>同样重要和独立的</strong>。正如我们所知，这个假设在现实世界中是很不真实的，因此，说朴素贝叶斯真的很“朴素”。</p>
<h5 id="21-请大致对比下plsa和LDA的区别。机器学习-ML模型-中等"><a href="#21-请大致对比下plsa和LDA的区别。机器学习-ML模型-中等" class="headerlink" title="21. 请大致对比下plsa和LDA的区别。机器学习 ML模型 中等"></a>21. 请大致对比下plsa和LDA的区别。机器学习 ML模型 中等</h5><p>　　<strong>pLSA</strong>:主题分布和词分布确定后，以一定的概率$(P(z_k|d_i), P(w_j|z_k))$分别选取具体的主题和词项，生成好文档。而后根据生成好的文档反推其主题分布、词分布时，最终用EM算法（极大似然估计思想）求解出了两个未知但固定的参数的值：(由$P(w_j|z_k)$转换而来)和(由$P(z_k|d_i)$转换而来)。</p>
<ul>
<li>　　文档d产生主题z的概率，主题z产生单词w的概率都是两个固定的值<br>　　举个文档d产生主题z的例子。给定一篇文档d，主题分布是一定的，比如${P(z_i|d), i = 1,2,3 }$可能就是{0.4,0.5,0.1}，表示z1、z2、z3，这3个主题被文档d选中的概率都是个固定的值：$P(z_1|d) = 0.4、P(z_2|d) = 0.5、P(z_3|d) = 0.1$，如下图所示（图截取自沈博PPT上）：<br><img src="plsa.jpg" alt="plsa.jpg"><br>　　<strong>LDA</strong>:但在贝叶斯框架下的LDA中，我们不再认为主题分布（各个主题在文档中出现的概率分布）和词分布（各个词语在某个主题下出现的概率分布）是唯一确定的（而是随机变量），而是有很多种可能。但一篇文档总得对应一个主题分布和一个词分布吧，怎么办呢？LDA为它们弄了两个Dirichlet先验参数，这个Dirichlet先验为某篇文档<strong>随机抽取出某个主题分布和词分布</strong>。</li>
<li>　　文档d产生主题z（准确的说，其实是Dirichlet先验为文档d生成主题分布Θ，然后根据主题分布Θ产生主题z）的概率，主题z产生单词　　　　w的概率都不再是某两个确定的值，而是随机变量。<br>　　还是再次举下文档d具体产生主题z的例子。给定一篇文档d，现在有多个主题z1、z2、z3，它们的主题分布${ P(z_i|d), i = 1,2,3 }$可能是{0.4,0.5,0.1}，也可能是{0.2,0.2,0.6}，即这些主题被d选中的概率都不再认为是确定的值，可能是$P(z_1|d) = 0.4、P(z_2|d) = 0.5、P(z_3|d) = 0.1$，也有可能是$P(z_1|d) = 0.2、P(z_2|d) = 0.2、P(z_3|d) = 0.6$等等，而主题分布到底是哪个取值集合我们不确定（为什么？这就是贝叶斯派的核心思想，把未知参数当作是随机变量，不再认为是某一个确定的值），但其先验分布是<strong>dirichlet分布</strong>，所以可以从无穷多个主题分布中按照dirichlet 先验随机抽取出某个主题分布出来。如下图所示（图截取自沈博PPT上）：<br><img src="lda.jpg" alt="lda.jpg"><br>　　换言之，LDA在pLSA的基础上给这两参数$(P(z_k|d_i), P(w_j|z_k))$加了两个先验分布的参数（贝叶斯化）：一个主题分布的先验分布<strong>Dirichlet分布</strong>$\alpha$，和一个词语分布的先验分布<strong>Dirichlet分布</strong>$\beta$。<br>　　更多请参见：《<a href="http://blog.csdn.net/v_july_v/article/details/41209515" target="_blank" rel="noopener">通俗理解LDA主题模型</a>》<h5 id="22-请简要说说EM算法。机器学习-ML模型-中等"><a href="#22-请简要说说EM算法。机器学习-ML模型-中等" class="headerlink" title="22. 请简要说说EM算法。机器学习 ML模型 中等"></a>22. 请简要说说EM算法。机器学习 ML模型 中等</h5>　　@tornadomeet，本题解析来源：<a href="http://www.cnblogs.com/tornadomeet/p/3395593.html" target="_blank" rel="noopener">机器学习&amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理）</a><br>　　有时候因为样本的产生和隐含变量有关（隐含变量是不能观察的），而求模型的参数时一般采用最大似然估计，由于含有了隐含变量，所以对似然函数参数求导是求不出来的，这时可以采用EM算法来求模型的参数的（对应模型参数个数可能有多个），EM算法一般分为2步：<br>　　<strong>E步</strong>：选取一组参数，求出在该参数下隐含变量的条件概率值；<br>　　<strong>M步</strong>：结合E步求出的隐含变量条件概率，求出似然函数下界函数（本质上是某个期望函数）的最大值。<br>　　重复上面2步直至收敛。公式如下所示：<script type="math/tex; mode=display">E-step:\\
For\ each\ i, set\ Q_i(z^{(i)}):=p(z^{(i)}|x^{(i)}; \theta) \\
M-step:\\ 
set\ \theta:=argmax_\theta \sum_i \sum_{z^{(i)}}Q_i(z^{(i)})log \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}</script>　　M步公式中下界函数的推导过程：<br><img src="em1.png" alt="em1.png"><br>　　EM算法一个常见的例子就是<strong>高斯混合模型</strong>(Gaussian Mixed Model, GMM)模型，每个样本都有可能由k个高斯产生，只不过由每个高斯产生的概率不同而已，因此每个样本都有对应的高斯分布（k个中的某一个），此时的隐含变量就是每个样本对应的某个高斯分布。<br>　　GMM的E步公式如下（计算每个样本对应每个高斯的概率）：<br><img src="gmm.png" alt="gmm.png"><br>　　更具体的计算公式为：<br><img src="gmm_e.png" alt="gmm_e.png"><br>　　M步公式如下(计算每个高斯的比重，均值，方差这3个参数)：<br><img src="gmm_m.png" alt="gmm_m.png"></li>
</ul>
<h5 id="23-KNN中的K如何选取的？机器学习-ML模型-易"><a href="#23-KNN中的K如何选取的？机器学习-ML模型-易" class="headerlink" title="23. KNN中的K如何选取的？机器学习 ML模型 易"></a>23. KNN中的K如何选取的？机器学习 ML模型 易</h5><p>　　关于什么是KNN，可以查看此文：《<a href="http://blog.csdn.net/v_july_v/article/details/8203674" target="_blank" rel="noopener">从K近邻算法、距离度量谈到KD树、SIFT+BBF算法</a>》。KNN中的K值选取对K近邻算法的结果会产生重大影响。如李航博士的一书「统计学习方法」上所说：<br>　　a). 如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；<br>　　b). 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。<br>　　K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。<br>　　在实际应用中，K值一般取一个比较小的数值，例如采用<strong>交叉验证法</strong>（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。 </p>
<h5 id="24-机器学习中，为何要经常对数据做归一化。机器学习-ML基础-中等"><a href="#24-机器学习中，为何要经常对数据做归一化。机器学习-ML基础-中等" class="headerlink" title="24. 机器学习中，为何要经常对数据做归一化。机器学习 ML基础 中等"></a>24. 机器学习中，为何要经常对数据做归一化。机器学习 ML基础 中等</h5><p>　　@zhanlijun，参考链接：<a href="http://www.cnblogs.com/LBSer/p/4440590.html" target="_blank" rel="noopener">为什么一些机器学习模型需要对数据进行归一化？</a><br>　　1）归一化后加快了梯度下降求最优解的速度；2）归一化有可能提高精度。<br>　　常见归一化类型：<strong>线性归一化</strong>、<strong>标准差标准化</strong>、<strong>非线性归一化</strong>。</p>
<h5 id="25-谈谈深度学习中的归一化问题。深度学习-DL基础-易"><a href="#25-谈谈深度学习中的归一化问题。深度学习-DL基础-易" class="headerlink" title="25. 谈谈深度学习中的归一化问题。深度学习 DL基础 易"></a>25. 谈谈深度学习中的归一化问题。深度学习 DL基础 易</h5><p>　　详情参见此视频：<a href="http://www.julyedu.com/video/play/69/686" target="_blank" rel="noopener">深度学习中的归一化</a></p>
<h5 id="26-哪些机器学习算法不需要做归一化处理？机器学习-ML基础-易"><a href="#26-哪些机器学习算法不需要做归一化处理？机器学习-ML基础-易" class="headerlink" title="26. 哪些机器学习算法不需要做归一化处理？机器学习 ML基础 易"></a>26. 哪些机器学习算法不需要做归一化处理？机器学习 ML基础 易</h5><p>　　<strong>概率模型</strong>不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、rf。而像adaboost、svm、lr、KNN、KMeans之类的最优化问题就需要归一化。比如说LR，我有两个特征，一个是(0,1)的，一个是(0,10000)的，这样运用梯度下降时候，损失等高线是一个椭圆的形状，这样我想迭代到最优点，就需要很多次迭代，但是如果进行了归一化，那么等高线就是圆形的，那么SGD就会往原点迭代，需要的迭代次数较少（加快了梯度下降求最优解的速度）。<br>　　另外，注意<strong>树模型</strong>是不能进行梯度下降的，因为树模型是阶跃的，阶跃点是不可导的，并且求导没意义，所以树模型（回归树）寻找最优点事通过寻找最优分裂点完成的。<br>　　@管博士：我理解归一化和标准化主要是为了使计算更方便 比如两个变量的<strong>量纲</strong>不同 可能一个的数值远大于另一个那么他们同时作为变量的时候 可能会造成数值计算的问题，比如说求矩阵的逆可能很不精确 或者梯度下降法的收敛比较困难，还有如果需要计算欧式距离的话可能 量纲也需要调整 所以我估计lr 和 knn 标准化一下应该有好处。至于其他的算法 我也觉得如果变量量纲差距很大的话 先标准化一下会有好处。<br>　　@寒小阳：一般我习惯说树形模型，这里说的概率模型可能是差不多的意思。</p>
<h5 id="27-请简要说说一个完整机器学习项目的流程。机器学习-ML应用-中"><a href="#27-请简要说说一个完整机器学习项目的流程。机器学习-ML应用-中" class="headerlink" title="27. 请简要说说一个完整机器学习项目的流程。机器学习 ML应用 中"></a>27. 请简要说说一个完整机器学习项目的流程。机器学习 ML应用 中</h5><p>　　a). <strong>抽象成数学问题</strong><br>　　明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。<br>　　这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题，如果都不是的话，如何划归为其中的某类问题。<br>　　b). <strong>获取数据</strong><br>　　数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。<br>　　数据要有代表性，否则必然会过拟合。<br>　　而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数个数量级的差距。(类别均衡)<br>　　而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。<br>　　c). <strong>特征预处理与特征选择（特征工程）</strong><br>　　良好的数据要能够提取出良好的特征才能真正发挥效力。<br>　　<strong>特征预处理</strong>、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。<br>　　<strong>特征选择</strong>: 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。<br>　　d). <strong>训练模型与调优</strong><br>　　直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数（<strong>调参</strong>），使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。<br>　　e). <strong>模型诊断 </strong><br>　　如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。<br>　　过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是<strong>增加数据量</strong>，<strong>降低模型复杂度</strong>。欠拟合的基本调优思路是<strong>提高特征数量和质量</strong>，<strong>增加模型复杂度</strong>。<br>　　<strong>误差分析</strong>也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题……<br>　　诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。<br>　　f). <strong>模型融合</strong><br>　　一般来说，模型融合后都能使得效果有一定提升。而且效果很好。<br>　　工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫【特征工程 + 模型融合】。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。<br>　　g).<strong>上线运行 </strong><br>　　这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(<strong>时间复杂度</strong>)、资源消耗程度（<strong>空间复杂度</strong>）、<strong>稳定性</strong>是否可接受。<br>　　这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有大家自己多实践，多积累项目经验，才会有自己更深刻的认识。<br>　　故，基于此，七月在线每一期ML算法班都特此增加特征工程、模型调优等相关课。比如，这里有个公开课视频《<a href="http://www.julyedu.com/video/play/18/186" target="_blank" rel="noopener">特征处理与特征选择</a>》。</p>
<h5 id="28-逻辑斯特回归为什么要对特征进行离散化。机器学习-ML模型-中等"><a href="#28-逻辑斯特回归为什么要对特征进行离散化。机器学习-ML模型-中等" class="headerlink" title="28. 逻辑斯特回归为什么要对特征进行离散化。机器学习 ML模型 中等"></a>28. 逻辑斯特回归为什么要对特征进行离散化。机器学习 ML模型 中等</h5><p>　　@严林，本题解析来源：<a href="https://www.zhihu.com/question/31989952" target="_blank" rel="noopener">https://www.zhihu.com/question/31989952</a></p>
<p>　　在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：</p>
<p>　　0. 离散特征的增加和减少都很容易，易于模型的<strong>快速迭代</strong>；</p>
<p>　　1. <strong>稀疏向量</strong>内积乘法运算速度快，计算结果方便存储，容易扩展；</p>
<p>　　2. 离散化后的特征对<strong>异常数据有很强的鲁棒性</strong>：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</p>
<p>　　3. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够<strong>提升模型表达能力</strong>，加大拟合；</p>
<p>　　4. 离散化后可以进行<strong>特征交叉</strong>，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；</p>
<p>　　5. 特征离散化后，<strong>模型会更稳定</strong>，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；</p>
<p>　　6. 特征离散化以后，起到了<strong>简化了逻辑回归模型</strong>的作用，降低了模型过拟合的风险。</p>
<p>　　李沐曾经说过：模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。</p>
<h5 id="29-下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B）-机器学习-ML模型-中等"><a href="#29-下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B）-机器学习-ML模型-中等" class="headerlink" title="29. 下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B） 机器学习 ML模型 中等"></a>29. 下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B） 机器学习 ML模型 中等</h5><p>　　A. 特征灵活　　B. <strong>速度快</strong>　　C. 可容纳较多上下文信息　　D. 全局最优<br>　　CRF 的优点：特征灵活，可以容纳较多的上下文信息，能够做到全局最优CRF 的缺点：<strong>速度慢</strong><br>　　首先，CRF(条件随机场)，HMM(隐马模型)，MEMM(最大熵隐马模型)都常用来做<strong>序列标注</strong>的建模.<br>　　隐马模型一个最大的缺点就是由于其输出独立性假设，导致其<strong>不能考虑上下文的特征</strong>，限制了特征的选择<br>　　最大熵隐马模型则解决了隐马的问题，可以任意选择特征，但由于其在每一节点都要进行归一化，所以只能找到<strong>局部的最优值</strong>，同时也带来了<strong>标记偏见</strong>的问题，即凡是训练语料中未出现的情况全都忽略掉<br>　　条件随机场则很好的解决了这一问题，他并不在每一个节点进行归一化，而是所有特征进行全局归一化，因此可以求得全局的最优值。<br>　　此外《<a href="https://www.julyedu.com/course/getDetail/65" target="_blank" rel="noopener">机器学习工程师第八期</a>》里有讲概率图模型。</p>
<h5 id="30-什么是熵。机器学习-ML基础-易"><a href="#30-什么是熵。机器学习-ML基础-易" class="headerlink" title="30. 什么是熵。机器学习 ML基础 易"></a>30. 什么是熵。机器学习 ML基础 易</h5><p>　　熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量。<br>　　1948年，香农Claude E. Shannon引入<strong>信息（熵）</strong>，将其定义为离散随机事件的出现概率。一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。所以说，信息熵可以被认为是系统有序化程度的一个度量。<br>　　信息熵计算公式：$H(x) = -\sum P(x_i)\log(p(x_i)), (i=1,2,…n)$<br>　　更多请查看《<a href="http://blog.csdn.net/v_july_v/article/details/40508465" target="_blank" rel="noopener">最大熵模型中的数学推导</a>》。</p>
<h5 id="31-熵、联合熵、条件熵、相对熵、互信息的定义。机器学习-ML基础-中等"><a href="#31-熵、联合熵、条件熵、相对熵、互信息的定义。机器学习-ML基础-中等" class="headerlink" title="31. 熵、联合熵、条件熵、相对熵、互信息的定义。机器学习 ML基础 中等"></a>31. 熵、联合熵、条件熵、相对熵、互信息的定义。机器学习 ML基础 中等</h5><p>　　为了更好的理解，需要了解的概率必备知识有：<br>　　a). 大写字母X表示随机变量，小写字母x表示随机变量X的某个具体的取值；<br>　　b). P(X)表示随机变量X的概率分布，P(X,Y)表示随机变量X、Y的联合概率分布，P(Y|X)表示已知随机变量X的情况下随机变量Y的条件概率分布；<br>　　c). p(X = x)表示随机变量X取某个具体值的概率，简记为p(x)；<br>　　d). p(X = x, Y = y) 表示联合概率，简记为p(x,y)，p(Y = y|X = x)表示条件概率，简记为p(y|x)，且有：p(x,y) = p(x) <em> p(y|x)。<br>　　<em>*熵</em></em>：如果一个随机变量X的可能取值为$X = \{x_1, x_2,…, x_k\}$，其概率分布为$P(X = x_i) = p_i（i = 1,2, …, n），则随机变量X的熵定义为：</p>
<script type="math/tex; mode=display">H(x) = -\sum P(x_i)\log(p(x_i)), (i=1,2,...n)</script><p>　　<strong>联合熵</strong>：两个随机变量X，Y的联合分布，可以形成联合熵Joint Entropy，用H(X,Y)表示。<br>　　<strong>条件熵</strong>：在随机变量X发生的前提下，随机变量Y发生所新带来的熵定义为Y的条件熵，用H(Y|X)表示，用来衡量在已知随机变量X的条件下随机变量Y的不确定性。且有此式子成立：$H(Y|X) = H(X,Y) – H(X)$，整个式子表示(X,Y)发生所包含的熵减去X单独发生包含的熵。至于怎么得来的请看推导：<br><img src="conentry.jpg" alt="conentry.jpg"><br>　　简单解释下上面的推导过程。整个式子共6行，其中:<br>　　第二行推到第三行的依据是边缘分布p(x)等于联合分布p(x,y)的和；<br>　　第三行推到第四行的依据是把公因子logp(x)乘进去，然后把x,y写在一起；<br>　　第四行推到第五行的依据是：因为两个sigma都有p(x,y)，故提取公因子p(x,y)放到外边，然后把里边的-（log p(x,y) - log p(x)）写成- log (p(x,y)/p(x) ) ；<br>　　第五行推到第六行的依据是：p(x,y) = p(x) <em> p(y|x)，故p(x,y) / p(x) =  p(y|x)。<br>　　<em>*相对熵</em></em>：又称互熵，交叉熵，鉴别信息，Kullback熵，Kullback-Leible散度等。设p(x)、q(x)是X中取值的两个概率分布，则p对q的相对熵是：</p>
<script type="math/tex; mode=display">D(p||q) = \sump(x)\log \frac{p(x)}{q(x)} = E_{p(x)}\log \frac{p(x)}{q(x)}</script><p>　　在一定程度上，相对熵可以度量两个随机变量的“距离”，且有D(p||q) ≠D(q||p)。另外，值得一提的是，D(p||q)是必然大于等于0的。<br>　　<strong>互信息</strong>：两个随机变量X，Y的互信息定义为X，Y的联合分布和各自独立分布乘积的相对熵，用I(X,Y)表示：</p>
<script type="math/tex; mode=display">I(X, Y) = \sum_{x, y}p(x, y)\log \frac{p(x, y)}{p(x)p(y)}</script><p>　　且有I(X,Y)=D(P(X,Y) || P(X)P(Y))。下面，咱们来计算下H(Y)-I(X,Y)的结果，如下：<br><img src="IX.jpg" alt="IX.jpg"><br> 　　通过上面的计算过程，我们发现竟然有H(Y)-I(X,Y) = H(Y|X)。故通过条件熵的定义，有：H(Y|X) = H(X,Y) - H(X)，而根据互信息定义展开得到H(Y|X) = H(Y) - I(X,Y)，把前者跟后者结合起来，便有I(X,Y)= H(X) + H(Y) - H(X,Y)，此结论被多数文献作为互信息的定义。更多请查看《<a href="http://blog.csdn.net/v_july_v/article/details/40508465" target="_blank" rel="noopener">最大熵模型中的数学推导</a>》。</p>
<h5 id="32-什么是最大熵。机器学习-ML基础-易"><a href="#32-什么是最大熵。机器学习-ML基础-易" class="headerlink" title="32. 什么是最大熵。机器学习 ML基础 易"></a>32. 什么是最大熵。机器学习 ML基础 易</h5><p>　　熵是随机变量不确定性的度量，不确定性越大，熵值越大；若随机变量退化成定值，熵为0。如果没有外界干扰，随机变量总是趋向于无序，在经过足够时间的稳定演化，它应该能够达到的最大程度的熵。<br>　　为了准确的估计随机变量的状态，我们一般习惯性最大化熵，认为在所有可能的概率模型（分布）的集合中，熵最大的模型是最好的模型。换言之，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或最随机的推断，其原则是承认已知事物（知识），且对未知事物不做任何假设，没有任何偏见。<br>　　例如，投掷一个骰子，如果问”每个面朝上的概率分别是多少”，你会说是等概率，即各点出现的概率均为1/6。因为对这个”一无所知”的色子，什么都不确定，而假定它每一个朝上概率均等则是最合理的做法。从投资的角度来看，这是风险最小的做法，而从信息论的角度讲，就是保留了最大的不确定性，也就是说让熵达到最大。</p>
<h5 id="33-了解正则化么。机器学习-ML基础-易"><a href="#33-了解正则化么。机器学习-ML基础-易" class="headerlink" title="33. 了解正则化么。机器学习 ML基础 易"></a>33. 了解正则化么。机器学习 ML基础 易</h5><p>　　正则化是针对<strong>过拟合</strong>而提出的，以为在求解模型最优的是一般优化最小的经验风险，现在在该经验风险上加入<strong>模型复杂度</strong>这一项（正则化项是模型参数向量的范数），并使用一个rate比率来权衡模型复杂度与以往经验风险的权重，如果模型复杂度越高，结构化的经验风险会越大，现在的目标就变为了<strong>结构经验风险</strong>的最优化，可以防止模型训练过度复杂，有效的降低过拟合的风险。<br>　　奥卡姆剃刀原理，能够很好的<strong>解释</strong>已知数据并且十分<strong>简单</strong>才是最好的模型。</p>
<h5 id="34-协方差和相关性有什么区别？机器学习-ML基础-易"><a href="#34-协方差和相关性有什么区别？机器学习-ML基础-易" class="headerlink" title="34. 协方差和相关性有什么区别？机器学习 ML基础 易"></a>34. 协方差和相关性有什么区别？机器学习 ML基础 易</h5><p>　　<strong>相关性</strong>是协方差的标准化格式。协方差本身很难做比较。例如：如果我们计算工资（$）和年龄（岁）的协方差，因为这两个变量有不同的度量，所以我们会得到不能做比较的不同的协方差。</p>
<script type="math/tex; mode=display">\sum_{ij} = cov(X_i, X_i) = E[(X_i - \mu_i)(X_j - \mu_j)] = E[X_iX_j]-\mu_i \mu_j</script><p>　　为了解决这个问题，我们计算相关性来得到一个介于-1和1之间的值，就可以忽略它们各自不同的度量。</p>
<script type="math/tex; mode=display">\rol{X, Y} = \frac{cov(X, Y)}{\sigma_X \sigma_Y}</script><h5 id="35-线性分类器与非线性分类器的区别以及优劣。机器学习-ML基础-易"><a href="#35-线性分类器与非线性分类器的区别以及优劣。机器学习-ML基础-易" class="headerlink" title="35. 线性分类器与非线性分类器的区别以及优劣。机器学习 ML基础 易"></a>35. 线性分类器与非线性分类器的区别以及优劣。机器学习 ML基础 易</h5><p>　　@伟祺，线性和非线性是针对，模型参数和输入特征来讲的；比如输入x，模型y=ax+ax^2那么就是非线性模型，如果输入是x和X^2则模型是线性的。<br>　　线性分类器可解释性好，计算复杂度较低，不足之处是模型的拟合效果相对弱些。<br>　　非线性分类器效果拟合能力较强，不足之处是数据量不足容易过拟合、计算复杂度高、可解释性不好。<br>　　常见的线性分类器有：LR,贝叶斯分类，单层感知机、线性回归（）<br>　　常见的非线性分类器：决策树、RF、GBDT、多层感知机(非线性激活函数)　<br>　　SVM两种都有（看线性核还是高斯核）</p>
<h5 id="36-简单说说贝叶斯定理。机器学习-ML模型-易"><a href="#36-简单说说贝叶斯定理。机器学习-ML模型-易" class="headerlink" title="36. 简单说说贝叶斯定理。机器学习 ML模型 易"></a>36. 简单说说贝叶斯定理。机器学习 ML模型 易</h5><p>　　在引出贝叶斯定理之前，先学习几个定义：<br>　　<strong>条件概率</strong>（又称后验概率）就是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”。</p>
<blockquote>
<p>比如，在同一个样本空间Ω中的事件或者子集A与B，如果随机从Ω中选出的一个元素属于B，那么这个随机选择的元素还属于A的概率就定义为在B的前提下A的条件概率，所以：P(A|B) = |A∩B|/|B|，接着分子、分母都除以|Ω|得到</p>
<script type="math/tex; mode=display">P(A|B)=\frac{P(A \cap B)}{P(B)}</script></blockquote>
<p>　　<strong>联合概率</strong>表示两个事件共同发生的概率。A与B的联合概率表示为$P(A∩B)$或者$P(A，B)$。<br>　　<strong>边缘概率</strong>（又称先验概率）是某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中那些不需要的事件通过合并成它们的全概率，而消去它们（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率），这称为边缘化（marginalization），比如A的边缘概率表示为P(A)，B的边缘概率表示为P(B)。<br>　　 接着，考虑一个问题：P(A|B)是在B发生的情况下A发生的可能性。</p>
<p>　　首先，事件B发生之前，我们对事件A的发生有一个基本的概率判断，称为A的先验概率，用P(A)表示；<br>　　其次，事件B发生之后，我们对事件A的发生概率重新评估，称为A的后验概率，用P(A|B)表示；<br>　　类似的，事件A发生之前，我们对事件B的发生有一个基本的概率判断，称为B的先验概率，用P(B)表示；<br>　　同样，事件A发生之后，我们对事件B的发生概率重新评估，称为B的后验概率，用P(B|A)表示。<br>　　<strong>贝叶斯定理</strong>的公式表达式： </p>
<script type="math/tex; mode=display">P(A|B)=\frac{P(B|A)P(A)}{P(B)}</script><p>　　所以，贝叶斯公式可以直接根据条件概率的定义直接推出。即因为P(A,B) = P(A)P(B|A) = P(B)P(A|B)，所以P(A|B) = P(A)P(B|A)  / P(B)。更多请参见此文：《<a href="http://blog.csdn.net/v_july_v/article/details/40984699" target="_blank" rel="noopener">从贝叶斯方法谈到贝叶斯网络</a>》。</p>
<h5 id="37-某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？-A-数据挖掘-DM模型-易"><a href="#37-某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？-A-数据挖掘-DM模型-易" class="headerlink" title="37. 某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？(A)   数据挖掘 DM模型 易"></a>37. 某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？(A)   数据挖掘 DM模型 易</h5><p>　　A. <strong>关联规则发现</strong>　　B. 聚类　　C. 分类 　　D. 自然语言处理</p>
<h5 id="38-将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？-C-数据挖掘-DM基础-易"><a href="#38-将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？-C-数据挖掘-DM基础-易" class="headerlink" title="38. 将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？(C)  数据挖掘 DM基础 易"></a>38. 将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？(C)  数据挖掘 DM基础 易</h5><p>　　A. 频繁模式挖掘     B. 分类和预测     C. <strong>数据预处理</strong>     D. 数据流挖掘</p>
<h5 id="39-下面哪种不属于数据预处理的方法？-D-数据挖掘-DM基础-易"><a href="#39-下面哪种不属于数据预处理的方法？-D-数据挖掘-DM基础-易" class="headerlink" title="39. 下面哪种不属于数据预处理的方法？ (D)  数据挖掘 DM基础 易"></a>39. 下面哪种不属于数据预处理的方法？ (D)  数据挖掘 DM基础 易</h5><p>　　A. 变量代换　　B. 离散化  C. 聚集　　D. <strong>估计遗漏值</strong> </p>
<h5 id="40-什么是KDD？-A-数据挖掘-DM基础-易"><a href="#40-什么是KDD？-A-数据挖掘-DM基础-易" class="headerlink" title="40. 什么是KDD？ (A)   数据挖掘 DM基础 易"></a>40. 什么是KDD？ (A)   数据挖掘 DM基础 易</h5><p>　　A. <strong>数据挖掘与知识发现</strong>　　B. 领域知识发现　　C. 文档知识发现　　D. 动态知识发现</p>
<h5 id="41-当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？-B-数据挖掘-DM模型-易"><a href="#41-当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？-B-数据挖掘-DM模型-易" class="headerlink" title="41. 当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？(B)  数据挖掘 DM模型 易"></a>41. 当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？(B)  数据挖掘 DM模型 易</h5><p>　　A. 分类　　B. <strong>聚类</strong>　　C. 关联分析　　D. 隐马尔可夫链</p>
<h5 id="42-建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？-C-数据挖掘-DM基础-易"><a href="#42-建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？-C-数据挖掘-DM基础-易" class="headerlink" title="42. 建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？(C)  数据挖掘 DM基础 易"></a>42. 建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？(C)  数据挖掘 DM基础 易</h5><p>　　A. 根据内容检索　　B. 建模描述　　C. <strong>预测建模</strong>　　D. 寻找模式和规则</p>
<h5 id="43-以下哪种方法不属于特征选择的标准方法：-D-数据挖掘-DM基础-易"><a href="#43-以下哪种方法不属于特征选择的标准方法：-D-数据挖掘-DM基础-易" class="headerlink" title="43. 以下哪种方法不属于特征选择的标准方法： (D)  数据挖掘 DM基础 易"></a>43. 以下哪种方法不属于特征选择的标准方法： (D)  数据挖掘 DM基础 易</h5><p>　　A. 嵌入　　B. 过滤　　 C. 包装　　D. <strong>抽样</strong>      </p>
<h5 id="44-请用python编写函数find-string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python-Python语言-易"><a href="#44-请用python编写函数find-string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python-Python语言-易" class="headerlink" title="44. 请用python编写函数find_string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python Python语言 易"></a>44. 请用python编写函数find_string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python Python语言 易</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">find_string(<span class="string">'hello\nworld\n'</span>,<span class="string">'wor'</span>)</span><br><span class="line">[<span class="string">'wor'</span>]</span><br><span class="line">find_string(<span class="string">'hello\nworld\n'</span>,<span class="string">'l*d'</span>)</span><br><span class="line">[<span class="string">'ld'</span>]</span><br><span class="line">find_string(<span class="string">'hello\nworld\n'</span>,<span class="string">'o.'</span>)</span><br><span class="line">[<span class="string">'or'</span>]</span><br><span class="line"><span class="comment"># 答案</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_string</span><span class="params">(str,pat)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> re.findall(pat,str,re.I)</span><br></pre></td></tr></table></figure>
<h5 id="45-简单说下sigmoid激活函数。深度学习-DL基础-易"><a href="#45-简单说下sigmoid激活函数。深度学习-DL基础-易" class="headerlink" title="45. 简单说下sigmoid激活函数。深度学习 DL基础 易"></a>45. 简单说下sigmoid激活函数。深度学习 DL基础 易</h5><p>　　常用的非线性激活函数有<strong>sigmoid、tanh、relu</strong>等等，前两者sigmoid/tanh比较常见于全连接层，后者relu常见于卷积层。这里先简要介绍下最基础的sigmoid函数（btw，在本博客中SVM那篇文章开头有提过）。<br>　　sigmoid的函数表达式如下：</p>
<script type="math/tex; mode=display">g(z) = \frac{1}{1 + e^{-z}}</script><p>　　其中z是一个线性组合，比如z可以等于：$z = wx + b$。通过代入很大的正数或很小的负数到g(z)函数中可知，其结果趋近于0或1。</p>
<p>　　因此，sigmoid函数g(z)的图形表示如下（ 横轴表示定义域z，纵轴表示值域g(z) ）：<br><img src="sigmoid.jpg" alt="sigmoid.jpg"><br>　　也就是说，<strong>sigmoid函数的功能是相当于把一个实数压缩至0到1之间。当z是非常大的正数时，g(z)会趋近于1，而z是非常小的负数时，则g(z)会趋近于0。</strong></p>
<p>　　压缩至0到1有何用处呢？用处是这样一来便可以把激活函数看作一种“分类的概率”，比如激活函数的输出为0.9的话便可以解释为90%的概率为正样本。</p>
<p>　　举个例子，如下图（图引自Stanford机器学习公开课）<br><img src="logistic.jpg" alt="logistic.jpg"><br>　　$z = b + w_1 \cdot x_1 + w_2 \cdot x_2$，其中b为偏置项，假定取-30，$w_1,w_2$都取为20<br><img src="sigmoid.jpg" alt="sigmoid.jpg"><br>　　- 如果 = 0  = 0，则z = -30，g(z) = 1/( 1 + e^-z )趋近于0。此外，从上图sigmoid函数的图形上也可以看出，当z=-30的时候，g(z)的值趋近于0<br>　　- 如果 = 0  = 1，或 =1  = 0，则z = b + <em> + </em> = -30 + 20 = -10，同样，g(z)的值趋近于0<br>　　- 如果 = 1  = 1，则z = b + <em> + </em> = -30 + 20<em>1 + 20</em>1 = 10，此时，g(z)趋近于1。<br>　　- 换言之，只有和都取1的时候，g(z)→1，判定为正样本；或取0的时候，g(z)→0，判定为负样本，如此达到分类的目的。<br>　　综上，sigmod函数，是逻辑斯蒂回归的压缩函数，它的性质是可以把分隔平面压缩到[0,1]区间一个数（向量），在线性分割平面值为0时候正好对应sigmod值为0.5，大于0对应sigmod值大于0.5、小于0对应sigmod值小于0.5；0.5可以作为分类的阀值；exp的形式最值求解时候比较方便，用相乘形式作为logistic损失函数，使得损失函数是凸函数；不足之处是sigmod函数在y趋于0或1时候有死区，控制不好在bp形式传递loss时候容易造成<strong>梯度弥撒</strong>。<br>    <em>导数：g(x)(1 - g(x))</em></p>
<h5 id="46-什么是卷积。深度学习-DL基础-易"><a href="#46-什么是卷积。深度学习-DL基础-易" class="headerlink" title="46. 什么是卷积。深度学习 DL基础 易"></a>46. 什么是卷积。深度学习 DL基础 易</h5><p>　　对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。<br>　　非严格意义上来讲，下图中红框框起来的部分便可以理解为一个滤波器，即带着一组固定权重的神经元。多个滤波器叠加便成了卷积层。<br><img src="conv1.jpg" alt="conv1.jpg"><br>　　OK，举个具体的例子。比如下图中，图中左边部分是原始输入数据(三通道)，图中中间部分是滤波器filter（shape：3，3,3,2），图中右边是输出的feature map。<br><img src="cov.gif" alt="cov.gif"><br>　　中间滤波器filter与数据窗口做内积，对应位置相乘相加（二维空间 + 通道），<em>卷积核大小若为1x1，就相当于通道同一位置乘一个系数相加</em></p>
<h5 id="47-什么是CNN的池化pool层。深度学习-DL模型-易"><a href="#47-什么是CNN的池化pool层。深度学习-DL模型-易" class="headerlink" title="47. 什么是CNN的池化pool层。深度学习 DL模型 易"></a>47. 什么是CNN的池化pool层。深度学习 DL模型 易</h5><p>　　池化，简言之，即取区域<strong>平均</strong>或<strong>最大</strong>，如下图所示（图引自cs231n）<br>　　<strong>*<a href="https://www.zhihu.com/question/36686900/answer/130890492" target="_blank" rel="noopener">CNN网络的pooling层有什么用</a></strong>：<br>　　1. invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)<br>　　2. 保留主要的特征同时减少参数(降维，效果类似PCA)和计算量，防止过拟合，提高模型泛化能力<em><br>　　<em>*缺陷</em></em>：丢失信息<br><img src="pooling.jpg" alt="pooling.jpg"><br>　　上图所展示的是取区域最大，即上图左边部分中 左上角2x2的矩阵中6最大，右上角2x2的矩阵中8最大，左下角2x2的矩阵中3最大，右下角2x2的矩阵中4最大，所以得到上图右边部分的结果：6 8 3 4。很简单不是？</p>
<h5 id="48-简述下什么是生成对抗网络（GAN）。深度学习-DL扩展-中"><a href="#48-简述下什么是生成对抗网络（GAN）。深度学习-DL扩展-中" class="headerlink" title="48. 简述下什么是生成对抗网络（GAN）。深度学习 DL扩展 中"></a>48. 简述下什么是生成对抗网络（GAN）。深度学习 DL扩展 中</h5><p>　　GAN之所以是对抗的，是因为GAN的内部是竞争关系(<em>引入博弈论的思想</em>)，一方叫generator，它的主要工作是生成图片，并且尽量使得其看上去是来自于训练样本的。另一方是discriminator，其目标是判断输入图片是否属于真实训练样本。<br>　　更直白的讲，将generator想象成假币制造商，而discriminator是警察。generator目的是尽可能把假币造的跟真的一样，从而能够骗过discriminator，即生成样本并使它看上去好像来自于真实训练样本一样。discriminator就是为了尽可能的区分假币与真币。<br>　　如下图中的左右两个场景：<br><img src="GAN.jpg" alt="GAN.jpgs"></p>
<h5 id="48-学梵高作画的原理是啥？深度学习-DL应用-难"><a href="#48-学梵高作画的原理是啥？深度学习-DL应用-难" class="headerlink" title="48. 学梵高作画的原理是啥？深度学习 DL应用 难"></a>48. 学梵高作画的原理是啥？深度学习 DL应用 难</h5><p>　　这里有篇如何做梵高风格画的实验教程《<a href="http://blog.csdn.net/v_july_v/article/details/52658965" target="_blank" rel="noopener">教你从头到尾利用DL学梵高作画：GTX 1070 cuda 8.0 tensorflow gpu版</a>》，至于其原理请看这个视频：<a href="http://www.julyedu.com/video/play/42/523" target="_blank" rel="noopener">NeuralStyle艺术化图片（学梵高作画背后的原理</a>）。<br>　　<em>风格迁移论文：</em>《<a href="https://arxiv.org/pdf/1508.06576v2.pdf" target="_blank" rel="noopener">A Neural Algorithm of Artistic Style</a>》<br>　　　　　　　　　　《<a href="https://arxiv.org/abs/1603.08155" target="_blank" rel="noopener">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a>》<br>　　　　　　　　　　《<a href="https://arxiv.org/pdf/1808.04537.pdf" target="_blank" rel="noopener">Learning Linear Transformations for Fast Arbitrary Style Transfer</a>》</p>
<h5 id="49-现在有-a-到-z-26-个元素，-编写程序打印-a-到-z-中任取-3-个元素的组合（比如-打印-a-b-c-，d-y-z等）-数理逻辑-排列组合-中"><a href="#49-现在有-a-到-z-26-个元素，-编写程序打印-a-到-z-中任取-3-个元素的组合（比如-打印-a-b-c-，d-y-z等）-数理逻辑-排列组合-中" class="headerlink" title="49. 现在有 a 到 z 26 个元素， 编写程序打印 a 到 z 中任取 3 个元素的组合（比如 打印 a b c ，d y z等） 数理逻辑 排列组合 中"></a>49. 现在有 a 到 z 26 个元素， 编写程序打印 a 到 z 中任取 3 个元素的组合（比如 打印 a b c ，d y z等） 数理逻辑 排列组合 中</h5><p>　　解析参考：<a href="http://blog.csdn.net/lvonve/article/details/53320680" target="_blank" rel="noopener">一道百度机器学习工程师职位的面试题</a></p>
<h5 id="50-说说梯度下降法。机器学习-ML基础-中"><a href="#50-说说梯度下降法。机器学习-ML基础-中" class="headerlink" title="50. 说说梯度下降法。机器学习 ML基础 中"></a>50. 说说梯度下降法。机器学习 ML基础 中</h5><p>　　@LeftNotEasy，本题解析来源：<a href="http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html" target="_blank" rel="noopener">机器学习中的数学(1)-回归(regression)、梯度下降(gradient descent)</a>，下面是一个典型的机器学习的过程，首先给出一个输入数据，我们的算法会通过一系列的过程得到一个<strong>估计函数</strong>，这个函数有能力对没有见过的新数据给出一个新的估计，也被称为构建一个模型。<br><img src="pipleline.png" alt="pipleline.png"><br>　　我们用$X_1，X_2…X_n$去描述feature里面的分量，比如x1=房间的面积，x2=房间的朝向等等，我们可以做出一个估计函数：</p>
<script type="math/tex; mode=display">h(x) = h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2</script><p>　　θ在这儿称为<strong>参数</strong>，在这儿的意思是调整feature中每个分量的影响力，就是到底是房屋的面积更重要还是房屋的地段更重要。如果我们令$x_0 = 1$，就可以用向量的方式来表示了：</p>
<script type="math/tex; mode=display">h_\theta(x) = \theta^TX</script><p>　　我们程序也需要一个机制去评估我们θ是否比较好，所以说需要对我们做出的h函数进行评估，一般这个进行评估的函数称为<strong>损失函数</strong>（loss function），描述h函数不好的程度，在下面，我们称这个函数为J函数<br>　　在这儿我们可以做出下面的一个损失函数（MSE）:</p>
<script type="math/tex; mode=display">J(\theta)_{min_\theta J_\theta}=\frac{1}{2}\sum_{i=1}^m{(h_\theta(x^{(i)}) - y^{(i)})^2}</script><p>　　换言之，我们把对$x_i$的估计值$h(x_i)$与真实值$y_i$差的平方和作为损失函数，前面乘上的1/2是为了在求导的时候，这个系数就不见了(<em>便于求导</em>)。<br>　　如何调整θ以使得J(θ)取得最小值有很多方法，其中有<strong>最小二乘法</strong>(min square)，是一种完全是数学描述的方法，另外一种就是<strong>梯度下降法</strong>。<br>　　梯度下降法的<strong>算法流程</strong>如下：<br>　　1）初始化：首先对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。　<br>　　2）更新：改变θ的值，使得J(θ)按梯度下降的方向进行减少。<br>　　为了描述的更清楚，给出下面的图：<br><img src="image_thumb_9.png" alt="image_thumb_9.png"><br>　　这是一个表示参数θ与误差函数J(θ)的关系图，红色的部分是表示J(θ)有着比较高的取值，我们需要的是，能够让J(θ)的值尽量的低，也就是达到深蓝色的部分。$θ_0，θ_1$表示θ向量的两个维度。</p>
<p>　　在上面提到梯度下降法的第一步是给θ给一个初值，假设随机给的初值是在图上的十字点。</p>
<p>　　然后我们将θ按照梯度下降的方向进行调整，就会使得J(θ)往更低的方向进行变化，如下图（左）所示，算法的结束将是在θ下降到无法继续下降为止。<br><img src="image_thumb_10.png" alt="image_thumb_10.png">  <img src="image_thumb_11.png" alt="image_thumb_11.png"><br>　　当然，可能梯度下降的最终点并非是全局最小点，即也可能是一个局部最小点，如上图（右）所示。这张图就是描述的一个局部最小点，这是我们重新选择了一个初始点得到的，看来我们这个算法将会在很大的程度上被初始点的选择影响而陷入局部最小点。<br>　　下面我将用一个例子描述一下梯度减少的过程，对于我们的函数J(θ)求偏导J：<br><img src="image_thumb_12.png" alt="image_thumb_12.png">　<br>　　下面是更新的过程，也就是θi会向着梯度最小的方向进行减少。θi表示更新之前的值，-后面的部分表示按梯度方向减少的量，α表示步长，也就是每次按照梯度减少的方向变化多少。<br><img src="image_thumb_14.png" alt="image_thumb_14.png"><br>　　一个很重要的地方值得注意的是，梯度是有方向的，对于一个向量θ，每一维分量θi都可以求出一个梯度的方向，我们就可以找到一个整体的方向，在变化的时候，我们就朝着下降最多的方向进行变化就可以达到一个最小点，不管它是局部的还是全局的。<br>　　 用更简单的数学语言进行描述步骤2）是这样的：<br><img src="image_thumb_15.png" alt="image_thumb_15.png"></p>
<h5 id="51-梯度下降法找到的一定是下降最快的方向么？机器学习-ML基础-中"><a href="#51-梯度下降法找到的一定是下降最快的方向么？机器学习-ML基础-中" class="headerlink" title="51. 梯度下降法找到的一定是下降最快的方向么？机器学习 ML基础 中"></a>51. 梯度下降法找到的一定是下降最快的方向么？机器学习 ML基础 中</h5><p>　　梯度下降法并不是下降最快的方向，它只是目标函数在当前的点的切平面（当然高维问题不能叫平面）上下降最快的方向。在practical implementation中，牛顿方向（考虑海森矩阵）才一般被认为是下降最快的方向，可以达到superlinear的收敛速度。梯度下降类的算法的收敛速度一般是linear甚至sublinear的（在某些带复杂约束的问题）。by<a href="https://www.zhihu.com/question/30672734/answer/139689869" target="_blank" rel="noopener">林小溪</a>。<br>一般解释梯度下降，会用下山来举例。假设你现在在山顶处，必须抵达山脚下（也就是山谷最低处）的湖泊。但让人头疼的是，你的双眼被蒙上了无法辨别前进方向。换句话说，你不再能够一眼看出哪条路径是最快的下山路径，如下图:<br><img src="BGD.jpg" alt="BGD.jpg"><br>　　最好的办法就是走一步算一步，先用脚向四周各个方向都迈出一步，试探一下周围的地势，用脚感觉下哪个方向是下降最大的方向。换言之，每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向（当前最陡峭的位置向下）走一步。就这样，每要走一步都根据上一步所在的位置选择当前最陡峭最快下山的方向走下一步，一步步走下去，一直走到我们感觉已经到了山脚。<br>　　当然这样走下去，我们走到的可能并不一定是真正的山脚，而只是走到了某一个局部的山峰低处。换句话说，梯度下降<strong>不一定能够找到全局的最优解</strong>，也有可能只是一个<strong>局部最优解</strong>。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。<br><img src="1042406-20161017221342935-1872962415.png" alt="1042406-20161017221342935-1872962415.png"><br>　参考：<a href="http://blog.csdn.net/wemedia/details.html?id=45460" target="_blank" rel="noopener">一文清晰讲解机器学习中梯度下降算法（包括其变式算法）</a></p>
<h5 id="52-随机梯度下降"><a href="#52-随机梯度下降" class="headerlink" title="52. 随机梯度下降"></a>52. 随机梯度下降</h5><p>　　普通的梯度下降算法在更新回归系数时要<strong>遍历整个数据集</strong>，是一种批处理方法，这样训练数据特别忙庞大时，可能出现如下问题：<br>　　1）收敛过程可能非常慢；<br>　　2）如果误差曲面上有多个局极小值，那么不能保证这个过程会找到全局最小值。<br>　　为了解决上面的问题，实际中我们应用的是梯度下降的一种变体被称为<strong>随机梯度下降</strong>。<br>　　上面公式中的误差是针对于所有训练样本而得到的，而随机梯度下降的思想是根据<strong>每个单独的训练样本来更新权值</strong>，这样我们上面的梯度公式就变成了：<br>　　参考：<a href="https://blog.csdn.net/u014568921/article/details/44856915" target="_blank" rel="noopener">梯度下降与随机梯度下降</a></p>
<h5 id="53-牛顿法和梯度下降法有什么不同。机器学习-ML基础-中"><a href="#53-牛顿法和梯度下降法有什么不同。机器学习-ML基础-中" class="headerlink" title="53. 牛顿法和梯度下降法有什么不同。机器学习 ML基础 中"></a>53. 牛顿法和梯度下降法有什么不同。机器学习 ML基础 中</h5><p>　　1）牛顿法（Newton’s method）<br>　　牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f(x)的泰勒级数的前面几项来寻找方程f(x) = 0的根。牛顿法最大的特点就在于它的<strong>收敛速度很快</strong>。<br>　　<strong>具体步骤：</strong>　<br>　　首先，选择一个接近函数f(x)零点的x0，计算相应的f(x0)和切线斜率f’(x0)（这里f’表示函数f的导数）。然后我们计算穿过点(x0,  f(x0))并且斜率为f ‘(x0)的直线和x轴的交点的x坐标，也就是求如下方程的解：</p>
<script type="math/tex; mode=display">x \cdot f'(x_0) + f(x_0) - x_0 \cdot f'(x_0) = 0</script><p>　　我们将新求得的点的ｘ坐标命名为x1，通常x1会比x0更接近方程f(x)=0的解。因此我们现在可以利用x1开始下一轮迭代。迭代公式可化简为如下所示：</p>
<script type="math/tex; mode=display">x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}</script><p>　　已经证明，如果f’是连续的，并且待求的零点x是孤立的，那么在零点x周围存在一个区域，只要初始值x0位于这个邻近区域内，那么牛顿法必定收敛。 并且，如果f’(x)不为0, 那么牛顿法将具有平方收敛的性能. 粗略的说，这意味着每迭代一次，牛顿法结果的有效数字将增加一倍。<br>　　由于牛顿法是基于当前位置的切线来确定下一次的位置，所以牛顿法又被很形象地称为是”切线法”。牛顿法的搜索路径（二维情况）如下图所示：<br><img src="NewtonIteration_Ani.gif" alt="NewtonIteration_Ani.gif"><br>　　关于牛顿法和梯度下降法的<strong>效率对比</strong>：<br>　　a). 从收敛速度上看 ，牛顿法是二阶收敛，梯度下降是一阶收敛，前者牛顿法收敛速度更快。但牛顿法仍然是局部算法，只是在局部上看的更细致，梯度法仅考虑方向，牛顿法不但考虑了方向还兼顾了步子的大小，其对步长的估计使用的是二阶逼近。<br>　　b). 根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。<br><img src="222309373784741.png" alt="222309373784741.png">注：红色的牛顿法的迭代路径，绿色的是梯度下降法的迭代路径。<br>　　牛顿法的<strong>优缺点总结</strong>：　<br>　　优点：二阶收敛，收敛速度快；<br>　　缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</p>
<h5 id="54-什么是拟牛顿法（Quasi-Newton-Methods）？机器学习-ML基础-中"><a href="#54-什么是拟牛顿法（Quasi-Newton-Methods）？机器学习-ML基础-中" class="headerlink" title="54. 什么是拟牛顿法（Quasi-Newton Methods）？机器学习 ML基础 中"></a>54. 什么是拟牛顿法（Quasi-Newton Methods）？机器学习 ML基础 中</h5><p>　　@wtq1993，<a href="http://blog.csdn.net/wtq1993/article/details/51607040" target="_blank" rel="noopener">机器学习中常见的最优化算法</a><br>　　<strong>拟牛顿法</strong>是求解非线性优化问题最有效的方法之一，于20世纪50年代由美国Argonne国家实验室的物理学家W.C.Davidon所提出来。Davidon设计的这种算法在当时看来是非线性优化领域最具创造性的发明之一。不久R. Fletcher和M. J. D. Powell证实了这种新的算法远比其他方法快速和可靠，使得非线性优化这门学科在一夜之间突飞猛进。<br>　　拟牛顿法的本质思想是<strong>改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。</strong>拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。<br>　　<strong>具体步骤：</strong><br>　　拟牛顿法的基本思想如下。首先构造目标函数在当前迭代$x_k$的二次模型：<br><img src="222253268161863.png" alt="222253268161863.png"><br>　　这里$B_K$是一个对称正定矩阵，于是我们取这个二次模型的最优解作为搜索方向，并且得到新的迭代点：</p>
<script type="math/tex; mode=display">x_{k+1} = X_k + \alpha_kp_k</script><p>　　其中我们要求步长$\alpha_k$，满足Wolfe条件。这样的迭代与牛顿法类似，区别就在于用近似的Hessian矩阵Bk<br>代替真实的Hessian矩阵。所以拟牛顿法最关键的地方就是每一步迭代中矩阵Bk的更新。现在假设得到一个新的迭代xk+1，并得到一个新的二次模型：</p>
<script type="math/tex; mode=display">m_{k+1}(p) = f(x_k + 1) + \delta f(x_{k + 1})^Tp + \frac{p^TB_{K+1}p}{2}</script><p>　　我们尽可能地利用上一步的信息来选取Bk。具体地，我们要求</p>
<script type="math/tex; mode=display">\delta f(x_k + 1) - \delta f(x_k) = \alpha_kB_{k +1}p_k</script><p>　　从而得到</p>
<script type="math/tex; mode=display">B_{k+1}(x_{k+1} - x_k) = \delta f(x_k + 1) - \delta f(x_k)</script><p>　　这个公式被称为<strong>割线方程</strong>。常用的拟牛顿法有DFP算法和BFGS算法。</p>
<h5 id="55-请说说随机梯度下降法的问题和挑战？机器学习-ML基础-中"><a href="#55-请说说随机梯度下降法的问题和挑战？机器学习-ML基础-中" class="headerlink" title="55. 请说说随机梯度下降法的问题和挑战？机器学习 ML基础 中"></a>55. 请说说随机梯度下降法的问题和挑战？机器学习 ML基础 中</h5><p>　　 <img src="20171008190826961.jpg" alt="20171008190826961.jpg"><br>　　 <img src="20171008190944146.jpg" alt="20171008190944146.jpg"><br>　　 <img src="20171008190952260.jpg" alt="20171008190952260.jpg"><br>　　 <img src="20171008191123640.jpg" alt="20171008191123640.jpg"><br>那到底如何优化随机梯度法呢？详情请点击：论文公开课第一期：<a href="https://ask.julyedu.com/question/7913" target="_blank" rel="noopener">详解梯度下降等各类优化算法（含视频和PPT下载）</a>。</p>
<h5 id="56-说说共轭梯度法？机器学习-ML基础-中"><a href="#56-说说共轭梯度法？机器学习-ML基础-中" class="headerlink" title="56. 说说共轭梯度法？机器学习 ML基础 中"></a>56. 说说共轭梯度法？机器学习 ML基础 中</h5><p>　　<strong>共轭梯度法</strong>是介于梯度下降法（最速下降法）与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了梯度下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hessian矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需<strong>存储量小，具有逐步收敛性，稳定性高，而且不需要任何外来参数。</strong><br>　　下图为共轭梯度法和梯度下降法搜索最优解的路径对比示意图：<br><img src="220px-Conjugate_gradient_illustration.svg.png" alt="220px-Conjugate_gradient_illustration.svg.png">  　　注：绿色为梯度下降法，红色代表共轭梯度法</p>
<h5 id="57-对所有优化问题来说-有没有可能找到比現在已知算法更好的算法？机器学习-ML基础-中"><a href="#57-对所有优化问题来说-有没有可能找到比現在已知算法更好的算法？机器学习-ML基础-中" class="headerlink" title="57. 对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法？机器学习 ML基础 中"></a>57. 对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法？机器学习 ML基础 中</h5><p>　　@抽象猴，来源<a href="https://www.zhihu.com/question/41233373/answer/145404190" target="_blank" rel="noopener">如果你是面试官，你怎么去判断一个面试者的深度学习水平？</a>　<br>　　<strong>没有免费的午餐定理</strong>：<br>　　对于训练样本（黑点），不同的算法A/B在不同的测试样本（白点）中有不同的表现，这表示：对于一个学习算法A，若它在某些问题上比学习算法 B更好，则必然存在一些问题，在那里B比A好。<br>　　也就是说：对于所有问题，无论学习算法A多聪明，学习算法B多笨拙，它们的期望性能相同。<br>　　但是：没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。<br><img src="20171008200137803.jpg" alt="20171008200137803.jpg"></p>
<h5 id="58-什么最小二乘法？机器学习-ML基础-中"><a href="#58-什么最小二乘法？机器学习-ML基础-中" class="headerlink" title="58. 什么最小二乘法？机器学习 ML基础 中"></a>58. 什么最小二乘法？机器学习 ML基础 中</h5><p>　　我们口头中经常说：一般来说，平均来说。如平均来说，不吸烟的健康优于吸烟者，之所以要加“平均”二字，是因为凡事皆有例外，总存在某个特别的人他吸烟但由于经常锻炼所以他的健康状况可能会优于他身边不吸烟的朋友。而最小二乘法的一个最简单的例子便是<strong>算术平均</strong>。<br>　　最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。用函数表示为：</p>
<script type="math/tex; mode=display">min_\vec(x) \sum_{i =1}^{n}(y_M - y_I)^2</script><p>　　<img src="20171214111608352.png" alt="20171214111608352.png"><br>　　由于算术平均是一个历经考验的方法，而以上的推理说明，算术平均是最小二乘的一个特例，所以从另一个角度说明了最小二乘方法的优良性，使我们对最小二乘法更加有信心。<br>　　最小二乘法发表之后很快得到了大家的认可接受，并迅速的在数据分析实践中被广泛使用。不过历史上又有人把最小二乘法的发明归功于高斯，这又是怎么一回事呢。高斯在1809年也发表了最小二乘法，并且声称自己已经使用这个方法多年。高斯发明了小行星定位的数学方法，并在数据分析中使用最小二乘方法进行计算，准确的预测了谷神星的位置。<br>　　对了，最小二乘法跟SVM有什么联系呢？请参见<a href="http://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">支持向量机通俗导论（理解SVM的三层境界）</a>。</p>
<h5 id="59-看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python-Python语言-易"><a href="#59-看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python-Python语言-易" class="headerlink" title="59. 看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python Python语言 易"></a>59. 看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python Python语言 易</h5><p>　　<a href="http://nooverfit.com/wp/15%E4%B8%AA%E9%87%8D%E8%A6%81python%E9%9D%A2%E8%AF%95%E9%A2%98-%E6%B5%8B%E6%B5%8B%E4%BD%A0%E9%80%82%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9Apython%EF%BC%9F/" target="_blank" rel="noopener">15个重要Python面试题 测测你适不适合做Python？</a><br>　　这里是一些关键点：<br>　　<strong>Python是解释型语言</strong>。这意味着不像C和其他语言，Python运行前不需要编译。其他解释型语言包括PHP和Ruby。<br>　　<strong>Python是动态类型的</strong>，这意味着你不需要在声明变量时指定类型。你可以先定义x=111，然后 x=”I’m a string”。<br>　　<strong>Python是面向对象语言</strong>，所有允许定义类并且可以继承和组合。Python没有访问访问标识如在C++中的public, private, 这就非常信任程序员的素质，相信每个程序员都是“成人”了~<br>　　在Python中，<strong>函数是一等公民</strong>。这就意味着它们可以被赋值，从其他函数返回值，并且传递函数对象。类不是一等公民。<br>　　写Python代码很快，但是跑起来会比编译型语言慢。幸运的是，Python允许使用C扩展写程序，所以瓶颈可以得到处理。Numpy库就是一个很好例子，因为很多代码不是Python直接写的，所以运行很快。<br>　　<strong>Python使用场景很多</strong> – web应用开发、大数据应用、数据科学、人工智能等等。它也经常被看做“胶水”语言，使得不同语言间可以衔接上。<br>　　<strong>Python能够简化工作</strong>，使得程序员能够关心如何重写代码而不是详细看一遍底层实现。</p>
<h5 id="60-Python是如何进行内存管理的？-Python-Python基础-中"><a href="#60-Python是如何进行内存管理的？-Python-Python基础-中" class="headerlink" title="60. Python是如何进行内存管理的？ Python Python基础 中"></a>60. Python是如何进行内存管理的？ Python Python基础 中</h5><p>　　@Tom_junsong，来源：<a href="http://www.cnblogs.com/tom-gao/p/6645859.html" target="_blank" rel="noopener">2017 Python最新面试题及答案16道题</a><br>　　答:从三个方面来说,一对象的<strong>引用计数机制</strong>,二<strong>垃圾回收机制</strong>,三<strong>内存池机制</strong><br>　　<strong>一、对象的引用计数机制</strong><br>　　Python内部使用引用计数，来保持追踪内存中的对象，所有对象都有引用计数。<br>　　引用计数增加的情况：<br>　　1，一个对象分配一个新名称<br>　　2，将其放入一个容器中（如列表、元组或字典）<br>　　引用计数减少的情况：<br>　　1，使用del语句对对象别名显示的销毁<br>　　2，引用超出作用域或被重新赋值<br>　　sys.getrefcount( )函数可以获得对象的当前引用计数<br>　　多数情况下，引用计数比你猜测得要大得多。对于不可变数据（如数字和字符串），解释器会在程序的不同部分共享内存，以便节约内存。<br>　　<strong>二、垃圾回收</strong><br>　　1，当一个对象的引用计数归零时，它将被垃圾收集机制处理掉。<br>　　2，当两个对象a和b相互引用时，del语句可以减少a和b的引用计数，并销毁用于引用底层对象的名称。然而由于每个对象都包含一个对其他对象的应用，因此引用计数不会归零，对象也不会销毁。（从而导致内存泄露）。为解决这一问题，解释器会定期执行一个循环检测器，搜索不可访问对象的循环并删除它们。<br>　　<strong>三、内存池机制</strong><br>　　Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。<br>　　1，Pymalloc机制。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。<br>　　2，Python中所有小于256个字节的对象都使用pymalloc实现的分配器，而大的对象则使用系统的malloc。<br>　　3，对于Python对象，如整数，浮点数和List，都有其独立的私有内存池，对象间不共享他们的内存池。也就是说如果你分配又释放了大量的整数，用于缓存这些整数的内存就不能再分配给浮点数。</p>
<h5 id="61-请写出一段Python代码实现删除一个list里面的重复元素。Python-Python开发-中"><a href="#61-请写出一段Python代码实现删除一个list里面的重复元素。Python-Python开发-中" class="headerlink" title="61. 请写出一段Python代码实现删除一个list里面的重复元素。Python Python开发 中"></a>61. 请写出一段Python代码实现删除一个list里面的重复元素。Python Python开发 中</h5><p>　　1、使用set函数，set(list)；<br>　　2、使用字典函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>]</span><br><span class="line">b=&#123;&#125;</span><br><span class="line">b=b.fromkeys(a)</span><br><span class="line">c=list(b.keys())</span><br><span class="line">c</span><br></pre></td></tr></table></figure></p>
<h5 id="62-编程用sort进行排序，然后从最后一个元素开始判断？Python-Python开发-中"><a href="#62-编程用sort进行排序，然后从最后一个元素开始判断？Python-Python开发-中" class="headerlink" title="62. 编程用sort进行排序，然后从最后一个元素开始判断？Python Python开发 中"></a>62. 编程用sort进行排序，然后从最后一个元素开始判断？Python Python开发 中</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>,<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">a.sort()</span><br><span class="line">last=a[<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">    <span class="keyword">if</span> last==a[i]:</span><br><span class="line">	    <span class="keyword">del</span> a[i]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">	    last=a[i]</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<h5 id="63-Python里面如何生成随机数？-？Python-Python开发-中"><a href="#63-Python里面如何生成随机数？-？Python-Python开发-中" class="headerlink" title="63. Python里面如何生成随机数？ ？Python Python开发 中"></a>63. Python里面如何生成随机数？ ？Python Python开发 中</h5><p>　　@Tom_junsong，<a href="http://www.cnblogs.com/tom-gao/p/6645859.html" target="_blank" rel="noopener">2017 Python最新面试题及答案16道题</a><br>　　答：<strong>random模块</strong><br>　　随机整数：random.randint(a,b)：返回随机整数x,a&lt;=x&lt;=b<br>　　random.randrange(start,stop,[,step])：返回一个范围在(start,stop,step)之间的随机整数，不包括结束值。<br>　　随机实数：random.random( ):返回0到1之间的浮点数<br>　　random.uniform(a,b):返回指定范围内的浮点数。更多Python笔试面试题请看：<a href="http://python.jobbole.com/85231/" target="_blank" rel="noopener">很全的 Python 面试题</a></p>
<h5 id="64-说说常见的损失函数？机器学习-ML基础-易"><a href="#64-说说常见的损失函数？机器学习-ML基础-易" class="headerlink" title="64. 说说常见的损失函数？机器学习 ML基础 易"></a>64. 说说常见的损失函数？机器学习 ML基础 易</h5><p>　　对于给定的输入X，由f(X)给出相应的输出Y，这个输出的预测值f(X)与真实值Y可能一致也可能不一致（要知道，有时损失或误差是不可避免的），用一个损失函数来度量预测错误的程度。损失函数记为L(Y, f(X))。<br>　　常用的损失函数有以下几种（基本引用自《统计学习方法》）：<br>　　<img src="20131119171556593.jpg" alt="20131119171556593.jpg"><br>　　<img src="20131119171613656.jpg" alt="20131119171613656.jpg"></p>
<h5 id="65-简单介绍下logistics回归？机器学习-ML模型-易"><a href="#65-简单介绍下logistics回归？机器学习-ML模型-易" class="headerlink" title="65. 简单介绍下logistics回归？机器学习 ML模型 易"></a>65. 简单介绍下logistics回归？机器学习 ML模型 易</h5><p>　　Logistic回归目的是从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此，使用logistic函数（或称作sigmoid函数）将自变量映射到(0,1)上，映射后的值被认为是属于y=1的概率。<br>　　假设函数：<script type="math/tex">h_{\theta }(x)=g(\theta ^T x)=\frac{1}{1+e^{-\theta ^{T}x}}</script><br>　　其中x是n维特征向量，函数g就是Logistic函数。而：$g(z)=\frac{1}{1+e^{-z}}$的图像是：<br>　　<img src="sigmoid.jpg" alt="sigmoid.jpg"><br>　　可以看到，将无穷映射到了(0,1)。<br>　　而假设函数就是特征属于y=1的概率。<br>　　<script type="math/tex">P(y=1|x ;\theta )=h_{\theta }(x)；P(y=0|x ;\theta )=1-h_{\theta }(x)</script><br>　　<img src="20171214113420858.png" alt="20171214113420858.png"></p>
<h5 id="66-看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习-DL应用-难"><a href="#66-看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习-DL应用-难" class="headerlink" title="66. 看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习 DL应用 难"></a>66. 看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习 DL应用 难</h5><p>　　原英文：adeshpande3.github.io<br>　　作者：Adit Deshpande，UCLA CS研究生<br>　　译者：新智元闻菲、胡祥杰<a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2651986617&amp;idx=1&amp;sn=fddebd0f2968d66b7f424d6a435c84af&amp;scene=0#wechat_redirect" target="_blank" rel="noopener">计算机视觉和 CNN 发展十一座里程碑</a><br>　　原论文：《<a href="https://pan.baidu.com/s/1dFyVLst#list/path=%2F" target="_blank" rel="noopener">CNN十篇经典论文</a>》<br>　　本文结构如下：　<br>　　　AlexNet（2012年）<br>　　　ZF Net（2013年）<br>　　　VGG Net（2014年）<br>　　　GoogLeNet （2014年）<br>　　　微软 ResNet （2015年）<br>　　　区域 CNN（R-CNN - 2013年，Fast R-CNN - 2015年，Faster R-CNN - 2015年 <em>Mask R-CNN  - 2017年</em>）<br>　　　生成对抗网络（2014年）<br>　　　生成图像描述（2014年）<br>　　　空间转化器网络（2015年）</p>
<h5 id="67-深度学习在视觉领域有何前沿进展？深度学习-DL应用-难"><a href="#67-深度学习在视觉领域有何前沿进展？深度学习-DL应用-难" class="headerlink" title="67. 深度学习在视觉领域有何前沿进展？深度学习 DL应用 难"></a>67. 深度学习在视觉领域有何前沿进展？深度学习 DL应用 难</h5><p>　　@元峰　　本题解析来源：<a href="https://zhuanlan.zhihu.com/p/24699780" target="_blank" rel="noopener">深度学习在计算机视觉领域的前沿进展</a><br>　　<strong>引言</strong><br>　　在今年的神经网络顶级会议NIPS2016上，深度学习三大牛之一的Yann Lecun教授给出了一个关于机器学习中的有监督学习、无监督学习和增强学习的一个有趣的比喻，他说：如果把智能（Intelligence）比作一个蛋糕，那么无监督学习就是蛋糕本体，增强学习是蛋糕上的樱桃，那么监督学习，仅仅能算作蛋糕上的糖霜（图1）。<br>　　<img src="20171006171604539.jpg" alt="20171006171604539.jpg">　图1. Yann LeCun 对监督学习，增强学习和无监督学习的价值的形象比喻<br>　　<strong>1. 深度有监督学习在计算机视觉领域的进展</strong><br>　　<strong>1.1 图像分类（Image Classification）</strong><br>　　自从Alex和他的导师Hinton（深度学习鼻祖）在2012年的ImageNet大规模图像识别竞赛（ILSVRC2012）中以超过第二名10个百分点的成绩(83.6%的Top5精度)碾压第二名（74.2%，使用传统的计算机视觉方法）后，深度学习真正开始火热，卷积神经网络（CNN）开始成为家喻户晓的名字，从12年的AlexNet（83.6%），到2013年ImageNet 大规模图像识别竞赛冠军的ZFnet88.8%，再到2014年VGG的92.7%和同年的冠军GoogLeNet的93.3%，终于，到了2015年，在1000类的图像识别中，微软提出的残差网（ResNet）以96.43%的Top5正确率，达到了超过人类的水平（人类的正确率也只有94.9%）.<br>　　Top5精度是指在给出一张图片，模型给出5个最有可能的标签，只要在预测的5个结果中包含正确标签，即为正确<br>　　<img src="20171006171612298.jpg" alt="20171006171612298.jpg">　图２. 2010-2015年ILSVRC竞赛图像识别错误率演进趋势<br>　　<br>　　<strong>1.2 图像检测（Image Dection）</strong><br>　　伴随着图像分类任务，还有另外一个更加有挑战的任务–图像检测，图像检测是指在分类图像的同时把物体用矩形框给圈起来。从14年到16年，先后涌现出R-CNN,Fast R-CNN, Faster R-CNN, YOLO, SSD等知名框架，其检测平均精度（mAP），在计算机视觉一个知名数据集上PASCAL VOC上的检测平均精度（mAP），也从R-CNN的53.3%，到Fast RCNN的68.4%，再到Faster R-CNN的75.9%，最新实验显示，Faster RCNN结合残差网（Resnet-101），其检测精度可以达到83.8%。深度学习检测速度也越来越快，从最初的RCNN模型，处理一张图片要用2秒多，到Faster RCNN的198毫秒/张，再到YOLO的155帧/秒（其缺陷是精度较低，只有52.7%），最后出来了精度和速度都较高的SSD，精度75.1%，速度23帧/秒。<br>　　<img src="20171006171620055.jpg" alt="20171006171620055.jpg">　图3. 图像检测示例<br>　　<strong>1.3 图像分割（Semantic Segmentation）</strong><br>　　图像分割也是一项有意思的研究领域，它的目的是把图像中各种不同物体给用不同颜色分割出来（实例分割/语义分割），如下图所示，其平均精度（mIoU，即预测区域和实际区域交集除以预测区域和实际区域的并集），也从最开始的FCN模型（图像语义分割全连接网络，该论文获得计算机视觉顶会CVPR2015的最佳论文的）的62.2%，到DeepLab框架的72.7%，再到牛津大学的CRF as RNN的74.7%。该领域是一个仍在进展的领域，仍旧有很大的进步空间。<br>　　<img src="20171006171627148.jpg" alt="20171006171627148.jpg">　图4. 图像分割的例子<br>　　<strong>1.4 图像标注–看图说话（Image Captioning）</strong><br>　　图像标注是一项引人注目的研究领域，它的研究目的是给出一张图片，你给我用一段文字描述它，如图中所示，图片中第一个图，程序自动给出的描述是“一个人在尘土飞扬的土路上骑摩托车”，第二个图片是“两只狗在草地上玩耍”。由于该研究巨大的商业价值（例如图片搜索），近几年，工业界的百度，谷歌和微软 以及学术界的加大伯克利，深度学习研究重地多伦多大学都在做相应的研究。<br>　　<img src="20171006171638975.jpg" alt="20171006171638975.jpg">　图5.图像标注，根据图片生成描述文字<br>   <strong>1.5 图像生成–文字转图像（Image Generator）</strong><br>　　图片标注任务本来是一个半圆，既然我们可以从图片产生描述文字，那么我们也能从文字来生成图片。如图6所示，第一列“一架大客机在蓝天飞翔”，模型自动根据文字生成了16张图片，第三列比较有意思，“一群大象在干燥草地行走”（这个有点违背常识，因为大象一般在雨林，不会在干燥草地上行走），模型也相应的生成了对应图片，虽然生成的质量还不算太好，但也已经中规中矩。<br>　　<img src="20171006171649563.jpg" alt="20171006171649563.jpg">　图6.根据文字生成图片<br>　　<br>　　<strong>2. 强化学习（Reinforcement Learning）</strong><br>　　在监督学习任务中，我们都是给定样本一个固定标签，然后去训练模型，可是，在真实环境中，我们很难给出所有样本的标签，这时候，强化学习就派上了用场。简单来说，我们给定一些奖励或惩罚，强化学习就是让模型自己去试错，模型自己去优化怎么才能得到更多的分数。2016年大火的AlphaGo就是利用了强化学习去训练，它在不断的自我试错和博弈中掌握了最优的策略。利用强化学习去玩flyppy bird，已经能够玩到几万分了。<br>　　<img src="20171006171727619.jpg" alt="20171006171727619.jpg">　 图７. 强化学习玩flappy bird<br>　　谷歌DeepMind发表的使用增强学习来玩Atari游戏，其中一个经典的游戏是打砖块（breakout），DeepMind提出的模型仅仅使用像素作为输入，没有任何其他先验知识，换句话说，模型并不认识球是什么，它玩的是什么，令人惊讶的是，在经过240分钟的训练后，它不光学会了正确的接球，击打砖块，它甚至学会了持续击打同一个位置，游戏就胜利的越快（它的奖励也越高）。视频链接:<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DV1eYniJ0Rnk" target="_blank" rel="noopener">Youtbe</a>(需翻墙),<a href="https://link.zhihu.com/?target=http%3A//v.youku.com/v_show/id_XMTUxODU2NjY5Ng%3D%3D.html" target="_blank" rel="noopener">优酷</a><br>　　<img src="20171006171738997.jpg" alt="20171006171738997.jpg"><br>　　强化学习在机器人领域和自动驾驶领域有极大的应用价值，当前arxiv上基本上每隔几天就会有相应的论文出现。机器人去学习试错来学习最优的表现，这或许是人工智能进化的最优途径，估计也是通向强人工智能的必经之路。<br>　　<br>　　<strong>3. 深度无监督学习（Deep Unsupervised Learning）–预测学习</strong><br>　　相比有限的监督学习数据，自然界有无穷无尽的未标注数据。试想，如果人工智能可以从庞大的自然界自动去学习，那岂不是开启了一个新纪元？当前，最有前景的研究领域或许应属无监督学习，这也正是Yann Lecun教授把无监督学习比喻成人工智能大蛋糕的原因吧。<br>　　深度学习牛人Ian Goodfellow在2014年提出<strong>生成对抗网络(GAN)</strong>后，该领域越来越火，成为16年研究最火热的一个领域之一。大牛Yann LeCun曾说：“对抗网络是切片面包发明以来最令人激动的事情。”这句话足以说明生成对抗网络有多重要。<br>　　生成对抗网络的一个简单解释如下：假设有两个模型，一个是生成模型（Generative Model，下文简写为G），一个是判别模型（Discriminative Model，下文简写为D），判别模型(D)的任务就是判断一个实例是真实的还是由模型生成的，生成模型(G)的任务是生成一个实例来骗过判别模型（D），两个模型互相对抗，发展下去就会达到一个平衡，生成模型生成的实例与真实的没有区别，判别模型无法区分自然的还是模型生成的。以赝品商人为例，赝品商人（生成模型）制作出假的毕加索画作来欺骗行家（判别模型D），赝品商人一直提升他的高仿水平来区分行家，行家也一直学习真的假的毕加索画作来提升自己的辨识能力，两个人一直博弈，最后赝品商人高仿的毕加索画作达到了以假乱真的水平，行家最后也很难区分正品和赝品了。下图是Goodfellow在发表生成对抗网络论文中的一些生成图片，可以看出，模型生成的模型与真实的还是有大差别，但这是14年的论文了，16年这个领域进展非常快，相继出现了<a href="https://arxiv.org/abs/1411.1784" target="_blank" rel="noopener"><strong>条件生成对抗网络</strong>（Conditional Generative Adversarial Nets）</a>和<a href="https://arxiv.org/abs/1606.03657" target="_blank" rel="noopener"><strong>信息生成对抗网络</strong>（InfoGAN）</a>，<a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="noopener"><strong>深度卷积生成对抗网络</strong>（Deep Convolutional Generative Adversarial Network, DCGAN）</a>，更重要的是，当前生成对抗网络把触角伸到了视频预测领域，众所周知，人类主要是靠视频序列来理解自然界的，图片只占非常小的一部分，当人工智能学会理解视频后，它也真正开始显现出威力了。<br>　　<img src="20171006171751331.jpg" alt="20171006171751331.jpg">　图9 生成对抗网络生成的一些图片，最后边一列是与训练集中图片最相近的生产图片<br>　　这里推荐一篇2017年初Ian GoodFellow结合他在NIPS2016的演讲写出的综述性论文<a href="https://arxiv.org/abs/1701.00160" target="_blank" rel="noopener">NIPS 2016 Tutorial: Generative Adversarial Networks</a><br>　　<strong>3.1条件生成对抗网络（Conditional Generative Adversarial Nets，CGAN）</strong><br>　　生成对抗网络一般是根据随机噪声来生成特定类型的图像等实例，条件生成对抗网络则是根据一定的输入来限定输出，例如根据几个描述名词来生成特定的实例，这有点类似1.5节介绍的由文字生成图像，下图是Conditioanal Generative Adversarial Nets论文中的一张图片，根据特定的名词描述来生成图片。（注意：左边的一列图片的描述文字是训练集中不存在的，也就是说是模型根据没有见过的描述来生成的图片，右边的一列图片的描述是训练集中存在的）<br>　　<img src="20171006171820270.jpg" alt="20171006171820270.jpg">　图10. 根据文字来生成图片<br>　　条件生成对抗网络的另一篇有意思的论文是图像到图像的翻译<a href="https://arxiv.org/pdf/1611.07004.pdf" target="_blank" rel="noopener">pix2pix</a>，该论文提出的模型能够根据一张输入图片，然后给出模型生成的图片，下图是论文中的一张图，其中左上角第一对非常有意思，模型输入图像分割的结果，给出了生成的真实场景的结果，这类似于图像分割的反向工程。<br>　　<img src="20171006171832891.jpg" alt="20171006171832891.jpg">　图11. 根据特定输入来生成一些有意思的输出图片<br>　　生成对抗网络也用在了图像超分辨率上，2016年有人提出<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1609.04802" target="_blank" rel="noopener">SRGAN</a>模型，它把原高清图下采样后，试图用生成对抗网络模型来还原图片来生成更为自然的，更逼近原图像的图像。下图中最右边是原图，把他降采样后采用三次差值（Bicubic Interpolation）得到的图像比较模糊，采用残差网络的版本（SRResNet）已经干净了很多，我们可以看到SRGAN生成的图片更为真实一些。<br>　　<img src="20171006171908694.jpg" alt="20171006171908694.jpg">　图12.生成对抗网络做超分辨率的例子，最右边是原始图像<br>　　生成对抗网络的另一篇有影响力的论文是<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.06434" target="_blank" rel="noopener">深度卷积生成对抗网络DCGAN</a>,作者把卷积神经网络和生成对抗网络结合起来，作者指出该框架可以很好的学习事物的特征，论文在图像生成和图像操作上给出了很有意思的结果，例如图13，<strong>带眼睛的男人-不戴眼镜的男人+不带眼睛的女人=带眼睛的女人</strong>,该模型给出了图片的类似向量化操作。<br>　　<img src="20171006171917236.jpg" alt="20171006171917236.jpg">　图13. DCGAN论文中的例图<br>　　生成对抗网络的发展是在是太火爆，一篇文章难以罗列完全，对此感兴趣的朋友们可以自己在网络搜素相关论文来研究<br>　　openAI的一篇描述生成对抗网络的博客非常棒，因为Ian Goodfellow就在OpenAI工作，所以这篇博客的质量还是相当有保障的。链接为：<a href="https://link.zhihu.com/?target=https%3A//openai.com/blog/generative-models/" target="_blank" rel="noopener">Open AI 生成对抗网络博客</a><br>　　<strong>3.2 视频预测</strong><br>　　该方向是笔者自己最感兴趣的方向，Yann LeCun也提出，“用预测学习来替代无监督学习”,预测学习通过观察和理解这个世界是如何运作的，然后对世界的变化做出预测，机器学会了感知世界的变化，然后对世界的状态进行了推断。<br>　　今年的NIPS上，MIT的学者Vondrick等人发表了一篇名为<a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/vondrick/tinyvideo/" target="_blank" rel="noopener">Generating Videos with Scene Dynamics</a>的论文,该论文提出了基于一幅静态的图片，模型自动推测接下来的场景，例如给出一张人站在沙滩的图片，模型自动给出一段接下来的海浪涌动的小视频。该模型是以无监督的方式，在大量的视频上训练而来的。该模型表明它可以自动学习到视频中有用的特征。下图是作者的官方主页上给出的图，是动态图，如果无法正常查看，请转入<a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/vondrick/tinyvideo/" target="_blank" rel="noopener">官方网站</a><br>　　MIT的CSAIL实验室也放出了一篇博客，题目是《<a href="https://link.zhihu.com/?target=http%3A//news.mit.edu/2016/teaching-machines-to-predict-the-future-0621" target="_blank" rel="noopener">教会机器去预测未来</a>》,该模型在youtube视频和电视剧上（例如The Office和《绝望主妇》）训练，训练好以后，如果你给该模型一个亲吻之前的图片，该模型能自动推测出加下来拥抱亲吻的动作，具体的例子见下图。<br>　　<img src="20171006172007882.jpg" alt="20171006172007882.jpg">　图14. 给出一张静态图，模型自动推测接下来的动作<br>　　哈佛大学的Lotter等人提出了<a href="https://link.zhihu.com/?target=https%3A//coxlab.github.io/prednet/" target="_blank" rel="noopener">PredNet</a>，该模型也是在<a href="https://link.zhihu.com/?target=http%3A//www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">KITTI数据集</a>上训练,然后该模型就可以根据前面的视频，预测行车记录仪接下来几帧的图像，模型是用长短期记忆神经网络（LSTM）训练得到的。具体例子见下图,给出行车记录仪前几张的图片，自动预测接下来的五帧场景，模型输入几帧图像后，预测接下来的5帧，由图可知，越往后，模型预测的越是模糊,但模型已经可以给出有参加价值的预测结果了。图片是动图，如果无法正常查看，请访问论文<a href="https://coxlab.github.io/prednet/" target="_blank" rel="noopener">作者的博客</a><br>　　<img src="20171006172029181.jpg" alt="20171006172029181.jpg">　图18. 给出行车记录仪前几张的图片，自动预测接下来的五帧场景,该图为动图<br>　　<strong>4. 总结</strong><br>　　生成对抗网络，无监督学习视频预测的论文实在是太多，本人精力实在有限，对此感兴趣的读者可以每天刷一下arxiv的<a href="https://arxiv.org/list/cs.CV/recent" target="_blank" rel="noopener">计算机视觉版块的计算机视觉和模型识别</a>，<a href="https://arxiv.org/list/cs.NE/recent" target="_blank" rel="noopener">神经网络和进化计算</a>和<a href="https://arxiv.org/list/cs.AI/recent" target="_blank" rel="noopener">人工智能</a>等相应版块，基本上每天都有这方面新论文出现。图像检测和分割，增强学习，生成对抗网络，预测学习都是人工智能发展火热的方向，希望对深度学习感兴趣的我们在这方面能做出来点成果。谢谢朋友们的阅读，对深度无监督学习感兴趣的朋友，欢迎一起学习交流，请私信我。</p>
<p>　　<strong>5. 参考文献</strong><br>　　在写本文的过程中，我尽量把论文网址以链接的形式附着在正文中.本文参考的大部分博客和论文整理如下，方便大家和自己以后研究查看。</p>
<p>　　<strong>参考博客:</strong></p>
<blockquote>
<ol>
<li><a href="https://mp.weixin.qq.com/s/VJkiVmGBMv3sL94mivjNHg" target="_blank" rel="noopener">【NIPS 主旨演讲】Yann LeCun：用预测学习替代无监督学习</a></li>
<li><a href="https://mp.weixin.qq.com/s/eosTWBbLpwVroYPEb9Q0wA" target="_blank" rel="noopener">计算机视觉和 CNN 发展十一座里程碑</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//openai.com/blog/generative-models/" target="_blank" rel="noopener">Generative Models</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/vondrick/tinyvideo/" target="_blank" rel="noopener">Generating Videos with Scene Dynamics</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//news.mit.edu/2016/teaching-machines-to-predict-the-future-0621" target="_blank" rel="noopener">Teaching machines to predict the future</a></li>
</ol>
</blockquote>
<p>　　<strong>参考论文:</strong></p>
<blockquote>
<ol>
<li>Resnet模型，图像分类，超过人类的计算机识别水平。<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
<li>图像检测 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></li>
<li>图像分割<a href="https://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/~szheng/CRFasRNN.html" target="_blank" rel="noopener">Conditional Random Fields as Recurrent Neural Networks</a></li>
<li>图像标注，看图说话 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1411.4555" target="_blank" rel="noopener">Show and Tell: A Neural Image Caption Generator</a></li>
<li>文字生成图像<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1605.05396" target="_blank" rel="noopener">Generative Adversarial Text to Image Synthesis</a></li>
<li>强化学习玩<a href="https://link.zhihu.com/?target=https%3A//github.com/yenchenlin/DeepLearningFlappyBird" target="_blank" rel="noopener">flyppy bird Using Deep Q-Network to Learn How To Play Flappy Bird</a></li>
<li>强化学习玩Atari游戏 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1312.5602" target="_blank" rel="noopener">Playing Atari with Deep Reinforcement Learning</a></li>
<li>生成对抗网络 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1406.2661" target="_blank" rel="noopener">Generative Adversarial Networks</a></li>
<li>条件生成对抗网络<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1411.1784" target="_blank" rel="noopener">Conditional Generative Adversarial Nets</a></li>
<li>生成对抗网络做图像超分辨率<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1609.04802" target="_blank" rel="noopener">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</a></li>
<li>深度卷积生成对抗网络<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.06434" target="_blank" rel="noopener">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></li>
<li>由图片推演视频<a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/vondrick/tinyvideo/" target="_blank" rel="noopener">Generating Videos with Scene Dynamics</a></li>
<li>视频预测和无监督学习<a href="https://link.zhihu.com/?target=https%3A//coxlab.github.io/prednet/" target="_blank" rel="noopener">Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning</a></li>
</ol>
</blockquote>
<h5 id="68-在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是-？-机器学习-ML基础-中"><a href="#68-在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是-？-机器学习-ML基础-中" class="headerlink" title="68. 在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是(  )？ 机器学习 ML基础 中"></a>68. 在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是(  )？ 机器学习 ML基础 中</h5><p>　　<strong>A 将负样本重复10次，生成10w样本量，打乱顺序参与分类</strong><br>　　B 直接进行分类，可以最大限度利用数据<br>　　<strong>C 从10w正样本中随机抽取1w参与分类</strong><br>　　<strong>D 将负样本每个权重设置为10，正样本权重为1，参与训练过程</strong><br>　　数据不均衡处理方法：<br>　　<strong>1. 重采样 </strong><br>　　A可视作重采样的变形。改变数据分布消除不平衡，可能导致过拟合。 　　<br>　　<strong>2. 欠采样</strong><br>　　C的方案 提高少数类的分类性能，可能丢失多数类的重要信息。<br>　　如果1：10算是均匀的话，可以将多数类分割成为1000份。然后将每一份跟少数类的样本组合进行训练得到分类器。而后将这1000个分类器用assemble的方法组合位一个分类器。A选项可以看作此方式，因而相对比较合理。<br>　　另：如果目标是 预测的分布 跟训练的分布一致，那就加大对分布不一致的惩罚系数。<br>　　<strong>3. 权值调整</strong><br>　　D方案也是其中一种方式。<br>　　<strong>４. 损失函数</strong><br>　　@管博士：准确的说，其实选项中的这些方法各有优缺点，需要具体问题具体分析，有篇文章对各种方法的优缺点进行了分析，讲的不错 感兴趣的同学可以参考一下：<a href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/" target="_blank" rel="noopener">How to handle Imbalanced Classification Problems in machine learning?</a>。</p>
<h5 id="69-深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A-B-C的乘积ABC-假设三个矩阵的尺寸分别为m-n，n-p，p-q，且m-lt-n-lt-p-lt-q，以下计算顺序效率最高的是（）？深度学习-DL基础-中"><a href="#69-深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A-B-C的乘积ABC-假设三个矩阵的尺寸分别为m-n，n-p，p-q，且m-lt-n-lt-p-lt-q，以下计算顺序效率最高的是（）？深度学习-DL基础-中" class="headerlink" title="69. 深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A,B,C的乘积ABC,假设三个矩阵的尺寸分别为m*n，n*p，p*q，且m&lt;n&lt;p&lt;q，以下计算顺序效率最高的是（）？深度学习 DL基础 中"></a>69. 深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A,B,C的乘积ABC,假设三个矩阵的尺寸分别为m*n，n*p，p*q，且m&lt;n&lt;p&lt;q，以下计算顺序效率最高的是（）？深度学习 DL基础 中</h5><p>　　<strong>A.(AB)C</strong>　　B.AC(B)　　C.A(BC)　　D.所以效率都相同<br>　　正确答案：A<br>　　@BlackEyes_SGC： m*n*p&lt;m*n*q，m*p*q&lt; n*p*q, 所以 (AB)C 最小<br>　　首先，根据简单的矩阵知识，因为 A*B ， A 的列数必须和B的行数相等。因此，可以排除 B 选项，<br>　　然后，再看 A、C 选项。在A选项中，m*n矩阵A和n*p的矩阵B的乘积，得到m*p的矩阵 A*B ，而的每行n个元素需要n次乘法和n-1次加法，忽略加法，共需要n次乘法运算。同样情况分析 A*B之后再乘以C时的情况，共需要p次乘法运算。因此， A 选项 (AB)C 需要的乘法次数是n*p。同理分析， C选项 A (BC) 需要的乘法次数是 。<br>由于，显然 A 运算次数更少，故选 A 。</p>
<h5 id="70-Nave-Bayes是一种特殊的Bayes分类器-特征变量是X-类别标签是C-它的一个假定是（）机器学习-ML模型-中"><a href="#70-Nave-Bayes是一种特殊的Bayes分类器-特征变量是X-类别标签是C-它的一个假定是（）机器学习-ML模型-中" class="headerlink" title="70. Nave Bayes是一种特殊的Bayes分类器,特征变量是X,类别标签是C,它的一个假定是（）机器学习 ML模型 中"></a>70. Nave Bayes是一种特殊的Bayes分类器,特征变量是X,类别标签是C,它的一个假定是（）机器学习 ML模型 中</h5><p>　　A.各类别的先验概率P(C)是相等的　　B.以0为均值，sqr(2)/2为标准差的正态分布　　<strong>C.特征变量X的各个维度是类别条件独立随机变量</strong>　　D.P(X|C)是高斯分布<br>　　正确答案：C<br>　　@BlackEyes_SGC：朴素贝叶斯的基本假设就是每个变量相互独立。</p>
<h5 id="70-关于支持向量机SVM-下列说法错误的是（）-机器学习-ML模型-中"><a href="#70-关于支持向量机SVM-下列说法错误的是（）-机器学习-ML模型-中" class="headerlink" title="70. 关于支持向量机SVM,下列说法错误的是（） 机器学习 ML模型 中"></a>70. 关于支持向量机SVM,下列说法错误的是（） 机器学习 ML模型 中</h5><p>　　A.L2正则项，作用是最大化分类间隔，使得分类器拥有更强的泛化能力<br>　　B.Hinge损失函数，作用是最小化经验分类错误<br>　　<strong>C.分类间隔为1/||w||，||w||代表向量的模</strong><br>　　D.当参数C越小时，分类间隔越大，分类错误越多，趋于欠学习<br>　　正确答案：C<br>　　@BlackEyes_SGC：<br>　　A正确。考虑加入正则化项的原因：想象一个完美的数据集，y&gt;1是正类，y&lt;-1是负类，决策面y=0，加入一个y=-30的正类噪声样本，那么决策面将会变“歪”很多，分类间隔变小，泛化能力减小。加入正则项之后，对噪声样本的容错能力增强，前面提到的例子里面，决策面就会没那么“歪”了，使得分类间隔变大，提高了泛化能力。<br>　　B正确。<br>　　C错误。间隔应该是<strong>2/||w||</strong>才对，后半句应该没错，向量的模通常指的就是其二范数。<br>　　D正确。考虑软间隔的时候，C对优化问题的影响就在于把a的范围从[0，+inf]限制到了[0,C]。C越小，那么a就会越小，目标函数拉格朗日函数导数为0可以求出w=求和ai∗yi∗xi，a变小使得w变小，因此间隔2/||w||变大</p>
<h5 id="71-在HMM中-如果已知观察序列和产生观察序列的状态序列-那么可用以下哪种方法直接进行参数估计（）机器学习-ML模型-中"><a href="#71-在HMM中-如果已知观察序列和产生观察序列的状态序列-那么可用以下哪种方法直接进行参数估计（）机器学习-ML模型-中" class="headerlink" title="71. 在HMM中,如果已知观察序列和产生观察序列的状态序列,那么可用以下哪种方法直接进行参数估计（）机器学习 ML模型 中"></a>71. 在HMM中,如果已知观察序列和产生观察序列的状态序列,那么可用以下哪种方法直接进行参数估计（）机器学习 ML模型 中</h5><p>　　A.EM算法　　B.维特比算法　　C.前向后向算法　　<strong>D.极大似然估计</strong><br>　　正确答案：D<br>　　@BlackEyes_SGC：<br>　　EM算法： 只有观测序列，无状态序列时来学习模型参数，即Baum-Welch算法<br>　　维特比算法： 用动态规划解决HMM的预测问题，不是参数估计<br>　　前向后向算法：用来算概率<br>　　极大似然估计：即观测序列和相应的状态序列都存在时的监督学习算法，用来估计参数<br>　　注意的是在给定观测序列和对应的状态序列估计模型参数，可以利用极大似然发估计。如果给定观测序列，没有对应的状态序列，才用EM，将状态序列看不不可测的隐数据。</p>
<h5 id="72-假定某同学使用Naive-Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习-ML模型-中"><a href="#72-假定某同学使用Naive-Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习-ML模型-中" class="headerlink" title="72. 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习 ML模型 中"></a>72. 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习 ML模型 中</h5><p>　　A.这个被重复的特征在模型中的决定作用会被加强<br>　　<strong>B.模型效果相比无重复特征的情况下精确度会降低</strong><br>　　C.如果所有特征都被重复一遍，得到的模型预测结果相对于不重复的情况下的模型预测结果一样。<br>　　<strong>D.当两列特征高度相关时，无法用两列特征相同时所得到的结论来分析问题</strong><br>　　E.NB可以用来做最小二乘回归<br>　　F.以上说法都不正确<br>　　正确答案：BD<br>　　@BlackEyes_SGC：NB的核心在于它假设向量的所有分量之间是独立的。在贝叶斯理论系统中，都有一个重要的条件独立性假设：假设所有特征之间相互独立，这样才能将联合概率拆分</p>
<h5 id="73-以下哪些方法不可以直接来对文本分类？机器学习-ML模型-易"><a href="#73-以下哪些方法不可以直接来对文本分类？机器学习-ML模型-易" class="headerlink" title="73. 以下哪些方法不可以直接来对文本分类？机器学习 ML模型 易"></a>73. 以下哪些方法不可以直接来对文本分类？机器学习 ML模型 易</h5><p>　　<strong>A、Kmean</strong>s　　B、决策树　　C、支持向量机　　D、KNN<br>　　正确答案: A分类不同于<strong>聚类</strong>。<br>　　@BlackEyes_SGC：A：Kmeans是聚类方法，典型的无监督学习方法。分类是监督学习方法，BCD都是常见的分类方法。</p>
<h5 id="74-已知一组数据的协方差矩阵P-下面关于主分量说法错误的是（）机器学习-ML基础-易"><a href="#74-已知一组数据的协方差矩阵P-下面关于主分量说法错误的是（）机器学习-ML基础-易" class="headerlink" title="74. 已知一组数据的协方差矩阵P,下面关于主分量说法错误的是（）机器学习 ML基础 易"></a>74. 已知一组数据的协方差矩阵P,下面关于主分量说法错误的是（）机器学习 ML基础 易</h5><p>　　A、主分量分析的最佳准则是对一组数据进行按一组正交基分解, 在只取相同数量分量的条件下,以均方误差计算截尾误差最小<br>　　B、在经主分量分解后,协方差矩阵成为对角矩阵<br>　　<strong>C、主分量分析就是K-L变换 </strong><br>　　D、主分量是通过求协方差矩阵的特征值得到<br>　　解析：K-L变换与PCA变换是不同的概念，PCA的变换矩阵是协方差矩阵，K-L变换的变换矩阵可以有很多种（二阶矩阵、协方差矩阵、总类内离散度矩阵等等）。当K-L变换矩阵为协方差矩阵时，等同于PCA。<br>　　@BlackEyes_SGC：K-L变换与PCA变换是不同的概念，PCA的变换矩阵是协方差矩阵，K-L变换的变换矩阵可以有很多种（二阶矩阵、协方差矩阵、总类内离散度矩阵等等）。当K-L变换矩阵为协方差矩阵时，等同于PCA。</p>
<h5 id="75-kmeans的复杂度？机器学习-ML模型-易"><a href="#75-kmeans的复杂度？机器学习-ML模型-易" class="headerlink" title="75. kmeans的复杂度？机器学习 ML模型 易"></a>75. kmeans的复杂度？机器学习 ML模型 易</h5><p>　　算法流程：选择k个质心作为初始质心<br>　　　　　　　repeat<br>　　　　　　　　　　将每个点指派到最近的质心，形成k个簇<br>　　　　　　　　　　重新计算每个簇的质心<br>　　　　　　　util 簇不再更新或者达到最大迭代次数<br>　　<strong>时间复杂度：O(tKmn)</strong>，其中，t为迭代次数，K为簇的数目，m为记录数，n为维数，<strong>空间复杂度：O((m+K)n)</strong>，其中，K为簇的数目，m为记录数，n为维数,具体参考：<a href="http://blog.csdn.net/sinat_35512245/article/details/55051306" target="_blank" rel="noopener">机器学习之深入理解K-means、与KNN算法区别及其代码实现</a></p>
<h5 id="76-关于logit回归和SVM不正确的是（A）-机器学习-ML模型-中"><a href="#76-关于logit回归和SVM不正确的是（A）-机器学习-ML模型-中" class="headerlink" title="76. 关于logit回归和SVM不正确的是（A） 机器学习 ML模型 中"></a>76. 关于logit回归和SVM不正确的是（A） 机器学习 ML模型 中</h5><p>　　A. Logit回归本质上是一种根据样本对权值进行极大似然估计的方法，而后验概率正比于先验概率和似然函数的乘积。logit仅仅是最大化似然函数，并没有最大化后验概率，更谈不上最小化后验概率。A错误<br>　　B. Logit回归的输出就是样本属于正类别的几率，可以计算出概率，正确<br>　　C. SVM的目标是找到使得训练数据尽可能分开且分类间隔最大的超平面，应该属于结构风险最小化。<br>　　D. SVM可以通过正则化系数控制模型的复杂度，避免过拟合。<br>　　@BlackEyes_SGC：Logit回归目标函数是最小化后验概率，Logit回归可以用于预测事件发生概率的大小，SVM目标是结构风险最小化，SVM可以有效避免模型过拟合。<br>的数目，m为记录数，n为维数</p>
<h5 id="77-输入图片大小为200×200，依次经过一层卷积（kernel-size-5×5，padding-1，stride-2），pooling（kernel-size-3×3，padding-0，stride-1），又一层卷积（kernel-size-3×3，padding-1，stride-1）之后，输出特征图大小为（）-深度学习-DL基础-中"><a href="#77-输入图片大小为200×200，依次经过一层卷积（kernel-size-5×5，padding-1，stride-2），pooling（kernel-size-3×3，padding-0，stride-1），又一层卷积（kernel-size-3×3，padding-1，stride-1）之后，输出特征图大小为（）-深度学习-DL基础-中" class="headerlink" title="77. 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为（） 深度学习 DL基础 中"></a>77. 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为（） 深度学习 DL基础 中</h5><p>　　A 95　　B 96　　<strong>C 97</strong>　　D 98　　E 99　　F 100<br>　　正确答案：C<br>　　@BlackEyes_SGC：计算尺寸不被整除只在GoogLeNet中遇到过。卷积向下取整，池化向上取整。<br>　　本题 （200-5+2 * 1）/2+1 为99.5，取99<br>　　（99-3）/1+1 为97<br>　　（97-3+2 * 1）/1+1 为97<br>　　研究过网络的话看到stride为1的时候，当kernel为 3 padding为1或者kernel为5 padding为2 一看就是卷积前后尺寸不变。<br>　　计算GoogLeNet全过程的尺寸也一样。</p>
<h5 id="78-影响聚类算法结果的主要因素有？-机器学习-ML模型-易"><a href="#78-影响聚类算法结果的主要因素有？-机器学习-ML模型-易" class="headerlink" title="78. 影响聚类算法结果的主要因素有？ 机器学习 ML模型 易"></a>78. 影响聚类算法结果的主要因素有？ 机器学习 ML模型 易</h5><p>　　A.已知类别的样本质量；　　<strong>B.分类准则；　　C.特征选取；　　D.模式相似性测度 </strong></p>
<h5 id="79-模式识别中，马式距离较之于欧式距离的优点是（C、D）-机器学习-ML模型-易"><a href="#79-模式识别中，马式距离较之于欧式距离的优点是（C、D）-机器学习-ML模型-易" class="headerlink" title="79. 模式识别中，马式距离较之于欧式距离的优点是（C、D） 机器学习 ML模型 易"></a>79. 模式识别中，马式距离较之于欧式距离的优点是（C、D） 机器学习 ML模型 易</h5><p>　　A.平移不变性；　　B.旋转不变性；　　<strong>C.尺度不变性；　　D.考虑了模式的分布</strong></p>
<h5 id="79-影响基本K-均值算法的主要因素有-BD）-机器学习-ML模型-易"><a href="#79-影响基本K-均值算法的主要因素有-BD）-机器学习-ML模型-易" class="headerlink" title="79. 影响基本K-均值算法的主要因素有(BD） 机器学习 ML模型 易"></a>79. 影响基本K-均值算法的主要因素有(BD） 机器学习 ML模型 易</h5><p>　　A.样本输入顺序；　<strong>　B.模式相似性测度；　</strong>　C.聚类准则；　　<strong>D.初始类中心的选取 </strong></p>
<h5 id="80-在统计模式分类问题中，当先验概率未知时，可以使用（BD）-机器学习-ML模型-易"><a href="#80-在统计模式分类问题中，当先验概率未知时，可以使用（BD）-机器学习-ML模型-易" class="headerlink" title="80. 在统计模式分类问题中，当先验概率未知时，可以使用（BD） 机器学习 ML模型 易"></a>80. 在统计模式分类问题中，当先验概率未知时，可以使用（BD） 机器学习 ML模型 易</h5><p>　　A. 最小损失准则；　　<strong>B. 最小最大损失准则；</strong>　　C. 最小误判概率准则； 　　<strong>D. N-P判决；</strong><br>　　@刘炫320，本题题目及解析来源：<a href="http://blog.csdn.net/column/details/16442.html" target="_blank" rel="noopener">机器学习习题集</a><br>　　选项A，最小损失准则中需要用到先验概率<br>　　选项B，而最大最小损失规则主要就是使用解决最小损失规则时先验概率未知或难以计算的问题的。<br>　　选项D，在贝叶斯决策中，对于先验概率p(y)，分为已知和未知两种情况。<br>　　1. p(y)已知，直接使用贝叶斯公式求后验概率即可；<br>　　2. p(y)未知，可以使用<strong>聂曼-皮尔逊决策(N-P决策)</strong>来计算决策面。<br>　　聂曼-皮尔逊决策（N-P判决）可以归结为找阈值a，即：<br>　　如果，则x属于w1；<br>　　如果，则x属于w2；</p>
<h5 id="81-如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC）-机器学习-ML模型-易"><a href="#81-如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC）-机器学习-ML模型-易" class="headerlink" title="81. 如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC） 机器学习 ML模型 易"></a>81. 如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC） 机器学习 ML模型 易</h5><p>　　A. 已知类别样本质量；　　<strong>B. 分类准则；　　C. 特征选取；</strong>　　D. 量纲；</p>
<h5 id="82-欧式距离具有（AB-）；马式距离具有（ABCD-）。机器学习-ML基础-易"><a href="#82-欧式距离具有（AB-）；马式距离具有（ABCD-）。机器学习-ML基础-易" class="headerlink" title="82. 欧式距离具有（AB ）；马式距离具有（ABCD ）。机器学习 ML基础 易"></a>82. 欧式距离具有（AB ）；马式距离具有（ABCD ）。机器学习 ML基础 易</h5><p>　　<strong>A. 平移不变性；　　B. 旋转不变性；　　C. 尺度缩放不变性；　　D. 不受量纲影响的特性</strong></p>
<h5 id="83-你有哪些deep-learning（rnn、cnn）调参的经验？-深度学习-DL基础-中"><a href="#83-你有哪些deep-learning（rnn、cnn）调参的经验？-深度学习-DL基础-中" class="headerlink" title="83. 你有哪些deep learning（rnn、cnn）调参的经验？ 深度学习 DL基础 中"></a>83. 你有哪些deep learning（rnn、cnn）调参的经验？ 深度学习 DL基础 中</h5><p>　　@萧瑟，来源<a href="https://www.zhihu.com/question/41631631/answer/94816420" target="_blank" rel="noopener">你有哪些deep learning（rnn、cnn）调参的经验？</a><br>　　<strong>参数初始化</strong><br>　　下面几种方式,随便选一个,结果基本都差不多。但是一定要做。否则可能会减慢收敛速度，影响收敛结果，甚至造成Nan等一系列问题。<br>　　下面的n_in为网络的输入大小，n_out为网络的输出大小，n为n_in或(n_in+n_out)*0.5<br>　　Xavier初始法论文：<a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Understanding the difficulty of training deep feedforward neural networks</a><br>　　He初始化论文：<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a><br>　　1. uniform均匀分布初始化：w = np.random.uniform(low=-scale, high=scale, size=[n_in,n_out])<br>　　　　Xavier初始法，适用于普通激活函数(tanh,sigmoid)：scale = np.sqrt(3/n)<br>　　　　He初始化，适用于ReLU：scale = np.sqrt(6/n)<br>　　2. normal高斯分布初始化：w = np.random.randn(n_in,n_out) * stdev # stdev为高斯分布的标准差，均值设为0<br>　　　　Xavier初始法，适用于普通激活函数 (tanh,sigmoid)：stdev = np.sqrt(n)<br>　　　　He初始化，适用于ReLU：stdev = np.sqrt(2/n)<br>　　3. svd初始化：对RNN有比较好的效果。参考论文：<a href="https://arxiv.org/abs/1312.6120" target="_blank" rel="noopener">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</a><br>　　<strong>数据预处理方式</strong><br>　　　1. zero-center ,这个挺常用的.X -= np.mean(X, axis = 0) # zero-centerX /= np.std(X, axis = 0) # normalize<br>　　　2. PCA whitening,这个用的比较少.<br>　　<strong>训练技巧</strong><br>　　　1. 要做梯度归一化,即算出来的梯度除以minibatch size<br>　　　2. clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2+w2^2….),如果value超过了阈值,就算一个衰减系系数,让value的值等于阈值: 5,10,15<br>　　　3. dropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd在我的大部分实验中，效果提升都非常明显.因此可能的话，建议一定要尝试一下。 dropout的位置比较有讲究, 对于RNN,建议放到输入-&gt;RNN与RNN-&gt;输出的位置.关于RNN如何用dropout,可以参考这篇论文:<a href="http://arxiv.org/abs/1409.2329" target="_blank" rel="noopener">Recurrent Neural Network Regularization</a><br>　　　4. adam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。<br>　　　5. 除了gate之类的地方,需要把输出限制成0-1之外,尽量不要用sigmoid,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4的区间里，才有较大的梯度。之外的区间，梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。<br>　　　6. rnn的dim和embdding size,一般从128上下开始调整. batch size,一般从128左右开始调整.batch size合适最重要,并不是越大越好.<br>　　　7. word2vec初始化,在小数据上,不仅可以有效提高收敛速度,也可以可以提高结果.<br>　　　8. 尽量对数据做shuffle<br>　　　9. LSTM 的forget gate的bias,用1.0或者更大的值做初始化,可以取得更好的结果,来自这篇论文:<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">An Empirical Exploration of Recurrent Network Architectures</a>, 我这里实验设成1.0,可以提高收敛速度.实际使用中,不同的任务,可能需要尝试不同的值.<br>　　　10.  Batch Normalization据说可以提升效果，不过我没有尝试过，建议作为最后提升模型的手段，参考论文：Accelerating Deep Network Training by Reducing Internal Covariate Shift<br>　　　11.  如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成Highway Network,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给输出加了一个gate来控制信息的流动，详细介绍请参考论文: <a href="http://arxiv.org/abs/1505.00387" target="_blank" rel="noopener">Highway Networks</a><br>　　　12.  来自@张馨宇的技巧：一轮加正则，一轮不加正则，反复进行。<br>　　<strong>Ensemble</strong><br>　　　Ensemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式<br>　　　同样的参数,不同的初始化方式<br>　　　不同的参数,通过cross-validation,选取最好的几组<br>　　　同样的参数,模型训练的不同阶段，即不同迭代次数的模型。<br>　　不同的模型,进行线性融合. 例如RNN和传统模型.<br>　　更多深度学习技巧，请参见专栏：<a href="https://zhuanlan.zhihu.com/easyml" target="_blank" rel="noopener">炼丹实验室 - 知乎专栏</a></p>
<h5 id="84-简单说说RNN的原理？深度学习-DL模型-中"><a href="#84-简单说说RNN的原理？深度学习-DL模型-中" class="headerlink" title="84. 简单说说RNN的原理？深度学习 DL模型 中"></a>84. 简单说说RNN的原理？深度学习 DL模型 中</h5><p>　　我们升学到高三准备高考时，此时的知识是由高二及高二之前所学的知识加上高三所学的知识合成得来，即我们的知识是由前序铺垫，是有记忆的，好比当电影字幕上出现：“我是”时，你会很自然的联想到：“我是中国人”。<br>　　<img src="20170929002252306.jpg" alt="20170929002252306.jpg"></p>
<h5 id="85-什么是RNN？深度学习-DL模型-中"><a href="#85-什么是RNN？深度学习-DL模型-中" class="headerlink" title="85. 什么是RNN？深度学习 DL模型 中"></a>85. 什么是RNN？深度学习 DL模型 中</h5><p>　　@一只鸟的天空，本题解析来源：<a href="http://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="noopener">循环神经网络(RNN, Recurrent Neural Networks)介绍</a><br>　　RNNs的目的使用来处理<strong>序列数据</strong>。在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNNs之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即<strong>隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。</strong>理论上，RNNs能够对任何长度的序列数据进行处理。但是在实践中，为了降低复杂性往往假设当前的状态只与前面的几个状态相关，下图便是一个典型的RNNs：<br>　　<img src="20150921225357857.jpg" alt="20150921225357857.jpg"><br>　　<img src="20150921225622105.jpg" alt="20150921225622105.jpg"><br>　　From Nature<br>　　RNNs包含输入单元(Input units)，输入集标记为${x_0,x_1,…,x_t,x_{t+1},…}$，而输出单元(Output units)的输出集则被标记为${y_0,y_1,…,y_t,y_{t+1}.,..}$。RNNs还包含隐藏单元(Hidden units)，我们将其输出集标记为${s_0,s_1,…,s_t,s_{t+1},…}，这些隐藏单元完成了最为主要的工作。你会发现，在图中：有一条单向流动的信息流是从输入单元到达隐藏单元的，与此同时另一条单向流动的信息流从隐藏单元到达输出单元。在某些情况下，RNNs会打破后者的限制，引导信息从输出单元返回隐藏单元，这些被称为“Back Projections”，并且隐藏层的输入还包括上一隐藏层的状态，即隐藏层内的节点可以自连也可以互连。<br>　　上图将循环神经网络进行展开成一个全神经网络。例如，对一个包含5个单词的语句，那么展开的网络便是一个五层的神经网络，每一层代表一个单词。对于该网络的计算过程如下：</p>
<p>　　a). $x_t$表示第$t,t=1,2,3…t$步(step)的输入。比如，$x_1$为第二个词的one-hot向量(根据上图，$x_0￥为第一个词)；<br>　　PS：使用计算机对自然语言进行处理，便需要将自然语言处理成为机器能够识别的符号，加上在机器学习过程中，需要将其进行数值化。而词是自然语言理解与处理的基础，因此需要对词进行数值化，词向量(Word Representation，Word embeding)[1]便是一种可行又有效的方法。何为词向量，即使用一个指定长度的实数向量v来表示一个词。有一种种最简单的表示方法，就是使用One-hot vector表示单词，即根据单词的数量|V|生成一个|V| * 1的向量，当某一位为一的时候其他位都为零，然后这个向量就代表一个单词。缺点也很明显：<br>　　　1. 由于向量长度是根据单词个数来的，如果有新词出现，这个向量还得增加，麻烦！(Impossible to keep up to date);<br>　　　2. 主观性太强(subjective)<br>　　　3. 这么多单词，还得人工打labor并且adapt，想想就恐<br>　　　4. 最不能忍受的一点便是很难计算单词之间的相似性。<br>　　　现在有一种更加有效的词向量模式，该模式是通过神经网或者深度学习对词进行训练，输出一个指定维度的向量，该向量便是输入词的表达。如word2vec。<br>　　b). $s_t$为隐藏层的第t步的状态，它是网络的记忆单元。 $s_t$根据当前输入层的输出与上一步隐藏层的状态进行计算。$st=f(U_{x_t}+W_{s_t−1)}，其中$f$一般是非线性的激活函数，如tanh或ReLU，在计算$s_0$时，即第一个单词的隐藏层状态，需要用到s_{−1}，但是其并不存在，在实现中一般置为0向量；<br>　　c). $o_t$是第t步的输出，如下个单词的向量表示，$o_t=softmax(V_{s_t}).<br>　　更多请看此文：<a href="http://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="noopener">循环神经网络(RNN, Recurrent Neural Networks)介绍。</a></p>
<h5 id="86-RNN是怎么从单层网络一步一步构造的？深度学习-DL模型-难"><a href="#86-RNN是怎么从单层网络一步一步构造的？深度学习-DL模型-难" class="headerlink" title="86. RNN是怎么从单层网络一步一步构造的？深度学习 DL模型 难"></a>86. RNN是怎么从单层网络一步一步构造的？深度学习 DL模型 难</h5><p>　　@何之源，本题解析来源：<a href="https://zhuanlan.zhihu.com/p/28054589" target="_blank" rel="noopener">完全图解RNN、RNN变体、Seq2Seq、Attention机制</a><br>　　<a href="https://www.jianshu.com/p/9dc9f41f0b29" target="_blank" rel="noopener">[译] 理解 LSTM 网络</a></p>
<h5 id="87-RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习-DL模型-中"><a href="#87-RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习-DL模型-中" class="headerlink" title="87. RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习 DL模型 中"></a>87. RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习 DL模型 中</h5><p>　　<a href="https://www.zhihu.com/question/61265076" target="_blank" rel="noopener">RNN中为什么要采用tanh而不是ReLu作为激活函数？</a></p>
<h5 id="88-深度学习（CNN-RNN-Attention）解决大规模文本分类问题。深度学习-DL应用-难"><a href="#88-深度学习（CNN-RNN-Attention）解决大规模文本分类问题。深度学习-DL应用-难" class="headerlink" title="88. 深度学习（CNN RNN Attention）解决大规模文本分类问题。深度学习 DL应用 难"></a>88. 深度学习（CNN RNN Attention）解决大规模文本分类问题。深度学习 DL应用 难</h5><p>　　<a href="https://zhuanlan.zhihu.com/p/25928551" target="_blank" rel="noopener">用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践</a></p>
<h5 id="89-如何解决RNN梯度爆炸和弥散的问题？深度学习-DL模型-难"><a href="#89-如何解决RNN梯度爆炸和弥散的问题？深度学习-DL模型-难" class="headerlink" title="89. 如何解决RNN梯度爆炸和弥散的问题？深度学习 DL模型 难"></a>89. 如何解决RNN梯度爆炸和弥散的问题？深度学习 DL模型 难</h5><p>　　本题解析来源：<a href="https://blog.csdn.net/han_xiaoyang/article/details/51932536" target="_blank" rel="noopener">深度学习与自然语言处理(7)_斯坦福cs224d 语言模型，RNN，LSTM与GRU</a><br>　　为了解<strong>决梯度爆炸</strong>问题，Thomas Mikolov首先提出了一个简单的启发性的解决方案，就是当梯度大于一定阈值的的时候，将它截断为一个较小的数。具体如算法1所述：<br>　　算法1：当梯度爆炸时截断梯度（伪代码）</p>
<script type="math/tex; mode=display">\hat{g} \leftarrow \frac{\partial E}{\partial W} \\
if \  \left \| \hat{g} \right \| \geq threshold \  then \\
\hat{g} \leftarrow \frac{threashold}{ \left\| \hat{g} \right\|}\hat{g}</script><p>　　下图可视化了梯度截断的效果。它展示了一个小的rnn（其中W为权值矩阵，b为bias项）的决策面。这个模型是一个一小段时间的rnn单元组成；实心箭头表明每步梯度下降的训练过程。当梯度下降过程中，模型的目标函数取得了较高的误差时，梯度将被送到远离决策面的位置。截断模型产生了一个虚线，它将误差梯度拉回到离原始梯度接近的位置。<br>　　<img src="1.png" alt="1.png"><br>　　为了解决<strong>梯度弥散</strong>的问题，我们介绍了两种方法。第一种方法是将随机初始化$W^{(hh)}改为一个有关联的矩阵初始化。第二种方法是使用ReLU（Rectified Linear Units）代替sigmoid函数。ReLU的导数不是0就是1.因此，神经元的梯度将始终为1，而不会当梯度传播了一定时间之后变小。</p>
<h5 id="90-如何理解LSTM网络。深度学习-DL模型-难"><a href="#90-如何理解LSTM网络。深度学习-DL模型-难" class="headerlink" title="90. 如何理解LSTM网络。深度学习 DL模型 难"></a>90. 如何理解LSTM网络。深度学习 DL模型 难</h5><p>　　@Not_GOD，本题解析来源：<a href="https://www.jianshu.com/p/9dc9f41f0b29/" target="_blank" rel="noopener">[译] 理解 LSTM 网络</a></p>
<h5 id="91-当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习-ML应用-难"><a href="#91-当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习-ML应用-难" class="headerlink" title="91. 当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习 ML应用 难"></a>91. 当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习 ML应用 难</h5><p>　　可以从这4个方面进行尝试：、基于数据、借助算法、用算法调参、借助模型融合。当然能谈多细多深入就看你的经验心得了。这里有一份参考清单：<a href="http://blog.csdn.net/han_xiaoyang/article/details/53453145" target="_blank" rel="noopener">机器学习性能改善备忘单</a>。</p>
<h5 id="92-如何提高深度学习的性能？深度学习-DL应用-难"><a href="#92-如何提高深度学习的性能？深度学习-DL应用-难" class="headerlink" title="92. 如何提高深度学习的性能？深度学习 DL应用 难"></a>92. 如何提高深度学习的性能？深度学习 DL应用 难</h5><p>　　<a href="https://blog.csdn.net/han_xiaoyang/article/details/52654879" target="_blank" rel="noopener">机器学习系列(10)_如何提高深度学习(和机器学习)的性能</a><br>　　1. 通过数据提升性能<br>　　　　a). 获取更多数据<br>　　　　b). 创造更多数据<br>　　　　c). 重放缩你的数据<br>　　　　d). 转换你的数据<br>　　　　e). 特征选取<br>　　　　f). 重架构你的问题<br>　　2. 通过算法提升性能<br>　　　　a). 对算法进行抽样调查<br>　　　　b). 借鉴已有文献<br>　　　　c). 重采样方法<br>　　3. 通过算法调参提升性能<br>　　　　a). 诊断（Diagnostics）<br>　　　　b). 权重初始化（Weight Initialization）<br>　　　　c). 学习速率（Learning Rate）<br>　　　　d). 激活函数<br>　　　　e). 网络拓扑（Network Topology）<br>　　　　f). 批次和周期（Batches and Epochs）<br>　　　　g). 正则化<br>　　　　h). 优化和损失<br>　　　　i). 早停法<br>　　4. 通过嵌套模型提升性能<br>　　　　a). 组合模型<br>　　　　b). 组合视角<br>　　　　c). 堆叠（Stacking）</p>
<h5 id="93-什麽样的资料集不适合用深度学习？深度学习-DL应用-难"><a href="#93-什麽样的资料集不适合用深度学习？深度学习-DL应用-难" class="headerlink" title="93. 什麽样的资料集不适合用深度学习？深度学习 DL应用 难"></a>93. 什麽样的资料集不适合用深度学习？深度学习 DL应用 难</h5><p>　　@抽象猴，来源：<a href="https://www.zhihu.com/question/41233373" target="_blank" rel="noopener">如果你是面试官，你怎么去判断一个面试者的深度学习水平？</a><br>　　1. <strong>数据集太小</strong>，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。<br>　　2. <strong>数据集没有局部相关特性</strong>，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。</p>
<h5 id="94-广义线性模型是怎被应用在深度学习中？深度学习-DL模型-中"><a href="#94-广义线性模型是怎被应用在深度学习中？深度学习-DL模型-中" class="headerlink" title="94. 广义线性模型是怎被应用在深度学习中？深度学习 DL模型 中"></a>94. 广义线性模型是怎被应用在深度学习中？深度学习 DL模型 中</h5><p>　　@许韩，来源：<a href="https://www.zhihu.com/question/41233373/answer/145404190" target="_blank" rel="noopener">如果你是面试官，你怎么去判断一个面试者的深度学习水平？</a><br>　　1. <a href="https://link.zhihu.com/?target=http%3A//blog.shakirm.com/2015/01/a-statistical-view-of-deep-learning-i-recursive-glms/" target="_blank" rel="noopener">A Statistical View of Deep Learning (I): Recursive GLMs</a><br>　　2. 深度学习从统计学角度，可以看做递归的广义线性模型。<br>　　3. 广义线性模型相对于经典的线性模型(y=wx+b)，核心在于引入了连接函数g(.)，形式变为：y=g−1(wx+b)。<br>　　4. 深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻辑回归（广义线性模型的一种）的Logistic函数即为神经元激活函数中的Sigmoid函数，很多类似的方法在统计学和神经网络中的名称不一样，容易引起初学者（这里主要指我）的困惑。下图是一个对照表：<br><img src="20171008195457989.jpg" alt="20171008195457989.jpg"></p>
<h5 id="95-准备机器学习面试应该了解哪些理论知识？机器学习-ML模型-中"><a href="#95-准备机器学习面试应该了解哪些理论知识？机器学习-ML模型-中" class="headerlink" title="95. 准备机器学习面试应该了解哪些理论知识？机器学习 ML模型 中"></a>95. 准备机器学习面试应该了解哪些理论知识？机器学习 ML模型 中</h5><p>　　@穆文，来源：<a href="https://www.zhihu.com/question/62482926" target="_blank" rel="noopener">如果你是面试官，你怎么去判断一个面试者的深度学习水平？</a><br>　　1. <strong>【理论功底】</strong>主要考察对机器学习模型的理解，选择性提问（如果遇到面试者的研究方向自己不了解但感兴趣，会很欣喜，可以趁机学习一个哈哈）这块儿的问题会比较细碎，都是我自己深入思考过的（背书是没用的，这里任何一个点我都可以给你展开问下去），在此全部手敲<br>　　　a).　<strong> 过拟合欠拟合</strong>（举几个例子让判断下，顺便问问交叉验证的目的、超参数搜索方法、EarlyStopping）、L1正则和L2正则的做法、正则化背后的思想（顺便问问BatchNorm、Covariance Shift）、L1正则产生稀疏解原理、逻辑回归为何线性模型（顺便问问LR如何解决低维不可分、从图模型角度看LR和朴素贝叶斯和无监督）、几种参数估计方法MLE/MAP/贝叶斯的联系和区别、简单说下SVM的支持向量（顺便问问KKT条件、为何对偶、核的通俗理解）、 GBDT随机森林能否并行（顺便问问bagging boosting）、 生成模型判别模型举个例子、聚类方法的掌握（顺便问问Kmeans的EM推导思路、谱聚类和Graph-cut的理解）、梯度下降类方法和牛顿类方法的区别（顺便问问Adam、L-BFGS的思路）、半监督的思想（顺便问问一些特定半监督算法是如何利用无标签数据的、从MAP角度看半监督）、常见的分类模型的评价指标（顺便问问交叉熵、ROC如何绘制、AUC的物理含义、类别不均衡样本）<br>　　　b).　CNN中卷积操作和卷积核作用、maxpooling作用、卷积层与全连接层的联系、梯度爆炸和消失的概念（顺便问问神经网络权值初始化的方法、为何能减缓梯度爆炸消失、CNN中有哪些解决办法、LSTM如何解决的、如何梯度裁剪、dropout如何用在RNN系列网络中、dropout防止过拟合）、为何卷积可以用在图像/语音/语句上（顺便问问channel在不同类型数据源中的含义）<br>　　　c). 如果面试者跟我一样做NLP、推荐系统，我会继续追问 CRF跟逻辑回归 最大熵模型的关系、CRF的优化方法、CRF和MRF的联系、HMM和CRF的关系（顺便问问 朴素贝叶斯和HMM的联系、LSTM+CRF 用于序列标注的原理、CRF的点函数和边函数、CRF的经验分布）、WordEmbedding的几种常用方法和原理（顺便问问language model、perplexity评价指标、word2vec跟Glove的异同）、topic model说一说、为何CNN能用在文本分类、syntactic和semantic问题举例、常见Sentence embedding方法、注意力机制（顺便问问注意力机制的几种不同情形、为何引入、seq2seq原理）、序列标注的评价指标、语义消歧的做法、常见的跟word有关的特征、factorization machine、常见矩阵分解模型、如何把分类模型用于商品推荐（包括数据集划分、模型验证等）、序列学习、wide&amp;deep model（顺便问问为何wide和deep)<br>　　2. <strong>【代码能力】</strong>主要考察实现算法和优化代码的能力，我一般会先看面试者的github repo（如果简历给出来），看其代码风格、架构能力（遇到大神会认真学习一个哈哈），如果没有github，我会避免问典型的应试题，而是问一些我本人从实际问题中抽象出的小算法题，比如：<br>　　　a). 给出节点的矩阵和边的矩阵，求路径和最大的路径（来源于Viterbi算法，本质就是个动态规划），至少给个思路和伪代码（顺便聊聊前向传播和反向传播）<br>　　　b). 给出一数组，数组元素是pair对儿，表示一个有向无环图的&lt;父亲节点, 孩子节点&gt;，用最优的方法，将其变成一个新的有序数组，数组元素是该有向无环图所有节点，数组的有序性体现在：父亲节点在孩子节点前面（来源于 贝叶斯网络实现时的小trick）<br>　　3. <strong>【项目能力】</strong>主要考察解决实际问题的思路、填坑能力，这部分最考验面试官功底，要能从面试者浮夸的描述中寻找有意义的点，并一步步深挖。另外很多dirty work(数据预处理、文本清洗、调参经验、算法复杂度优化、Bad case分析、修改损失函数等)也是在这步深挖。</p>
<h5 id="96-标准化与归一化的区别？机器学习-ML基础-易"><a href="#96-标准化与归一化的区别？机器学习-ML基础-易" class="headerlink" title="96. 标准化与归一化的区别？机器学习 ML基础 易"></a>96. 标准化与归一化的区别？机器学习 ML基础 易</h5><p>　　@艾华丰，本题解析来源：<a href="https://www.zhihu.com/question/20467170" target="_blank" rel="noopener">标准化和归一化什么区别？</a><br>　　<strong>归一化方法：</strong><br>　　1、把数变为（0，1）之间的小数主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。<br>　　2、把有量纲表达式变为无量纲表达式 归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。<br>　　<strong>标准化方法：</strong><br>　　数据的标准化是将数据按比例缩放，使之落入一个小的特定区间。由于信用指标体系的各个指标度量单位是不同的，为了能够将指标参与评价计算，需要对指标进行规范化处理，通过函数变换将其数值映射到某个数值区间。</p>
<h5 id="97-随机森林如何处理缺失值？机器学习-ML模型-中"><a href="#97-随机森林如何处理缺失值？机器学习-ML模型-中" class="headerlink" title="97. 随机森林如何处理缺失值？机器学习 ML模型 中"></a>97. 随机森林如何处理缺失值？机器学习 ML模型 中</h5><p>　　<strong>方法一</strong>（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补。<br>　　<strong>方法二</strong>（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用proximity矩阵进行加权平均的方法补缺失值。然后迭代4-6次，这个补缺失值的思想和KNN有些类似12。</p>
<h5 id="98-随机森林如何评估特征重要性？机器学习-ML模型-中"><a href="#98-随机森林如何评估特征重要性？机器学习-ML模型-中" class="headerlink" title="98. 随机森林如何评估特征重要性？机器学习 ML模型 中"></a>98. 随机森林如何评估特征重要性？机器学习 ML模型 中</h5><p>　　衡量变量重要性的方法有两种，Decrease GINI 和 Decrease Accuracy：<br>　　1) Decrease GINI： 对于回归问题，直接使用argmax(VarVarLeftVarRight)作为评判标准，即当前节点训练集的方差Var减去左节点的方差VarLeft和右节点的方差VarRight。<br>　　2) Decrease Accuracy：对于一棵树Tb(x)，我们用OOB样本可以得到测试误差1；然后随机改变OOB样本的第j列：保持其他列不变，对第j列进行随机的上下置换，得到误差2。至此，我们可以用误差1-误差2来刻画变量j的重要性。基本思想就是，如果一个变量j足够重要，那么改变它会极大的增加测试误差；反之，如果改变它测试误差没有增大，则说明该变量不是那么的重要。</p>
<h5 id="99-优化Kmeans？机器学习-ML模型-中"><a href="#99-优化Kmeans？机器学习-ML模型-中" class="headerlink" title="99. 优化Kmeans？机器学习 ML模型 中"></a>99. 优化Kmeans？机器学习 ML模型 中</h5><p>　　使用kd树或者ball tree<br>　　将所有的观测实例构建成一颗kd树，之前每个聚类中心都是需要和每个观测点做依次距离计算，现在这些聚类中心根据kd树只需要计算附近的一个局部区域即可。</p>
<h5 id="100-KMeans初始类簇中心点的选取。机器学习-ML模型-中"><a href="#100-KMeans初始类簇中心点的选取。机器学习-ML模型-中" class="headerlink" title="100. KMeans初始类簇中心点的选取。机器学习 ML模型 中"></a>100. KMeans初始类簇中心点的选取。机器学习 ML模型 中</h5><p>　　k-means++算法选择初始seeds的基本思想就是：初始的聚类中心之间的相互距离要尽可能的远。<br>　　1. 从输入的数据点集合中随机选择一个点作为第一个聚类中心<br>　　2. 对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)<br>　　3. 选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大<br>　　4. 重复2和3直到k个聚类中心被选出来<br>　　5. 利用这k个初始的聚类中心来运行标准的k-means算法</p>
<p><strong>见下一篇：BAT机器学习面试题库(101-200)</strong></p>

      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/assets/img/weixin.png">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">面试</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">笔记</a>
        		</li>
      		
		</ul>
	</div>

      

      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//pan.baidu.com/share/qrcode?url=http://yoursite.com/2018/07/20/BAT机器学习面试题库（1-100）/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2018/08/01/Leetcode刷题（1-100）/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          LeetCode刷题(1-100)
        
      </div>
    </a>
  
  
    <a href="/2018/06/20/2018搜狐内容识别算法大赛总结/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">2018搜狐内容识别算法大赛总结</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                    <div class="toc-article">
                    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BAT机器学习面试1000题系列"><span class="toc-number"></span> <span class="toc-text">BAT机器学习面试1000题系列</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-请简要介绍下SVM。-机器学习-ML模型-易"><span class="toc-number">0.0.1.</span> <span class="toc-text">1. 请简要介绍下SVM。 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-请简要介绍下Tensorflow的计算图。-深度学习-DL框架-中"><span class="toc-number">0.0.2.</span> <span class="toc-text">2. 请简要介绍下Tensorflow的计算图。 深度学习 DL框架 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？-机器学习-ML模型-中"><span class="toc-number">0.0.3.</span> <span class="toc-text">3. 在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别？ 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-CNN的卷积核是单层的还是多层的？-深度学习-DL模型-中"><span class="toc-number">0.0.4.</span> <span class="toc-text">4. CNN的卷积核是单层的还是多层的？ 深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-关于LR。-机器学习-ML模型-难"><span class="toc-number">0.0.5.</span> <span class="toc-text">5. 关于LR。 机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-（过拟合）overfitting怎么解决？机器学习-ML基础-中"><span class="toc-number">0.0.6.</span> <span class="toc-text">6. （过拟合）overfitting怎么解决？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-LR和SVM的联系与区别。机器学习-ML模型-中"><span class="toc-number">0.0.7.</span> <span class="toc-text">7. LR和SVM的联系与区别。机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-说说你知道的核函数。机器学习-ML基础-易"><span class="toc-number">0.0.8.</span> <span class="toc-text">8. 说说你知道的核函数。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-LR与线性回归的区别与联系。机器学习-ML模型-中等"><span class="toc-number">0.0.9.</span> <span class="toc-text">9. LR与线性回归的区别与联系。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-请问（决策树、Random-Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习-ML模型-难"><span class="toc-number">0.0.10.</span> <span class="toc-text">10. 请问（决策树、Random Forest、Booting、Adaboot）GBDT和XGBoost的区别是什么？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难"><span class="toc-number">0.0.11.</span> <span class="toc-text">11. 为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#12-xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习-ML模型-难"><span class="toc-number">0.0.12.</span> <span class="toc-text">12. xgboost如何寻找最优特征？是又放回还是无放回的呢？机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-谈谈判别式模型和生成式模型？机器学习-ML基础-易"><span class="toc-number">0.0.13.</span> <span class="toc-text">13. 谈谈判别式模型和生成式模型？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#14-L1和L2的区别。机器学习-ML基础-易"><span class="toc-number">0.0.14.</span> <span class="toc-text">14. L1和L2的区别。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#15-L1和L2正则先验分别服从什么分布。机器学习-ML基础-易"><span class="toc-number">0.0.15.</span> <span class="toc-text">15. L1和L2正则先验分别服从什么分布。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#16-CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习-DL应用-难"><span class="toc-number">0.0.16.</span> <span class="toc-text">16. CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#17-说一下Adaboost，权值更新公式。当弱分类器是-G-m-时，每个样本的的权重是-w-1，w-2…-，请写出最终的决策公式。机器学习-ML模型-难"><span class="toc-number">0.0.17.</span> <span class="toc-text">17. 说一下Adaboost，权值更新公式。当弱分类器是$G_m$时，每个样本的的权重是$w_1，w_2…$，请写出最终的决策公式。机器学习 ML模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#18-LSTM结构推导，为什么比RNN好？-深度学习DL模型-难"><span class="toc-number">0.0.18.</span> <span class="toc-text">18. LSTM结构推导，为什么比RNN好？ 深度学习DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#19-根据谷歌一员工写的How-to-Write-a-Spelling-Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习-ML应用-难"><span class="toc-number">0.0.19.</span> <span class="toc-text">19. 根据谷歌一员工写的How to Write a Spelling Corrector显示，Google的拼写检查基于贝叶斯方法。请说说的你的理解，具体Google是怎么利用贝叶斯方法，实现”拼写检查”的功能。机器学习 ML应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#20-为什么朴素贝叶斯如此“朴素”？机器学习-ML模型-易"><span class="toc-number">0.0.20.</span> <span class="toc-text">20. 为什么朴素贝叶斯如此“朴素”？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#21-请大致对比下plsa和LDA的区别。机器学习-ML模型-中等"><span class="toc-number">0.0.21.</span> <span class="toc-text">21. 请大致对比下plsa和LDA的区别。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#22-请简要说说EM算法。机器学习-ML模型-中等"><span class="toc-number">0.0.22.</span> <span class="toc-text">22. 请简要说说EM算法。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#23-KNN中的K如何选取的？机器学习-ML模型-易"><span class="toc-number">0.0.23.</span> <span class="toc-text">23. KNN中的K如何选取的？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#24-机器学习中，为何要经常对数据做归一化。机器学习-ML基础-中等"><span class="toc-number">0.0.24.</span> <span class="toc-text">24. 机器学习中，为何要经常对数据做归一化。机器学习 ML基础 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#25-谈谈深度学习中的归一化问题。深度学习-DL基础-易"><span class="toc-number">0.0.25.</span> <span class="toc-text">25. 谈谈深度学习中的归一化问题。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#26-哪些机器学习算法不需要做归一化处理？机器学习-ML基础-易"><span class="toc-number">0.0.26.</span> <span class="toc-text">26. 哪些机器学习算法不需要做归一化处理？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#27-请简要说说一个完整机器学习项目的流程。机器学习-ML应用-中"><span class="toc-number">0.0.27.</span> <span class="toc-text">27. 请简要说说一个完整机器学习项目的流程。机器学习 ML应用 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#28-逻辑斯特回归为什么要对特征进行离散化。机器学习-ML模型-中等"><span class="toc-number">0.0.28.</span> <span class="toc-text">28. 逻辑斯特回归为什么要对特征进行离散化。机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#29-下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B）-机器学习-ML模型-中等"><span class="toc-number">0.0.29.</span> <span class="toc-text">29. 下列哪个不属于CRF模型对于HMM和MEMM模型的优势（B） 机器学习 ML模型 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#30-什么是熵。机器学习-ML基础-易"><span class="toc-number">0.0.30.</span> <span class="toc-text">30. 什么是熵。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#31-熵、联合熵、条件熵、相对熵、互信息的定义。机器学习-ML基础-中等"><span class="toc-number">0.0.31.</span> <span class="toc-text">31. 熵、联合熵、条件熵、相对熵、互信息的定义。机器学习 ML基础 中等</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#32-什么是最大熵。机器学习-ML基础-易"><span class="toc-number">0.0.32.</span> <span class="toc-text">32. 什么是最大熵。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#33-了解正则化么。机器学习-ML基础-易"><span class="toc-number">0.0.33.</span> <span class="toc-text">33. 了解正则化么。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#34-协方差和相关性有什么区别？机器学习-ML基础-易"><span class="toc-number">0.0.34.</span> <span class="toc-text">34. 协方差和相关性有什么区别？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#35-线性分类器与非线性分类器的区别以及优劣。机器学习-ML基础-易"><span class="toc-number">0.0.35.</span> <span class="toc-text">35. 线性分类器与非线性分类器的区别以及优劣。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#36-简单说说贝叶斯定理。机器学习-ML模型-易"><span class="toc-number">0.0.36.</span> <span class="toc-text">36. 简单说说贝叶斯定理。机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#37-某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？-A-数据挖掘-DM模型-易"><span class="toc-number">0.0.37.</span> <span class="toc-text">37. 某超市研究销售纪录数据后发现，买啤酒的人很大概率也会购买尿布，这种属于数据挖掘的哪类问题？(A)   数据挖掘 DM模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#38-将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？-C-数据挖掘-DM基础-易"><span class="toc-number">0.0.38.</span> <span class="toc-text">38. 将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？(C)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#39-下面哪种不属于数据预处理的方法？-D-数据挖掘-DM基础-易"><span class="toc-number">0.0.39.</span> <span class="toc-text">39. 下面哪种不属于数据预处理的方法？ (D)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#40-什么是KDD？-A-数据挖掘-DM基础-易"><span class="toc-number">0.0.40.</span> <span class="toc-text">40. 什么是KDD？ (A)   数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#41-当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？-B-数据挖掘-DM模型-易"><span class="toc-number">0.0.41.</span> <span class="toc-text">41. 当不知道数据所带标签时，可以使用哪种技术促使带同类标签的数据与带其他标签的数据相分离？(B)  数据挖掘 DM模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#42-建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？-C-数据挖掘-DM基础-易"><span class="toc-number">0.0.42.</span> <span class="toc-text">42. 建立一个模型，通过这个模型根据已知的变量值来预测其他某个变量值属于数据挖掘的哪一类任务？(C)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#43-以下哪种方法不属于特征选择的标准方法：-D-数据挖掘-DM基础-易"><span class="toc-number">0.0.43.</span> <span class="toc-text">43. 以下哪种方法不属于特征选择的标准方法： (D)  数据挖掘 DM基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#44-请用python编写函数find-string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python-Python语言-易"><span class="toc-number">0.0.44.</span> <span class="toc-text">44. 请用python编写函数find_string，从文本中搜索并打印内容，要求支持通配符星号和问号。Python Python语言 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#45-简单说下sigmoid激活函数。深度学习-DL基础-易"><span class="toc-number">0.0.45.</span> <span class="toc-text">45. 简单说下sigmoid激活函数。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#46-什么是卷积。深度学习-DL基础-易"><span class="toc-number">0.0.46.</span> <span class="toc-text">46. 什么是卷积。深度学习 DL基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#47-什么是CNN的池化pool层。深度学习-DL模型-易"><span class="toc-number">0.0.47.</span> <span class="toc-text">47. 什么是CNN的池化pool层。深度学习 DL模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#48-简述下什么是生成对抗网络（GAN）。深度学习-DL扩展-中"><span class="toc-number">0.0.48.</span> <span class="toc-text">48. 简述下什么是生成对抗网络（GAN）。深度学习 DL扩展 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#48-学梵高作画的原理是啥？深度学习-DL应用-难"><span class="toc-number">0.0.49.</span> <span class="toc-text">48. 学梵高作画的原理是啥？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#49-现在有-a-到-z-26-个元素，-编写程序打印-a-到-z-中任取-3-个元素的组合（比如-打印-a-b-c-，d-y-z等）-数理逻辑-排列组合-中"><span class="toc-number">0.0.50.</span> <span class="toc-text">49. 现在有 a 到 z 26 个元素， 编写程序打印 a 到 z 中任取 3 个元素的组合（比如 打印 a b c ，d y z等） 数理逻辑 排列组合 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#50-说说梯度下降法。机器学习-ML基础-中"><span class="toc-number">0.0.51.</span> <span class="toc-text">50. 说说梯度下降法。机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#51-梯度下降法找到的一定是下降最快的方向么？机器学习-ML基础-中"><span class="toc-number">0.0.52.</span> <span class="toc-text">51. 梯度下降法找到的一定是下降最快的方向么？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#52-随机梯度下降"><span class="toc-number">0.0.53.</span> <span class="toc-text">52. 随机梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#53-牛顿法和梯度下降法有什么不同。机器学习-ML基础-中"><span class="toc-number">0.0.54.</span> <span class="toc-text">53. 牛顿法和梯度下降法有什么不同。机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#54-什么是拟牛顿法（Quasi-Newton-Methods）？机器学习-ML基础-中"><span class="toc-number">0.0.55.</span> <span class="toc-text">54. 什么是拟牛顿法（Quasi-Newton Methods）？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#55-请说说随机梯度下降法的问题和挑战？机器学习-ML基础-中"><span class="toc-number">0.0.56.</span> <span class="toc-text">55. 请说说随机梯度下降法的问题和挑战？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#56-说说共轭梯度法？机器学习-ML基础-中"><span class="toc-number">0.0.57.</span> <span class="toc-text">56. 说说共轭梯度法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#57-对所有优化问题来说-有没有可能找到比現在已知算法更好的算法？机器学习-ML基础-中"><span class="toc-number">0.0.58.</span> <span class="toc-text">57. 对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#58-什么最小二乘法？机器学习-ML基础-中"><span class="toc-number">0.0.59.</span> <span class="toc-text">58. 什么最小二乘法？机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#59-看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python-Python语言-易"><span class="toc-number">0.0.60.</span> <span class="toc-text">59. 看你T恤上印着：人生苦短，我用Python，你可否说说Python到底是什么样的语言？你可以比较其他技术或者语言来回答你的问题。Python Python语言 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#60-Python是如何进行内存管理的？-Python-Python基础-中"><span class="toc-number">0.0.61.</span> <span class="toc-text">60. Python是如何进行内存管理的？ Python Python基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#61-请写出一段Python代码实现删除一个list里面的重复元素。Python-Python开发-中"><span class="toc-number">0.0.62.</span> <span class="toc-text">61. 请写出一段Python代码实现删除一个list里面的重复元素。Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#62-编程用sort进行排序，然后从最后一个元素开始判断？Python-Python开发-中"><span class="toc-number">0.0.63.</span> <span class="toc-text">62. 编程用sort进行排序，然后从最后一个元素开始判断？Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#63-Python里面如何生成随机数？-？Python-Python开发-中"><span class="toc-number">0.0.64.</span> <span class="toc-text">63. Python里面如何生成随机数？ ？Python Python开发 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#64-说说常见的损失函数？机器学习-ML基础-易"><span class="toc-number">0.0.65.</span> <span class="toc-text">64. 说说常见的损失函数？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#65-简单介绍下logistics回归？机器学习-ML模型-易"><span class="toc-number">0.0.66.</span> <span class="toc-text">65. 简单介绍下logistics回归？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#66-看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习-DL应用-难"><span class="toc-number">0.0.67.</span> <span class="toc-text">66. 看你是搞视觉的，熟悉哪些CV框架，顺带聊聊CV最近五年的发展史如何？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#67-深度学习在视觉领域有何前沿进展？深度学习-DL应用-难"><span class="toc-number">0.0.68.</span> <span class="toc-text">67. 深度学习在视觉领域有何前沿进展？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#68-在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是-？-机器学习-ML基础-中"><span class="toc-number">0.0.69.</span> <span class="toc-text">68. 在分类问题中，我们经常会遇到正负样本数据量不等的情况，比如正样本为10w条数据，负样本只有1w条数据，以下最合适的处理方法是(  )？ 机器学习 ML基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#69-深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A-B-C的乘积ABC-假设三个矩阵的尺寸分别为m-n，n-p，p-q，且m-lt-n-lt-p-lt-q，以下计算顺序效率最高的是（）？深度学习-DL基础-中"><span class="toc-number">0.0.70.</span> <span class="toc-text">69. 深度学习是当前很热门的机器学习算法，在深度学习中，涉及到大量的矩阵相乘，现在需要计算三个稠密矩阵A,B,C的乘积ABC,假设三个矩阵的尺寸分别为m*n，n*p，p*q，且m&lt;n&lt;p&lt;q，以下计算顺序效率最高的是（）？深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#70-Nave-Bayes是一种特殊的Bayes分类器-特征变量是X-类别标签是C-它的一个假定是（）机器学习-ML模型-中"><span class="toc-number">0.0.71.</span> <span class="toc-text">70. Nave Bayes是一种特殊的Bayes分类器,特征变量是X,类别标签是C,它的一个假定是（）机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#70-关于支持向量机SVM-下列说法错误的是（）-机器学习-ML模型-中"><span class="toc-number">0.0.72.</span> <span class="toc-text">70. 关于支持向量机SVM,下列说法错误的是（） 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#71-在HMM中-如果已知观察序列和产生观察序列的状态序列-那么可用以下哪种方法直接进行参数估计（）机器学习-ML模型-中"><span class="toc-number">0.0.73.</span> <span class="toc-text">71. 在HMM中,如果已知观察序列和产生观察序列的状态序列,那么可用以下哪种方法直接进行参数估计（）机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#72-假定某同学使用Naive-Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习-ML模型-中"><span class="toc-number">0.0.74.</span> <span class="toc-text">72. 假定某同学使用Naive Bayesian（NB）分类模型时，不小心将训练数据的两个维度搞重复了，那么关于NB的说法中正确的是？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#73-以下哪些方法不可以直接来对文本分类？机器学习-ML模型-易"><span class="toc-number">0.0.75.</span> <span class="toc-text">73. 以下哪些方法不可以直接来对文本分类？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#74-已知一组数据的协方差矩阵P-下面关于主分量说法错误的是（）机器学习-ML基础-易"><span class="toc-number">0.0.76.</span> <span class="toc-text">74. 已知一组数据的协方差矩阵P,下面关于主分量说法错误的是（）机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#75-kmeans的复杂度？机器学习-ML模型-易"><span class="toc-number">0.0.77.</span> <span class="toc-text">75. kmeans的复杂度？机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#76-关于logit回归和SVM不正确的是（A）-机器学习-ML模型-中"><span class="toc-number">0.0.78.</span> <span class="toc-text">76. 关于logit回归和SVM不正确的是（A） 机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#77-输入图片大小为200×200，依次经过一层卷积（kernel-size-5×5，padding-1，stride-2），pooling（kernel-size-3×3，padding-0，stride-1），又一层卷积（kernel-size-3×3，padding-1，stride-1）之后，输出特征图大小为（）-深度学习-DL基础-中"><span class="toc-number">0.0.79.</span> <span class="toc-text">77. 输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为（） 深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#78-影响聚类算法结果的主要因素有？-机器学习-ML模型-易"><span class="toc-number">0.0.80.</span> <span class="toc-text">78. 影响聚类算法结果的主要因素有？ 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#79-模式识别中，马式距离较之于欧式距离的优点是（C、D）-机器学习-ML模型-易"><span class="toc-number">0.0.81.</span> <span class="toc-text">79. 模式识别中，马式距离较之于欧式距离的优点是（C、D） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#79-影响基本K-均值算法的主要因素有-BD）-机器学习-ML模型-易"><span class="toc-number">0.0.82.</span> <span class="toc-text">79. 影响基本K-均值算法的主要因素有(BD） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#80-在统计模式分类问题中，当先验概率未知时，可以使用（BD）-机器学习-ML模型-易"><span class="toc-number">0.0.83.</span> <span class="toc-text">80. 在统计模式分类问题中，当先验概率未知时，可以使用（BD） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#81-如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC）-机器学习-ML模型-易"><span class="toc-number">0.0.84.</span> <span class="toc-text">81. 如果以特征向量的相关系数作为模式相似性测度，则影响聚类算法结果的主要因素有（BC） 机器学习 ML模型 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#82-欧式距离具有（AB-）；马式距离具有（ABCD-）。机器学习-ML基础-易"><span class="toc-number">0.0.85.</span> <span class="toc-text">82. 欧式距离具有（AB ）；马式距离具有（ABCD ）。机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#83-你有哪些deep-learning（rnn、cnn）调参的经验？-深度学习-DL基础-中"><span class="toc-number">0.0.86.</span> <span class="toc-text">83. 你有哪些deep learning（rnn、cnn）调参的经验？ 深度学习 DL基础 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#84-简单说说RNN的原理？深度学习-DL模型-中"><span class="toc-number">0.0.87.</span> <span class="toc-text">84. 简单说说RNN的原理？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#85-什么是RNN？深度学习-DL模型-中"><span class="toc-number">0.0.88.</span> <span class="toc-text">85. 什么是RNN？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#86-RNN是怎么从单层网络一步一步构造的？深度学习-DL模型-难"><span class="toc-number">0.0.89.</span> <span class="toc-text">86. RNN是怎么从单层网络一步一步构造的？深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#87-RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习-DL模型-中"><span class="toc-number">0.0.90.</span> <span class="toc-text">87. RNN中只能采用tanh而不是ReLu作为激活函数么？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#88-深度学习（CNN-RNN-Attention）解决大规模文本分类问题。深度学习-DL应用-难"><span class="toc-number">0.0.91.</span> <span class="toc-text">88. 深度学习（CNN RNN Attention）解决大规模文本分类问题。深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#89-如何解决RNN梯度爆炸和弥散的问题？深度学习-DL模型-难"><span class="toc-number">0.0.92.</span> <span class="toc-text">89. 如何解决RNN梯度爆炸和弥散的问题？深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#90-如何理解LSTM网络。深度学习-DL模型-难"><span class="toc-number">0.0.93.</span> <span class="toc-text">90. 如何理解LSTM网络。深度学习 DL模型 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#91-当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习-ML应用-难"><span class="toc-number">0.0.94.</span> <span class="toc-text">91. 当机器学习性能遭遇瓶颈时，你会如何优化的？机器学习 ML应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#92-如何提高深度学习的性能？深度学习-DL应用-难"><span class="toc-number">0.0.95.</span> <span class="toc-text">92. 如何提高深度学习的性能？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#93-什麽样的资料集不适合用深度学习？深度学习-DL应用-难"><span class="toc-number">0.0.96.</span> <span class="toc-text">93. 什麽样的资料集不适合用深度学习？深度学习 DL应用 难</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#94-广义线性模型是怎被应用在深度学习中？深度学习-DL模型-中"><span class="toc-number">0.0.97.</span> <span class="toc-text">94. 广义线性模型是怎被应用在深度学习中？深度学习 DL模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#95-准备机器学习面试应该了解哪些理论知识？机器学习-ML模型-中"><span class="toc-number">0.0.98.</span> <span class="toc-text">95. 准备机器学习面试应该了解哪些理论知识？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#96-标准化与归一化的区别？机器学习-ML基础-易"><span class="toc-number">0.0.99.</span> <span class="toc-text">96. 标准化与归一化的区别？机器学习 ML基础 易</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#97-随机森林如何处理缺失值？机器学习-ML模型-中"><span class="toc-number">0.0.100.</span> <span class="toc-text">97. 随机森林如何处理缺失值？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#98-随机森林如何评估特征重要性？机器学习-ML模型-中"><span class="toc-number">0.0.101.</span> <span class="toc-text">98. 随机森林如何评估特征重要性？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#99-优化Kmeans？机器学习-ML模型-中"><span class="toc-number">0.0.102.</span> <span class="toc-text">99. 优化Kmeans？机器学习 ML模型 中</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#100-KMeans初始类簇中心点的选取。机器学习-ML模型-中"><span class="toc-number">0.0.103.</span> <span class="toc-text">100. KMeans初始类簇中心点的选取。机器学习 ML模型 中</span></a></li></ol></li></ol></li></ol>
                    </div>
                </span>
            </div>
        </div>
        
    </div>
</aside>




  
  <!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC8zNjc2NC8xMzI5OQ==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->
  
  
  
  
  

  

  

  




          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 申发海
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
  
<span id="busuanzi_container_site_uv">  访问用户<span id="busuanzi_value_site_uv"></span>人次</span>

<span id="busuanzi_container_site_pv"> 总访问量<span id="busuanzi_value_site_pv"></span>次</span>

</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: true
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



<script  async  src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">比赛</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">总结</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">笔记</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">cs231n</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">课程</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">工具使用</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">刷题</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://blog.aschool.cn/17930" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>12计软班级博客</a>
            </li>
          
            <li class="search-li">
              <a href="http://www.cyy11.cn" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>曹依依博客</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">向内认知&lt;br&gt;&lt;br&gt;向外生长&lt;br&gt;</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>